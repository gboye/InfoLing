{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import sys\n",
    "import pickle\n",
    "#import time\n",
    "\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "def warning(*objs):\n",
    "    print(\"WARNING: \", *objs, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nomFeatures=\"NGrams-LetterFeatures.csv\"\n",
    "with codecs.open(nomFeatures,\"r\",encoding=\"utf8\") as stream:\n",
    "    featureLines=stream.readlines()\n",
    "letterFeatures={}\n",
    "for featureLine in featureLines[2:]:\n",
    "    elements=featureLine.strip().split(\"\\t\")\n",
    "    letterFeatures[elements[0]]=[int(i) for i in elements[1:]]\n",
    "#letterFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vectorizeNGram(ngram):\n",
    "    vecteurs=[]\n",
    "    for letter in ngram:\n",
    "        vecteurs.extend(letterFeatures[letter])\n",
    "    return vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorizeNGram(\"bac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nomFichier=\"texte.txt\"\n",
    "try:\n",
    "    fichier = codecs.open(nomFichier, \"r\",encoding=\"utf8\")\n",
    "except IOError:\n",
    "    warning(\"could not open\", nomFichier)\n",
    "    sys.exit()\n",
    "else:\n",
    "    text = fichier.readlines()\n",
    "    fichier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngramN = 5\n",
    "pc = [\".\", \",\", \";\", \":\", \"?\", \"!\", \"--\", \"...\", u\"«\", u\"»\", \"(\", \")\", \"_\",\"*\",'\"',\"/\",\"+\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normaliserTexte(text,nospace=False):\n",
    "    normalText=[]\n",
    "    for line in text:\n",
    "        for ponct in pc: \n",
    "            line=line.replace(ponct,\"\")\n",
    "        line=line.replace(\"'\",\" \")\n",
    "        line=line.replace(\"-\",\" \")\n",
    "        if nospace:\n",
    "            line=re.sub('\\s+','',line)\n",
    "        else:\n",
    "            line=re.sub('\\s+',' ',line)\n",
    "        normalText.append(line.lower())\n",
    "    return normalText\n",
    "\n",
    "def extraireNgrams(text,noclasses=False):\n",
    "    ngrams=[]\n",
    "    classes=[]\n",
    "    for line in text[:]:\n",
    "        line = line.strip()\n",
    "    #    print (line)\n",
    "        espace = line.count(\" \")\n",
    "#        print (len(line),ngramN,espace)\n",
    "        i = 0\n",
    "        while i <= (len(line) - ngramN - espace):\n",
    "            if line[i] != \" \":\n",
    "                lettres = 0\n",
    "                lettreslocales = 0\n",
    "                ngramLocal=[]\n",
    "                j = 0\n",
    "                type = \"\"\n",
    "                while lettres < ngramN:\n",
    "                    if line[i + j] != \" \":\n",
    "                        ngramLocal.append(line[i + j])\n",
    "                        lettres += 1\n",
    "                        lettreslocales += 1\n",
    "                    else:\n",
    "                        type = type + str(lettreslocales) + \"_\"\n",
    "                        lettreslocales = 0\n",
    "                    j += 1\n",
    "                type = type + str(lettreslocales)\n",
    "                ngrams.append(ngramLocal)\n",
    "                classes.append(type)\n",
    "            i = i + 1\n",
    "    if noclasses:\n",
    "        return ngrams\n",
    "    else:\n",
    "        return(ngrams, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'c', u'h', u'a', u'p', u'i'] 5\n"
     ]
    }
   ],
   "source": [
    "trainTexte = normaliserTexte(text)\n",
    "(ngramTrain,classesTrain)=extraireNgrams(trainTexte)\n",
    "print (ngramTrain[0],classesTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngramTrain2=[]\n",
    "for n,ngram in enumerate(ngramTrain):\n",
    "    if debug: print (n, \"\".join(ngram),end=\", \")\n",
    "    ngramTrain2.append(vectorizeNGram(ngram))\n",
    "    \n",
    "#ngramTrain2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 8s, sys: 4.52 s, total: 19min 13s\n",
      "Wall time: 19min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
       "  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,\n",
       "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(ngramTrain2, classesTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testSource=[u\"Dans cette histoire, il y a un loup, une chêvre, et un agneau. Tout se passe bien tant que le loup et l'agneau ne sont pas seuls.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nomFichier=\"LesMiserables.txt\"\n",
    "try:\n",
    "    fichier = codecs.open(nomFichier, \"r\", encoding=\"utf-8\")\n",
    "except IOError:\n",
    "    warning(\"could not open\", nomFichier)\n",
    "    sys.exit()\n",
    "else:\n",
    "    testSource = fichier.readlines()\n",
    "    fichier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u't', u'o', u'm', u'e', u'i']\n"
     ]
    }
   ],
   "source": [
    "testTexte=normaliserTexte(testSource[:200],True)\n",
    "ngramTest=extraireNgrams(testTexte,True)\n",
    "print (ngramTest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngramTest2=[]\n",
    "for n,ngram in enumerate(ngramTest):\n",
    "    if n>2500000: print (n, \"\".join(ngram),end=\", \")\n",
    "    ngramTest2.append(vectorizeNGram(ngram))\n",
    "    \n",
    "#ngramTrain2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction=clf.predict(ngramTest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultChunks=[]\n",
    "for i,element in enumerate(prediction):\n",
    "    chunks=[int(n) for n in element.split(\"_\")]\n",
    "#    print (chunks)\n",
    "    debut=0\n",
    "    elementChunks=[]\n",
    "    for chunk in chunks:\n",
    "#        print (chunk,ngramTest[i][debut:debut+chunk],end=\",\")\n",
    "#    print ()\n",
    "        elementChunks.append(ngramTest[i][debut:debut+chunk])\n",
    "#        print (ngramTest[i][debut:debut+chunk],end=\" \")\n",
    "        debut+=chunk\n",
    "#    print ()\n",
    "    resultChunks.append(elementChunks)\n",
    "#print (resultChunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testSpaces={}\n",
    "for i,chunks in enumerate(resultChunks):\n",
    "    posChunk=0\n",
    "    for chunk in chunks:\n",
    "        if posChunk!=0: \n",
    "#            print (i+posChunk,chunk)\n",
    "            if not i+posChunk in testSpaces:\n",
    "                testSpaces[i+posChunk]=0\n",
    "            testSpaces[i+posChunk]+=1\n",
    "        posChunk+=len(chunk)\n",
    "#testSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomeifantine1862tabledesmatièreslivrepremierunjustechapitreimonsieurmyrielchapitreiimonsieurmyrieldevientmonseigneurbienvenuchapitreiiiàbonévêquedurévêchéchapitreivlesoeuvressemblablesauxparoles_chapitrevquemonseigneurbienvenufaisaitdurertroplongtempssessoutaneschapitreviparquiilfaisaitgardersamaison_chapitreviicravattechapitreviiiphilosophieaprèsboirechapitreixlefrèreracontéparlasoeurchapitrexlévêqueenprésencedunelumièreinconnuechapitrexiunerestrictionchapitrexiisolitudedemonseigneurbienvenuchapitrexiiicequilcroyaitchapitrexivcequilpensait_livredeuxièmelachutechapitreilesoirdunjourdemarchechapitreiilaprudenceconseilléeàlasagessechapitreiiihéroïsmedelobéissancepassivechapitreivdétailssurlesfromageriesdepontarlier_chapitrevtranquillitéchapitrevijeanvaljean_chapitreviilededansdudésespoirchapitreviiilondeetlombrechapitreixnouveauxgriefschapitrexlhommeréveilléchapitrexicequilfaitchapitrexiilévêquetravaillechapitrexiiipetitgervais_livretroisièmeenlannée1817chapitreilannée1817chapitreiidoublequatuorchapitreiiiquatreàquatrechapitreivtholomyèsestsijoyeuxquilchanteunechansonespagnolechapitrevchezbombardachapitrevichapitreoùlonsadorechapitreviisagessedetholomyès_chapitreviiimortdunchevalchapitreixfinjoyeusedelajoielivrequatrièmeconfiercestquelquefoislivrerchapitreiunemèrequienrencontreuneautrechapitreiipremièreesquissededeuxfiguresloucheschapitreiiilalouettelivrecinquièmeladescentechapitreihistoiredunprogrèsdanslesverroteriesnoireschapitreiimmadeleinechapitreiiisommesdéposéeschezlaffittechapitreivmmadeleineendeuilchapitrevvagueséclairsàlhorizonchapitrevilepèrefaucheleventchapitreviifaucheleventdevientjardinieràparischapitreviiimadamevicturniendépensetrentecinqfrancspourlamoralechapitreixsuccèsdemadamevicturnienchapitrexsuitedusuccès_chapitrexichristusnosliberavitchapitrexiiledésoeuvrementdembamataboischapitrexiiisolutiondequelquesquestionsdepolicemunicipalelivresixièmejavertchapitreicommencementdurepos_chapitreiicommentjeanpeutdevenirchamplivreseptièmelaffairechampmathieu_chapitreilasoeursimplicechapitreiiperspicacitédemaîtrescaufflairechapitreiiiunetempêtesousuncrânechapitreivformesqueprendlasouffrancependantlesommeilchapitrevbâtonsdanslesroueschapitrevilasoeursimplicemiseàlépreuvechapitreviilevoyageurarrivéprendsesprécautionspourrepartirchapitreviiientréedefaveurchapitreixunlieuoùdesconvictionssontentraindeseformerchapitrexlesystèmededénégationschapitrexichampmathieudeplusenplusétonné_livrehuitièmecontrecoup_chapitreidansquelmiroirmmadeleineregardesescheveuxchapitreiifantineheureusechapitreiiijavertcontentchapitreivlautoritéreprendsesdroitschapitrevtombeauconvenablelivrepremierunjuste_chapitrei_monsieurmyrielen1815mcharlesfrançoisbienvenumyrielétaitévêquededignecétaitunvieillarddenvironsoixantequinzeansiloccupaitlesiège_dedignedepuis1806quoiquecedétailnetoucheenaucunemanièreaufondmêmedecequenousavonsàraconterilnestpeutêtrepasinutilenefûtcequepourêtreexactentoutdindiquericilesbruitsetlesproposquiavaientcourusursoncompteaumomentoùilétaitarrivédanslediocèsevraioufauxcequonditdeshommestientsouventautantdeplacedansleurvieetsurtoutdansleurdestinéequecequilsfontmmyrielétaitfilsdunconseillerauparlementdaixnoblessederobeoncontaitdeluiquesonpèreleréservantpourhériterdesachargelavaitmariédefortbonneheureàdixhuitouvingtanssuivantunusageassezrépandudanslesfamillesparlementairescharlesmyrielnonobstantcemariageavaitdisaitonbeaucoupfaitparlerdeluiilétaitbienfaitdesapersonnequoiquedassezpetitetailleélégantgracieuxspiritueltoutelapremièrepartiedesavieavaitétédonnéeaumondeetauxgalanterieslarévolutionsurvintlesévénementsseprécipitèrentlesfamillesparlementairesdéciméeschasséestraquées_sedispersèrentmcharlesmyrieldèslespremiersjoursdelarévolutionémigraenitaliesafemmeymourutdunemaladiedepoitrinedontelleétaitatteintedepuislongtempsilsnavaientpointdenfantsquesepassatilensuitedansladestinéedemmyriellécroulementdelanciennesociétéfrançaiselachutedesaproprefamillelestragiquesspectaclesde93pluseffrayantsencorepeutêtrepourlesémigrésquilesvoyaientdeloinaveclegrossissementdelépouvantefirentilsgermerenluidesidéesde_renoncementetdesolitudefutilaumilieudunedecesdistractionsetdecesaffectionsquioccupaientsaviesubitementatteintdundecescoupsmystérieuxetterriblesquiviennentquelquefoisrenverserenlefrappantaucoeurlhommequelescatastrophespubliquesnébranleraientpasenlefrappantdanssonexistenceetdanssafortunenulnauraitpulediretoutcequonsavaitcestquelorsquilrevintditalieilétaitprêtreen1804mmyrielétaitcurédebrignollesilétaitdéjàvieuxetvivaitdansuneretraiteprofondeverslépoqueducouronnementunepetiteaffairedesacureonnesaitplustropquoilamenaàparisentreautrespersonnespuissantesil_allasolliciterpoursesparoissiensmlecardinalfeschunjourquelempereurétaitvenufairevisiteàsononcleledignecuréquiattendaitdanslantichambresetrouvasurlepassagedesamajesténapoléonsevoyantregardéavecunecertainecuriositéparcevieillardseretournaetditbrusquementquelestcebonhommequimeregardesireditmmyrielvousregardezunbonhommeetmoijeregardeungrandhommechacundenouspeutprofiterlempereurlesoirmêmedemandaaucardinallenomdececuréetquelquetempsaprèsmmyrielfuttoutsurprisdapprendrequilétaitnomméévêquededigne_quyavaitildevraidurestedanslesrécitsquonfaisaitsurlapremièrepartiedelaviedemmyrielpersonnenelesavaitpeudefamillesavaientconnulafamillemyrielavantlarévolutionmmyrieldevaitsubirlesortdetoutnouveauvenudansunepetitevilleoùilyabeaucoupdebouchesquiparlentetfortpeudetêtesquipensentildevaitlesubirquoiquilfûtévêqueetparcequilétaitévêquemaisaprèstoutlesproposauxquelsonmêlaitsonnomnétaientpeutêtrequedesproposdubruitdesmotsdesparolesmoinsquedesparolesdespalabrescommeditlénergiquelanguedumidi_quoiquilenfûtaprèsneufansdépiscopatetderésidenceàdignetouscesracontagessujetsdeconversationquioccupentdanslepremiermomentlespetitesvillesetlespetitesgensétaienttombésdansun_oubliprofondpersonneneûtoséenparlerpersonneneûtmêmeosésensouvenirmmyrielétaitarrivéàdigneaccompagnédunevieillefille_mademoisellebaptistinequiétaitsasoeuretquiavaitdixansdemoinsqueluiilsavaientpourtoutdomestiqueuneservantedumêmeâgequemademoisellebaptistineetappeléemadamemagloirelaquelleaprèsavoirétélaservantedemlecuréprenaitmaintenantledoubletitredefemmedechambredemademoiselleetfemmedechargede"
     ]
    }
   ],
   "source": [
    "\n",
    "for i,lettre in enumerate(testTexte):\n",
    "#    print (i)\n",
    "    if i in testSpaces:\n",
    "        # choisir le seuil d'apparition des espaces\n",
    "        # au dessus de deux types convergents : >2\n",
    "        # on insère un espace\n",
    "#        print (testSpaces[i])        \n",
    "        if testSpaces[i]>2:\n",
    "            print (\"_\",end=\"\")\n",
    "        # sinon, par exemple, on colle les lettres\n",
    "        # on pourrait aussi mettre le nombre de votes convergents\n",
    "        # pour voir ce que ça donne\n",
    "        else:\n",
    "            pass\n",
    "#            print (testSpaces[i],end=\"\")\n",
    "    print (lettre,end=\"\")\n",
    "#    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'danscettehistoireilyaunloupunech\\xeavreetunagneautoutsepassebientantqueleloupetlagneaunesontpasseuls']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction=clf.predict(skTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngramComplete=ngramTrain+ngramTest\n",
    "textComplete=[\"\".join(x) for x in ngramComplete]\n",
    "textTrain=[\"\".join(x) for x in ngramTrain]\n",
    "textTest=[\"\".join(x) for x in ngramTest]\n",
    "print (len(textComplete),len(textTrain),len(textTest))\n",
    "print (textComplete[0],textTrain[0],textTest[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer permet de traiter le texte comme des données numériques  \n",
    "- analyzer permet de définir le niveau de tokenization (word, char)\n",
    "- ngram_range permet de définir les ngrams qui seront extraits (min, max)\n",
    "\n",
    "La méthode fit_transform permet de déterminer les données numériques (features) qui seront utilisées pour représenter le texte.\n",
    "\n",
    "Ensuite, on peut utiliser la méthode transform pour représenter un texte en utilisant ces features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "transformVectors = CountVectorizer(analyzer=u'char',ngram_range=(5, 5))\n",
    "skComplete = transformVectors.fit_transform(textComplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM est une des formes d'apprentissage\n",
    "- gamma définit le nombre de features qui seront utilisées pour l'apprentissage\n",
    "- C ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skTrain est la représentation numérique de textTrain\n",
    "\n",
    "clf.fit permet de faire l'apprentissage du lien entre les données de skTrain et les étiquettes fournies dataClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "skTrain=transformVectors.transform(textTrain)\n",
    "clf.fit(skTrain, classesTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('SVC-Decoupages.pkl', 'wb') as output:\n",
    "   pickle.dump(clf, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skTest est la représentation numérique de textTest\n",
    "\n",
    "clf.predict permet de faire la prédiction des étiquettes pour les données de skTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skTest=transformVectors.transform(textTest)\n",
    "prediction=clf.predict(skTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##interprétation des résultats\n",
    "\n",
    "###Découpage des ngrams\n",
    "\n",
    "découpage des ngrams de test en fonction des étiquettes => resultChunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-19ba99927de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#        elementChunks.append(textTest[i][debut:debut+chunk])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0melementChunks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestTexte\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdebut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdebut\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#        print (textTest[i][debut:debut+chunk],end=\" \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdebut\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "resultChunks=[]\n",
    "for i,element in enumerate(prediction):\n",
    "    chunks=[int(n) for n in element.split(\"_\")]\n",
    "#    print (chunks)\n",
    "    debut=0\n",
    "    elementChunks=[]\n",
    "    for chunk in chunks:\n",
    "        elementChunks.append(textTest[i][debut:debut+chunk])\n",
    "#        print (textTest[i][debut:debut+chunk],end=\" \")\n",
    "        debut+=chunk\n",
    "#    print ()\n",
    "    resultChunks.append(elementChunks)\n",
    "#print (resultChunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calcul des votes\n",
    "\n",
    "calcul des votes pour les séparations entre mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSpaces={}\n",
    "for i,chunks in enumerate(resultChunks):\n",
    "    posChunk=0\n",
    "    for chunk in chunks:\n",
    "        if posChunk!=0: \n",
    "#            print (i+posChunk,chunk)\n",
    "            if not i+posChunk in testSpaces:\n",
    "                testSpaces[i+posChunk]=0\n",
    "            testSpaces[i+posChunk]+=1\n",
    "        posChunk+=len(chunk)\n",
    "#testSpaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Découpage de test\n",
    "\n",
    "Séparation des mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,lettre in enumerate(testTexte[200:250]):\n",
    "    if i in testSpaces:\n",
    "        # choisir le seuil d'apparition des espaces\n",
    "        # au dessus de deux types convergents : >2\n",
    "        # on insère un espace\n",
    "        if testSpaces[i]>2:\n",
    "            print (\"_\",end=\"\")\n",
    "        # sinon, par exemple, on colle les lettres\n",
    "        # on pourrait aussi mettre le nombre de votes convergents\n",
    "        # pour voir ce que ça donne\n",
    "        else:\n",
    "            pass\n",
    "#            print (testSpaces[i],end=\"\")\n",
    "    print (lettre,end=\"\")\n",
    "#    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
