{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des TRS pour ajouter les informations de BDLexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import codecs\n",
    "import re\n",
    "import pdb # ajouter pdb.set_trace() à l'endroit où on veut le débugueur\n",
    "from lxml import etree\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os, fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS À FAIRE :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS FAITES :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. ajouter un #id aux tours et aux mots => **22/12/15**\n",
    "1. gérer les parenthèses => **22/12/15**\n",
    "  - les troncations\n",
    "    - version longue pour BDLexique\n",
    "    - version courte pour la transcription\n",
    "  - les champs supplémentaires\n",
    "    - mot => nbsyllabes à saisir\n",
    "    - tour => raccourci\n",
    "1. gérer les balises Event auto-fermantes => **23/12/15**\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'environnement pour le script\n",
    "- *dossier* doit être le répertoire où se trouvent vos fichiers (devrait finir par un /)\n",
    "- *fichierTRS* contient la liste des noms de vos fichiers TRS à traiter (rempli automatiquement)\n",
    "- *fichierLexique* doit être le nom du fichier BDLEXIQUE\n",
    "- *fichierExceptions* doit être le nom de votre fichier INCONNUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecteurs=[\n",
    "    u\"et\", u\"alors\", u\"du coup\", u\"sinon\", u\"par contre\", u\"ça veut dire\", u\"enfin\",\n",
    "u\"après\", u\"donc\", u\"puisque\", u\"puisqu'\", u\"en fait\", u\"mais\", u\"parce que\", u\"parce qu'\", u\"même si\" , u\"d'abord\", u\"et puis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "update=True\n",
    "dossierCorpus=\"/Users/gilles/Downloads/LNS3U5/\"\n",
    "dossierCorpus=\"/Users/gilles/pCloud Drive/FOD/Corpus-2017/0 Groupes/\"\n",
    "dossierCorpus=\"/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/\"\n",
    "fichierXSLT=\"/Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl\"\n",
    "corpusDossiers=glob.glob(dossierCorpus+\"*/\")\n",
    "dossiersTRS={dCorpus:dCorpus+\"inconnus.txt\" for dCorpus in corpusDossiers}\n",
    "sansRebalisageFichiers=[\n",
    "#                        \"Chantal Véronique Giacomo.trs\",\n",
    "#                        \"Les Filles à la fac 2211.trs\",\n",
    "#                        \"Lili et Axelle au mcdo-transcription.trs\",\n",
    "#                        \"heartstone.trs\",\n",
    "#                        \"KirchnerovaAneta.trs\",\n",
    "#                        \"Xeleko-4.3.trs\",\n",
    "#                        \"KevinAzaisCesarMeilleurEspoirMasculin.trs\",\n",
    "#                        \"Donald Trump Talks Media Coverage, Polls and His Vocal Transformation.trs\",\n",
    "#                        \"Nicolas Sarkozy et questions libres.trs\",\n",
    "#                        \"les filles à la fac 22nov.trs\",\n",
    "#                        \"Linguistique (1) (mp3cut.net) (1).trs\",\n",
    "#                        \"trs_3.trs\",\n",
    "#                        \"trs_8.trs\",\n",
    "#                        \"3Cours_Latin 5e _Jean-Pierre_Anne.trs\"\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listeDossiersTRS=corpusDossiers\n",
    "if update:\n",
    "    updatedDossiers=glob.glob(dossierCorpus.replace(\"0 Groupes/\",\"\")+\"[a-zA-Z]*/\")\n",
    "    filtreDossiers=[n.split(\"/\")[-2] for n in updatedDossiers]\n",
    "    filtreDossiers\n",
    "\n",
    "    listeDossiersTRS=[c for c in corpusDossiers if c.split(\"/\")[-2] in filtreDossiers or \"Guerin\" in c]\n",
    "listeDossiersTRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPremierDossier=0\n",
    "numDernierDossier=0\n",
    "if numDernierDossier<numPremierDossier or numDernierDossier==0:\n",
    "    numDernierDossier=100\n",
    "elif numDernierDossier==numPremierDossier:\n",
    "    numDernierDossier+=1\n",
    "numDossiers=range(numPremierDossier,numDernierDossier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichierLexique=\"/Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/bdlexique.txt\"\n",
    "fichier_exceptions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "voyelles=u\"ieɛayøœəuoɔɑɛ̃ɔ̃ɑ̃\"\n",
    "voyelles=u\"ieEay296@uoOòèâêûô\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous n'avez pas de fichier *inconnus.txt* \n",
    ">mettez *fichier_exceptions=False* au dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- mise en texte des deux blocs de traitement de la ligne de commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon=codecs.open(fichierLexique,\"r\",encoding='utf8')\n",
    "bdlexique=lexicon.readlines()\n",
    "lexicon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "facultatives = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon={}\n",
    "result=[]\n",
    "nouvellesExceptions = []\n",
    "output=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "ajouter chaque ligne du fichier à phrases[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerAccents(chaine):\n",
    "    return chaine.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser le mot en cours\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ la ponctuation est remplacée par un espace\n",
    "+ les espaces aux extrémités sont effacés\n",
    "+ le mot est mis en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimer(mot):\n",
    "    mot=lowerAccents(mot)\n",
    "#    for p in u',;.:-?!()“”‘’‛‟′″´˝\"«»':\n",
    "    for p in u',;.:-?!“”‘’‛‟′″´˝\"«»':   # Modifié le 22/12/15 pour gérer les parenthèses comme marqueur dans les mots\n",
    "        mot=mot.replace(p, ' ')\n",
    "    mot=mot.strip()\n",
    "    return mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deparentheser(mot):\n",
    "    forme=mot\n",
    "    graphie=mot\n",
    "    m=re.search(ur\"\\([^)]*\\)\",forme)\n",
    "    while (m):\n",
    "        forme=re.sub(ur\"\\(([^)]*)\\)\",\"\\g<1>\", forme)\n",
    "        graphie=re.sub(ur\"\\(([\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?)\\)\",\"'\", graphie)\n",
    "        m=re.search(ur\"\\([^)]*\\)\",forme)\n",
    "    return(forme,graphie)\n",
    "#    motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'th\\xe9rapeutique', u\"th'rapeutiq'\")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deparentheser(u\"th(é)rapeutiq(ue)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listerMotsCorpus(rootTRS):\n",
    "    phrases=[]\n",
    "    motsPhrases=[]\n",
    "    elementsPhrases=[]\n",
    "    motsCorpus=set()\n",
    "    nPhrases=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        line=ligne.strip()\n",
    "        if 0: print [line]\n",
    "    #    print nPhrases, line\n",
    "        phrases.append(line)\n",
    "#        elements=re.findall(ur\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", line)\n",
    "        elements=re.findall(ur\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ()]+['’]?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", line)\n",
    "        mots=[x for x in elements if not x in u\"-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~:\" and not x in [u\" ;\",u\" !\",u\" ?\",u\" :\"]]\n",
    "        elements=[x for x in elements if x!=u\" \"]\n",
    "        elementsPhrases.append(elements)\n",
    "        phrasePropre = u\"\"\n",
    "        for mot in mots:\n",
    "            mot = trimer(mot)\n",
    "            phrasePropre += mot+u\" \"\n",
    "            (forme,graphie)=deparentheser(mot)\n",
    "#            m=re.search(ur\"\\(.*\\)\",mot)\n",
    "#            forme=mot\n",
    "#            graphie=mot\n",
    "#            if m :\n",
    "#                forme=re.sub(ur\"\\((.*)\\)\",\"\\g<1>\", mot)\n",
    "#                graphie=re.sub(ur\"\\(([\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?)\\)\",\"'\", mot)\n",
    "#                motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}    \n",
    "            motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}\n",
    "            motsCorpus.add(forme)\n",
    "#        phraseMots = phrasePropre.strip()\n",
    "        phraseMots = phrasePropre.split()        \n",
    "        motsPhrases.append(phraseMots)\n",
    "        nPhrases+=1\n",
    "    return (motsCorpus,motsPhrases,elementsPhrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire de BDLex 0.forme fléchie, 1.phonétique, 2.liaison, 3.cat-gram, 4.genre+nombre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire du fichier d'exceptions les mêmes données que pour BDLex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- fait une liste des exceptions lues pour ne pas les rajouter à la fin\n",
    "- éviter de tenir compte des exceptions non renseignées\n",
    " - les mots du fichier exceptions sans transcriptions étaient transcrits par une chaine vide..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier si le mot existe\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ si le mot est dans BDLex, ok\n",
    "+ s'il y a un espace dans le mot,\n",
    "    * le mot est divisé en deux et\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ s'il y a un apostrophe dans le mot,\n",
    "    * le mot est divisé en deux\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ dans les autres cas, le mot est ajouté aux nouvelles exceptions et mis entre étoiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_mot(mot):\n",
    "        sampa=\"\"\n",
    "        if mot in phon.keys():\n",
    "            sampa += phon[mot][0]\n",
    "        elif \" \" in mot:\n",
    "            mots = mot.split()\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif \"'\" in mot:\n",
    "            mots = mot.split(\"'\")\n",
    "            mots[0]=mots[0]+\"'\"\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif mot != \"\": \n",
    "            nouvellesExceptions.append(mot)\n",
    "            sampa=\"***\"+mot+\"*** \"\n",
    "        return sampa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. traduire le SAMPA de BDLexique en API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- ajout du r et du â\n",
    "- ajout des exemples associés en dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traduire SAMPA-BDLex en API\n",
    "\n",
    "def sampa2api(sampa):\n",
    "    if isinstance(sampa,str):\n",
    "        api=sampa.decode(\"utf8\")\n",
    "    else:\n",
    "        api=sampa\n",
    "    api=api.replace(u'n\"',u'n') \n",
    "    api=api.replace(u't\"',u't') \n",
    "    api=api.replace(u'z\"',u'z') \n",
    "    api=api.replace(u'R\"',u'ʁ') \n",
    "    api=api.replace(u'p\"',u'p') \n",
    "    api=api.replace(u'S',u'ʃ') \n",
    "    api=api.replace(u'Z',u'ʒ')\n",
    "    api=api.replace(u'N',u'ŋ')\n",
    "    api=api.replace(u'J',u'ɲ')\n",
    "    api=api.replace(u'r',u'ʁ') \n",
    "    api=api.replace(u'H',u'ɥ')\n",
    "    api=api.replace(u'E',u'ɛ')\n",
    "    api=api.replace(u'2',u'ø')\n",
    "    api=api.replace(u'9',u'œ')\n",
    "    api=api.replace(u'6',u'ə')\n",
    "    api=api.replace(u'O',u'ɔ')\n",
    "    api=api.replace(u'è',u'e')   \n",
    "    api=api.replace(u'ò',u'o')    \n",
    "    api=api.replace(u'â',u'ɑ̃')   \n",
    "    api=api.replace(u'ê',u'ɛ̃')   \n",
    "    api=api.replace(u'û',u'œ̃')  \n",
    "    api=api.replace(u'ô',u'ɔ̃')       \n",
    "    api=api.replace(u'@',u'ə')\n",
    "    api=api.replace(u'R',u'ʁ') \n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Vérifier si la liaison est possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant ne sont pas dans lexicon, pas de liaison\n",
    "+ si le mot a une consonne dans le champ de la voyelle de liaison, check1 est vrai\n",
    "+ si le mot suivant commence par une voyelle, check2 est vrai\n",
    "\n",
    "  si check1 et check2 sont vrais, il y a liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liaison_possible(phrase ,mot , mot_numero):\n",
    "    check1=0\n",
    "    check2=0\n",
    "    if mot in phon and len(phrase)>mot_numero+1 and phrase[mot_numero+1] in phon:\n",
    "        consonnes=['k\"', '(kt)\"', 'n\"', 'p\"', 'R\"', '@t\"', 't\"', '-V', '+V', '@z\"', 'z\"']\n",
    "        phoneme=phon[mot][2]\n",
    "        for phoneme in consonnes:\n",
    "            check1=1\n",
    "        \n",
    "        voyelles=[\"H\", \"j\", \"w\", \"E\", \"a\", \"2\", \"9\", \"6\", \"@\", \"y\", \"u\", \"O\", u\"ò\", \"o\", \"e\", u\"è\", u\"ê\", u\"û\", u\"ô\", \"i\"]\n",
    "        mot_suivant=phon[phrase[mot_numero+1]][1]\n",
    "        for v in voyelles:\n",
    "            if mot_suivant.startswith(v):\n",
    "                check2=1\n",
    "\n",
    "    if check1 and check2 :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. vérifier si la liaison est obligatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liaison_obligatoire(phrase, mot, mot_numero):\n",
    "    determinant=[\"d\", \"P\"]\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    pronompers=[\"P\"]\n",
    "    verbe=[\"V\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "\n",
    "    if catgram_mot1 in determinant and catgram_mot2 in nom :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in determinant and catgram_mot2 in adjectif :\n",
    "        return True\n",
    " \n",
    "    elif catgram_mot1 in pronompers and catgram_mot2 in verbe :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in verbe and catgram_mot2 in pronompers :\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles:\n",
    "\n",
    "- DET + N\n",
    "    * ri + N:   d'animal, \n",
    "    * di + N:   certains éléphants\n",
    "    * rd + N:   les animaux\n",
    "    * dd + N:   ces étés, cet été\n",
    "    * dp + N:   ton anorak\n",
    "    * rc + N:   aux armes\n",
    "- DET + ADJ:\n",
    "    * ri + ADJ:   d'énormes\n",
    "    * di + ADJ:   plusieurs immenses\n",
    "    * rd + ADJ:   les immenses\n",
    "    * dd + ADJ:   cet immense\n",
    "    * dp + ADJ:   son immense\n",
    "    * rc + ADJ:   aux immenses\n",
    "- PERS + V:\n",
    "    * SS + V:   m'épate\n",
    "- V + PRO PERS: \n",
    "    * V + SS:   vont-ils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifier si la liaison est facultative\n",
    "def liaison_facultative(phrase, mot, mot_numero):\n",
    "    #pdb.set_trace()\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    pluriel=[\"MP\", \"FP\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    verbe=[\"V\"]\n",
    "    pronompers=[\"P\"]\n",
    "    adverbe=[\"A\"]\n",
    "    preposition=[\"p\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "    genre_mot1=phon[phrase[mot_numero]][4]\n",
    "    \n",
    "    if (catgram_mot1 in nom) and (phon[phrase[mot_numero]][4] in pluriel) and (catgram_mot2 in adjectif) : \n",
    "        return True\n",
    "\n",
    "    elif (catgram_mot1 in verbe) and (catgram_mot2 not in pronompers):\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in adverbe :\n",
    "        return True\n",
    "    \n",
    "    elif catgram_mot1 in preposition : \n",
    "        return True\n",
    "\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles :\n",
    "\n",
    "- N pl + ADJ: \n",
    "    * N + ADJ: monstres énormes \n",
    "    * G + ADJ: rivaux énormes\n",
    "- VERBE + TOUT-SAUF-PRO-PERS:\n",
    "    * V + N sont éléphants\n",
    "    * V + G sommes abdicaires\n",
    "    * V + V sommes assis\n",
    "    * V + A sommes admirablement\n",
    "    * V + p sommes autour de\n",
    "    * V + di ont aucune\n",
    "    * V + rc sommes au\n",
    "- ADV + QQCH:\n",
    "    * ADV + N vraiment abruti\n",
    "    * ADV + G vraiment abandonné\n",
    "    * ADV + V vraiment aimé\n",
    "    * ADV + J vraiment étonnant\n",
    "    * ADV + ss vraiment ils\n",
    "    * ADV + A vraiment étonnamment\n",
    "    * ADV + p vraiment attendu\n",
    "    * ADV + di vraiment autre \n",
    "    * ADV + rc vraiment au\n",
    "- PREP + QQCH:\n",
    "    * PREP + N très amoureux\n",
    "    * PREP + G très abandonné\n",
    "    * PREP + V très aimé\n",
    "    * PREP + J très étonnant\n",
    "    * PREP + SS très ils\n",
    "    * PREP + A très étonnamment\n",
    "    * PREP + p très attendu\n",
    "    * PREP + di très autre\n",
    "    * PREP + rc très au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Partie 1\n",
    "*chaque phrase est prise individuellement,\n",
    "    * découpée en blocs,\n",
    "        * qui sont chacuns trimés si ce sont des mots\n",
    "        * s'il y a plusieurs mots dans le bloc, ils sont séparés\n",
    "    + Partie 2\n",
    "    * pour chaque couple de mots\n",
    "        * si la liaison est possible,\n",
    "            * et qu'elle est obligatoire, l'api avec la liaison est généré\n",
    "            * et qu'elle est facultative,\n",
    "                * si l'utilisateur l'a choisi, l'api avec la liaison est généré\n",
    "                * sinon l'api sans la liaison est généré\n",
    "\n",
    "        + Partie 3\n",
    "        * si la liaison n'est pas possible,\n",
    "            * si le mot est dans bdlex, l'api est généré\n",
    "            * sinon le mot est laissé tel quel (il a déjà les étoiles)        \n",
    "\n",
    "    * pour le dernier mot de la phrase, \n",
    "        * si le mot est dans bdlex, l'api est généré\n",
    "        * sinon le mot est laissé tel quel (il a déjà les étoiles) \n",
    "\n",
    "+ Partie 4\n",
    "* le message à l'utilisateur et la phrase en api est imprimée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- suppression du délai dans la boucle\n",
    " - pour 1500 lignes => 3 secondes sans ralentisseur, 1503 secondes avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.builder import E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compterVoyelles(chaine):\n",
    "    result=0\n",
    "    for element in chaine:\n",
    "        if element in voyelles:\n",
    "            result+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Début de l'enchassement en XML (7/12/15)\n",
    "- récupérer la ponctuation et les sauts de lignes pour rendre le texte lisible\n",
    "- ajouter le reste des informations du lexique dans la balise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enchasseBDLexique(nphrase,nmot,liaison=False):\n",
    "    boolAbrege=False\n",
    "    motTRS=motsPhrases[nphrase][nmot]\n",
    "    if motTRS in motsAbreges:\n",
    "        mot=motsAbreges[motTRS][\"lexical\"]\n",
    "        graphie=motsAbreges[motTRS][\"graphie\"]\n",
    "        boolAbrege=True\n",
    "    else:\n",
    "        mot=motTRS\n",
    "        graphie=motTRS\n",
    "#    print mot\n",
    "    if mot in phon: \n",
    "        phono=sampa2api(phon[mot][1])\n",
    "        if liaison:\n",
    "            phono+=sampa2api(phon[mot][2])\n",
    "        cat=phon[mot][3]\n",
    "        if cat in [u\"J\",u\"K\"]:\n",
    "            cat=u\"Adj\"\n",
    "        ms=phon[mot][4]\n",
    "        vs=phon[mot][5]\n",
    "        lexeme=phon[mot][6].upper()\n",
    "        freq=phon[mot][8]\n",
    "        nbVoyelles=str(compterVoyelles(phon[mot][1]))\n",
    "        if u\" \" in vs:\n",
    "            vs=u\"\"\n",
    "    else:\n",
    "        phono=verifier_mot(mot)[:-1]\n",
    "        cat=u\"???\"\n",
    "        ms=\"\"\n",
    "        vs=\"\"\n",
    "        lexeme=\"???\"\n",
    "        freq=\"\"\n",
    "        nbVoyelles=\"\"\n",
    "    motAttributs={\"cat\":cat,\"ms\":ms,\"vs\":vs,\"phon\":phono,\"nbsyll\":nbVoyelles, \"lexeme\":lexeme, \"freq\":freq, \"id\":\"%05d%03d\"%(nphrase,nmot)}\n",
    "    if boolAbrege:\n",
    "        motAttributs[\"ABnbsyll\"]=\"\"\n",
    "        motAttributs[\"ABphon\"]=\"\"\n",
    "    result=E.motBDL(graphie,motAttributs)\n",
    "#    print etree.tostring(result,encoding=\"utf8\")\n",
    "#    print (cat,ms,vs,phono,mot)\n",
    "#    u'<mot cat=\"%s\" ms=\"%s\" vs=\"%s\" phon=\"%s\">%s</mot>' % (cat,ms,vs,phono,mot)\n",
    "    return result\n",
    "    \n",
    "def enchasseXML(mot, phono):\n",
    "    if isinstance(phono,str):\n",
    "        phono=phono.decode(\"utf8\")\n",
    "    result=E.motBDL(mot,{\"phon\":phono})\n",
    "#    u'<mot phon=\"%s\">%s</mot>' % (phono, mot)\n",
    "    return result\n",
    "\n",
    "def enchasseTour(phrase):\n",
    "    result=E.tour(phrase,{\"id\":\"%06d\"%nPhrase})\n",
    "    return result\n",
    "\n",
    "def enchasseNonMot(nonmot):\n",
    "    result=E.punct(nonmot)\n",
    "#    u'<punct>%s</punct>' % (nonmot)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitementTRS(rootTRS):\n",
    "    a=1\n",
    "    nPhrase=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        phrase=ligne.strip()\n",
    "        api=E.tour()\n",
    "        mot_numero=0\n",
    "        element_numero=0\n",
    "        while elementsPhrases[nPhrase] and element_numero < len(elementsPhrases[nPhrase]):\n",
    "            if not mot_numero < len(motsPhrases[nPhrase]) or motsPhrases[nPhrase][mot_numero]!=elementsPhrases[nPhrase][element_numero].lower():\n",
    "                api.append(enchasseNonMot(elementsPhrases[nPhrase][element_numero]))\n",
    "            elif liaison_possible(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                if liaison_obligatoire(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    api.append(enchasseBDLexique(nPhrase,mot_numero,True))\n",
    "                elif liaison_facultative(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    if facultatives:\n",
    "                        api.append(enchasseBDLexique(nPhrase,mot_numero,True))\n",
    "                    else :\n",
    "                        api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                else:\n",
    "                    api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero+=1\n",
    "            else:\n",
    "                api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero = mot_numero+1\n",
    "            element_numero+=1\n",
    "        a=a+1\n",
    "        if phrase!=\"\":\n",
    "            phraseConnecteurs=set()\n",
    "            for connecteur in connecteurs:\n",
    "                if \" \" in connecteur:\n",
    "                    connecteurParties=connecteur.split(\" \")\n",
    "                else:\n",
    "                    connecteurParties=[connecteur]\n",
    "                for i in range(len(elementsPhrases[nPhrase])-len(connecteurParties)+1):\n",
    "                    if connecteurParties==elementsPhrases[nPhrase][i:i+len(connecteurParties)]:\n",
    "                        phraseConnecteurs.add(connecteur)\n",
    "            if phraseConnecteurs:\n",
    "#                print phraseConnecteurs\n",
    "                api.set(\"connecteurs\",\",\".join(phraseConnecteurs))\n",
    "            api.set(\"nbmots\",str(len(api.xpath(\"//tour/motBDL\"))))\n",
    "            api.set(\"id\",\"%06d\"%nPhrase)\n",
    "            noeudAttachement=ligne.getparent()\n",
    "            if noeudAttachement.text==None:\n",
    "                noeudAttachement.tail=None\n",
    "                noeudAttachement.addnext(api)\n",
    "            else:\n",
    "                noeudAttachement.text=None\n",
    "                try:\n",
    "                    noeudAttachement.append(api)\n",
    "                except TypeError:\n",
    "                    print phrase, noeudAttachement\n",
    "                    noeudAttachement.append(api)\n",
    "        else:\n",
    "            ligne.getparent().tail=None\n",
    "        nPhrase+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- Insertion d'un set sur les nouvellesExceptions pour éviter les entrées multiples\n",
    "- Ajout d'un test pour vérifier que les nouvellesExceptions sont nouvelles\n",
    "\n",
    "#TO DO\n",
    "- Ajouter un message pour dire que le résultat a été concaténé au fichier existant si c'est le cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraireMotsTRS(motsCorpus,phon):\n",
    "    for entry in bdlexique:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(u';')\n",
    "        if p[0].lower() in motsCorpus:\n",
    "            if p[2]==\"@\" and not p[3] in [\"N\",\"V\",\"J\",\"K\"]:\n",
    "                p[1]+=p[2]\n",
    "                p[2]=\"\"\n",
    "                if len(p)<7:\n",
    "                    for i in range(len(p)+1,7):\n",
    "                        p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8],p[9])\n",
    "    return phon\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if fichier_exceptions:\n",
    "    for entry in inconnus:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(\";\")\n",
    "        if len(p[1])!=0:\n",
    "            if len(p)<9:\n",
    "                for i in range(len(p)+1,7):\n",
    "                    p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "        oldExceptions.append(p[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2.b. mettre les phrases phonémisées dans un fichier\n",
    "enteteXML=[\n",
    "            u'<?xml version=\"1.0\" encoding=\"UTF8\" standalone=\"yes\"?>',\n",
    "            u'<?xml-stylesheet type=\"text/xsl\" href=\"phonemise-TRS.xsl\"?>',\n",
    "            u'<!DOCTYPE Trans SYSTEM \"trans-14-corpus.dtd\">'\n",
    "          ]\n",
    "\n",
    "#print [etree.tostring(rootTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\")]\n",
    "motsAbreges={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiretsTRS(contenuTRS):\n",
    "    sortie=[]\n",
    "    for ligne in contenuTRS:\n",
    "        m=re.search(ur'Event desc=\"-(\\w+)\" .* extent=\"(\\w+)\"',ligne)\n",
    "        if m:\n",
    "            ligne=ligne.replace('desc=\"-%s\"'%m.group(1),'desc=\"%s\"'%m.group(1)).replace('extent=\"%s\"'%m.group(2),'extent=\"end\"')\n",
    "        m=re.search(ur'Event desc=\"(\\w+)-\" .* extent=\"(\\w+)\"',ligne)\n",
    "        if m:\n",
    "            ligne=ligne.replace('desc=\"%s-\"'%m.group(1),'desc=\"%s\"'%m.group(1)).replace('extent=\"%s\"'%m.group(2),'extent=\"begin\"')\n",
    "        sortie.append(ligne)\n",
    "    return sortie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baliserTRS(nomTRS):\n",
    "    with open(nomTRS,\"r\") as temp:\n",
    "        header= temp.readlines()[0]\n",
    "        s=re.search(ur'encoding=\"(.+)\"',header)\n",
    "        if s:\n",
    "            TRS=codecs.open(nomTRS,\"r\",encoding=s.group(1)).readlines()\n",
    "        else:\n",
    "            TRS=open(nomTRS,\"r\").readlines()\n",
    "    sortie=\"\"\n",
    "    fins=[]\n",
    "    debs=[]\n",
    "    TRS=tiretsTRS(TRS)\n",
    "    for numLigne,ligne in enumerate(TRS[2:]):\n",
    "        ligne=ligne.strip()\n",
    "        if 0<=numLigne <=10:\n",
    "            print ligne\n",
    "        disfluenceGen=re.match('<Event desc=\"disflu\" type=\"(noise|lexical|pronounce|language|entities)\" extent=\"(begin|end)\"/>',ligne)\n",
    "        disfluenceSpec=re.match('<Event desc=\"([Mm]d|[Rr]ep|[Aa]uto[Cc]|[Nn]on[Ff]inie|[Mm][Cc]oup)\" type=\"pronounce\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        eventAutre=re.match('<Event desc=\"([^\"]+)\" type=\"([^\"]+)\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        tagTurn=re.match('<(/?)Turn.*>',ligne)        \n",
    "        if disfluenceGen:\n",
    "            if debug: print \"disfluGen\",disfluenceGen.group(2)\n",
    "            if disfluenceGen.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceGen.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceGen.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif disfluenceSpec:\n",
    "            if debug: print \"disfluSpec\",disfluenceSpec.group(2)\n",
    "            if disfluenceSpec.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceSpec.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceSpec.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif eventAutre:\n",
    "            if debug: print \"Autre\",eventAutre.group(3)\n",
    "            descEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(1)])\n",
    "            typeEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(2)])\n",
    "            if eventAutre.group(3)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<%s desc=\"%s\">'%(typeEvent,descEvent)+\"\\n\")\n",
    "                fins.append(\"</%s>\"%typeEvent)\n",
    "            elif eventAutre.group(3)==\"end\":\n",
    "#                print numLigne\n",
    "                if fins:\n",
    "                    sortie+=(\"</%s>\"%typeEvent+\"\\n\")\n",
    "                    chaine=fins.pop()\n",
    "                else:\n",
    "                    print \"PB no stack to pop\", typeEvent,numLigne\n",
    "                if chaine!=\"</%s>\"%typeEvent:\n",
    "                    print \"PB\",chaine, typeEvent,numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif tagTurn:\n",
    "            if debug: print tagTurn.group(1)+\"Turn\"\n",
    "            if tagTurn.group(1)==\"/\" and fins:\n",
    "                lenFins=len(fins)\n",
    "                for num in range(lenFins):\n",
    "                    chaine=fins.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    debs.append(chaine.replace(\"/\",\"\"))\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "            if tagTurn.group(1)==\"\" and debs:\n",
    "                lenDebs=len(debs)\n",
    "                for num in range(lenDebs):\n",
    "                    chaine=debs.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    fins.append(chaine.replace(\"<\",\"</\"))\n",
    "        else:\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "        if debug and (debs or fins):\n",
    "            print debs, fins\n",
    "    return sortie"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dossiersTRS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "paires={num:el for num,el in enumerate(listeDossiersTRS)}\n",
    "for paire in paires:\n",
    "    print paire,paires[paire]\n",
    "#debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/\n",
      "['/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio1_WAKZ.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio2_LRB.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio4_DOVAKHING.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio3_SKTvsMisfits.trs']\n",
      "fichier Exception /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/inconnus.txt\n",
      "\n",
      "0 0 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio1_WAKZ.trs\n",
      "<Trans scribe=\"Carine\" audio_filename=\"wow-une-game-vraiment-compliquee-xayah-adc-ranked-challenger\" version=\"10\" version_date=\"171214\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Youtubeur WAKZ\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"1040.184\">\n",
      "<Turn startTime=\"0\" endTime=\"8.287\" speaker=\"spk1\" fidelity=\"high\">\n",
      "<Sync time=\"0\"/>\n",
      "et à vous les potes on est partis dans une super partie et celle-ci va être extrêmement dure encore plus que toutes les\n",
      "<Event desc=\"en\" type=\"language\" extent=\"begin\"/>\n",
      "games\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio1_WAKZ-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio1_WAKZ-BDL2.trs\n",
      "0 1 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio2_LRB.trs\n",
      "<Trans scribe=\"Carine\" audio_filename=\"LE ROI BISOU (1)\" version=\"13\" version_date=\"171214\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Le Roi Bisou Youtubeur\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"1651.619\">\n",
      "<Turn startTime=\"0\" endTime=\"0.148\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "<Turn speaker=\"spk1\" startTime=\"0.148\" endTime=\"0.635\" fidelity=\"high\">\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio2_LRB-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio2_LRB-BDL2.trs\n",
      "0 2 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio4_DOVAKHING.trs\n",
      "<Trans scribe=\"phili_000\" audio_filename=\"TOURNOI - CLASH\" version=\"5\" version_date=\"171214\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"commentateur 1\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"commentateur 2\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk4\" name=\"7\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk5\" name=\"4\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk6\" name=\"*\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"1599.843\">\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio4_DOVAKHING-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio4_DOVAKHING-BDL2.trs\n",
      "0 3 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio3_SKTvsMisfits.trs\n",
      "<Trans scribe=\"Jean\" audio_filename=\"Preshow - SKT T1 vs Misfits - World Championship 2017 - 14 de finale - League of Legends\" version=\"33\" version_date=\"171214\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Bulii\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk2\" name=\"Zaboutine\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk3\" name=\"Noi\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk4\" name=\"speaker#4\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"1437.466\">\n",
      "<Turn startTime=\"0\" endTime=\"33.68\">\n",
      "<Sync time=\"0\"/>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio3_SKTvsMisfits-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/Audio3_SKTvsMisfits-BDL2.trs\n",
      "fichierExceptions /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Fournioux/inconnus.txt\n",
      "am\n"
     ]
    }
   ],
   "source": [
    "oldExceptions=[]\n",
    "for numDossier,dossier in enumerate(listeDossiersTRS):\n",
    "    if numDossier in numDossiers:\n",
    "        print numDossier, dossier\n",
    "        fichiersTRS=glob.glob(dossier+\"/*.trs\")\n",
    "        print fichiersTRS\n",
    "        fichiersTRS=[f for f in fichiersTRS if not f.endswith(\"-BDL2.trs\")]\n",
    "        fichierExceptions=dossiersTRS[dossier]\n",
    "        print \"fichier Exception\",fichierExceptions\n",
    "        print\n",
    "        nouvellesExceptions=[]\n",
    "        boolExceptions=True\n",
    "        try:\n",
    "    #        print fichierExceptions\n",
    "            exceptions=codecs.open(fichierExceptions,\"r\",encoding='utf8')\n",
    "            inconnus=exceptions.readlines()\n",
    "            exceptions.close()\n",
    "    #        print inconnus\n",
    "        except IOError:\n",
    "            boolExceptions=False\n",
    "        if fichier_exceptions and boolExceptions:\n",
    "            oldExceptions=[]\n",
    "            for entry in inconnus:\n",
    "                entry=entry.strip()\n",
    "                if 0: print entry\n",
    "                p=entry.split(\";\")\n",
    "                if len(p)<9:\n",
    "                    for i in range(len(p)+1,10):\n",
    "                        p.append(u\"\")\n",
    "                if 0: print p\n",
    "                if len(p[1])!=0:\n",
    "                    phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "                oldExceptions.append(p[0].lower())\n",
    "        for numTRS,nomTRS in enumerate(fichiersTRS):\n",
    "            print numDossier,numTRS,nomTRS\n",
    "            fichierBDL=nomTRS[:-4]+\"-BDL2.xml\"\n",
    "            if nomTRS.split(\"/\")[-1] in sansRebalisageFichiers:\n",
    "                print \"SANS reBALISER\"\n",
    "                xmlTRS=etree.parse(nomTRS,parser)\n",
    "                print \"FIN parse\"\n",
    "            else:\n",
    "                fichierTRS=baliserTRS(nomTRS)\n",
    "                print \"FIN reBALISER\"\n",
    "                xmlTRS=etree.fromstring(fichierTRS,parser)\n",
    "                print \"FIN fromstring\"\n",
    "            (motsCorpus,motsPhrases,elementsPhrases)=listerMotsCorpus(xmlTRS)\n",
    "            print \"FIN lister mots\"\n",
    "            phon=extraireMotsTRS(motsCorpus,phon)\n",
    "            print \"FIN extraire mots\"\n",
    "            traitementTRS(xmlTRS)\n",
    "            print \"FIN traitement\"\n",
    "            with codecs.open(fichierBDL, \"w\", encoding='utf8') as f:\n",
    "                for ligne in enteteXML:\n",
    "                    f.write(ligne+u\"\\n\")\n",
    "                f.write(etree.tostring(xmlTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\"))\n",
    "            cliBDL=fichierBDL.replace(\" \",\"\\ \")\n",
    "            cliXSLT=fichierXSLT.replace(\" \",\"\\ \")\n",
    "            cliPhonTRS=fichierBDL.replace(\".xml\",\".trs\").replace(\" \",\"\\ \")\n",
    "            cliText=\"xsltproc %s %s > %s\"%(cliXSLT,cliBDL,cliPhonTRS)\n",
    "            print cliText\n",
    "            os.system(cliText)  \n",
    "        with codecs.open(fichierExceptions, \"a\", encoding='utf8') as f:\n",
    "            print \"fichierExceptions\",fichierExceptions\n",
    "            for n in set(nouvellesExceptions):\n",
    "                print n,\n",
    "                if not (n in oldExceptions): \n",
    "                    f.write(n+u\";;;;;;;;;;;;\")\n",
    "                    f.write(\"\\n\")\n",
    "            print\n",
    "        oldExceptions=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPremierDossier=10\n",
    "numDernierDossier=0\n",
    "if numDernierDossier<numPremierDossier or numDernierDossier==0:\n",
    "    numDernierDossier=100\n",
    "elif numDernierDossier==numPremierDossier:\n",
    "    numDernierDossier+=1\n",
    "numDossiers=range(numPremierDossier,numDernierDossier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problèmes de noms de fichiers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fichierPbs={}\n",
    "for numDossier,dossier in enumerate(glob.glob(dossierCorpus+\"*/\")):\n",
    "    fichierPbs[numDossier]=glob.glob(dossier+\"*'*.trs\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for fichier in fichierPbs[30]:\n",
    "    mPar=re.findall(ur\"\\([^)]+\\)\",fichier.split(\"/\")[-1])\n",
    "    oldString=mPar[0]\n",
    "    newString=mPar[0][1:-1]\n",
    "    newName=fichier.replace(oldString,newString).replace(\".trs\",\"-PBdeNOM.trs\")\n",
    "    if os.path.isfile(newName):\n",
    "        print \"PB fichier existant\",fichier,newName\n",
    "    else:\n",
    "        os.rename(fichier,newName)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for fichier in fichierPbs[26]:\n",
    "    newName=fichier.replace(\"'\",\" \").replace(\".trs\",\"-PBdeNOM.trs\")\n",
    "    if os.path.isfile(newName):\n",
    "        print \"PB fichier existant\",fichier,newName\n",
    "    else:\n",
    "        os.rename(fichier,newName)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fichierPbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
