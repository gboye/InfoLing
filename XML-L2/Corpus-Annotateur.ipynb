{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement de XML pour ajouter les informations de BDLexique et des annotations TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier d'entrée est un TEXTE annoté avec TreeTagger. Le fichier doit avoir l'extention .TT. Ensuite il est transformer en XML (racine: Document, balise: Turn) et les informations de TreeTagger et BDLexique sont balisées.\n",
    "Le script a besoin de BDLexique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import codecs\n",
    "import re\n",
    "import pdb # ajouter pdb.set_trace() à l'endroit où on veut le débugueur\n",
    "from lxml import etree\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os, fnmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous voulez que le texte garde l'orthographe initiale (par défaut, le texte est mis en minuscule), spécifiez ici: lowercase = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "debug=False\n",
    "lowercase = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS À FAIRE :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS FAITES :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. ajouter un #id aux tours et aux mots => **22/12/15**\n",
    "1. gérer les parenthèses => **22/12/15**\n",
    "  - les troncations\n",
    "    - version longue pour BDLexique\n",
    "    - version courte pour la transcription\n",
    "  - les champs supplémentaires\n",
    "    - mot => nbsyllabes à saisir\n",
    "    - tour => raccourci\n",
    "1. gérer les balises Event auto-fermantes => **23/12/15**\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'environnement pour le script\n",
    "- *dossierCorpus* doit être le **répertoire** où se trouvent vos fichiers .TT (devrait finir par un /)\n",
    "- *fichierLexique* doit être le nom du fichier BDLEXIQUE\n",
    "- *fichierExceptions* doit être le nom de votre fichier INCONNUS (s'il existe déjà ou non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connecteurs=[\n",
    "    u\"et\", u\"alors\", u\"du coup\", u\"sinon\", u\"par contre\", u\"ça veut dire\", u\"enfin\",\n",
    "u\"après\", u\"donc\", u\"puisque\", u\"puisqu'\", u\"en fait\", u\"mais\", u\"parce que\", u\"parce qu'\", u\"même si\" , u\"d'abord\", u\"et puis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Users/ania/Documents/BdLife/M1-Tools4NLP/Outils_2016-17/CM4/\n"
     ]
    }
   ],
   "source": [
    "dossierCorpus=\"/Users/ania/Documents/BdLife/M1-Tools4NLP/Outils_2016-17/CM4/\"\n",
    "dossiersHorsCorpus=[\"Ponctuation\", \"Transcription Phonétique\",\"Exemple transcription pour cours d'informatique\"]\n",
    "dossiersSpeciaux=[]\n",
    "dossiersRestants=[]\n",
    "sansRebalisageFichiers=[\n",
    "    \"6 - L'amour à la plage.trs\",\n",
    "    \"7 - Les Mostaganems de saluent.trs\"\n",
    "]\n",
    "dossiersTRS={}\n",
    "inconnusTRS={}\n",
    "for root, dirs, files in os.walk(dossierCorpus):\n",
    "    if \"Corpus 2015-2016/\" in dossierCorpus:\n",
    "        dossierGroupe=root.split(\"Corpus 2015-2016/\")[1].split(\"/\")[0]\n",
    "        if not dossierGroupe in dossiersHorsCorpus+dossiersSpeciaux and dossierGroupe in dossiersRestants:\n",
    "            trs=fnmatch.filter(files, \"*.TT\") #.trs\n",
    "            if trs:\n",
    "                dossiersTRS[root]=dossierGroupe\n",
    "            inconnus=fnmatch.filter(files, \"*-inconnus.txt\")\n",
    "            if inconnus:\n",
    "                inconnusTRS[dossierGroupe]=root+\"/\"+inconnus[0]\n",
    "        else:\n",
    "            print \"dossier évité :\",dossierGroupe\n",
    "    else:\n",
    "        dossiersTRS[dossierCorpus]=dossierCorpus+\"inconnus.txt\"\n",
    "        \n",
    "for element in dossiersTRS:\n",
    "    if dossiersTRS[element] in inconnusTRS:\n",
    "        dossiersTRS[element]=inconnusTRS[dossiersTRS[element]]\n",
    "    else:\n",
    "        dossiersTRS[element]=element+\"/inconnus.txt\"\n",
    "if 0:\n",
    "    print \"INC\"\n",
    "    for element in sorted(dossiersTRS):\n",
    "        print element\n",
    "        print dossiersTRS[element]\n",
    "        print\n",
    "listeDossiersTRS=sorted(dossiersTRS.keys())\n",
    "for num,element in enumerate(listeDossiersTRS):\n",
    "    print num, element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPremierDossier=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fichierLexique=\"/Users/ania/Documents/BdLife/M1-Tools4NLP/Outils_2016-17/CM5/phonemizer/bdlexique.txt\"\n",
    "fichier_exceptions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voyelles=u\"ieɛayøœəuoɔɑɛ̃ɔ̃ɑ̃\"\n",
    "voyelles=u\"ieEay296@uoOòèâêûô\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous n'avez pas de fichier *inconnus.txt* \n",
    ">mettez *fichier_exceptions=False* au dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- mise en texte des deux blocs de traitement de la ligne de commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicon=codecs.open(fichierLexique,\"r\",encoding='utf8')\n",
    "bdlexique=lexicon.readlines()\n",
    "lexicon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facultatives = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phon={}\n",
    "result=[]\n",
    "nouvellesExceptions = []\n",
    "output=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "ajouter chaque ligne du fichier à phrases[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lowerAccents(chaine):\n",
    "    return chaine.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser le mot en cours\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ la ponctuation est remplacée par un espace\n",
    "+ les espaces aux extrémités sont effacés\n",
    "+ le mot est mis en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trimer(mot):\n",
    "    if lowercase == True:\n",
    "        mot=lowerAccents(mot) \n",
    "    for p in u',;.:?!“”‘’‛‟′″´˝\"«»_':   # Pas de remplacement de souscrit mais ajouter _\n",
    "        mot=mot.replace(p, ' ')\n",
    "    mot=mot.strip()\n",
    "    return mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def listerMotsCorpus(rootTRS):\n",
    "    #phrases=[]\n",
    "    motsPhrases=[]\n",
    "    elementsPhrases=[]\n",
    "    motsCorpus=set()\n",
    "    nPhrases=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        line=ligne.strip()\n",
    "        line_clean = [] #AK: Modif wrt TreeTagger format\n",
    "        words = line.split(\"\\n\")\n",
    "        for word in words:\n",
    "            w = word.split(\"\\t\")\n",
    "            if len(w[0].strip(\".\")) > 0:\n",
    "                line_clean.append(w[0].strip(\".\")) # AK: trimer pour décalage M. vs M .\n",
    "            else:\n",
    "                line_clean.append(w[0])\n",
    "        if 0: print [line]\n",
    "        lineC = \" \".join(line_clean)\n",
    "        elements = line_clean\n",
    "        mots=[x for x in elements if not x in u\"-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~:\" and not x in [u\"--\",u\" ;\",u\" !\",u\" ?\",u\" :\"]]\n",
    "        elements=[x for x in elements if x!=u\" \"]\n",
    "        elementsPhrases.append(elements)\n",
    "        phrasePropre = u\"\"\n",
    "        for mot in mots:\n",
    "            mot = trimer(mot)\n",
    "            phrasePropre += mot+u\" \"\n",
    "            m=re.search(ur\"\\(.*\\)\",mot)\n",
    "            forme=mot\n",
    "            graphie=mot\n",
    "            if m :\n",
    "                forme=re.sub(ur\"\\((.*)\\)\",\"\\g<1>\", mot)\n",
    "                graphie=re.sub(ur\"\\(([\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?)\\)\",\"'\", mot)\n",
    "                motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}    \n",
    "            motsCorpus.add(forme)\n",
    "        print(phrasePropre)\n",
    "        phraseMots = phrasePropre.split()        \n",
    "        motsPhrases.append(phraseMots)\n",
    "        nPhrases+=1\n",
    "    return (motsCorpus,motsPhrases,elementsPhrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire de BDLex 0.forme fléchie, 1.phonétique, 2.liaison, 3.cat-gram, 4.genre+nombre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire du fichier d'exceptions les mêmes données que pour BDLex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- fait une liste des exceptions lues pour ne pas les rajouter à la fin\n",
    "- éviter de tenir compte des exceptions non renseignées\n",
    " - les mots du fichier exceptions sans transcriptions étaient transcrits par une chaine vide..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier si le mot existe\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ si le mot est dans BDLex, ok\n",
    "+ s'il y a un espace dans le mot,\n",
    "    * le mot est divisé en deux et\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ s'il y a un apostrophe dans le mot,\n",
    "    * le mot est divisé en deux\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ dans les autres cas, le mot est ajouté aux nouvelles exceptions et mis entre étoiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def verifier_mot(mot):\n",
    "        sampa=\"\"\n",
    "        if mot in phon.keys():\n",
    "            sampa += phon[mot][0]\n",
    "        elif \" \" in mot:\n",
    "            mots = mot.split()\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif \"'\" in mot:\n",
    "            mots = mot.split(\"'\")\n",
    "            mots[0]=mots[0]+\"'\"\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif mot != \"\": \n",
    "            nouvellesExceptions.append(mot)\n",
    "            sampa=\"***\"+mot+\"*** \"\n",
    "        return sampa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. traduire le SAMPA de BDLexique en API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- ajout du r et du â\n",
    "- ajout des exemples associés en dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# traduire SAMPA-BDLex en API\n",
    "\n",
    "def sampa2api(sampa):\n",
    "    if isinstance(sampa,str):\n",
    "        api=sampa.decode(\"utf8\")\n",
    "    else:\n",
    "        api=sampa\n",
    "    api=api.replace(u'S',u'ʃ') \n",
    "    api=api.replace(u'Z',u'ʒ')\n",
    "    api=api.replace(u'N',u'ŋ')\n",
    "    api=api.replace(u'J',u'ɲ')\n",
    "    api=api.replace(u'r',u'ʁ') \n",
    "    api=api.replace(u'H',u'ɥ')\n",
    "    api=api.replace(u'E',u'ɛ')\n",
    "    api=api.replace(u'2',u'ø')\n",
    "    api=api.replace(u'9',u'œ')\n",
    "    api=api.replace(u'6',u'ə')\n",
    "    api=api.replace(u'O',u'ɔ')\n",
    "    api=api.replace(u'è',u'e')   \n",
    "    api=api.replace(u'ò',u'o')    \n",
    "    api=api.replace(u'â',u'ɑ̃')   \n",
    "    api=api.replace(u'ê',u'ɛ̃')   \n",
    "    api=api.replace(u'û',u'œ̃')  \n",
    "    api=api.replace(u'ô',u'ɔ̃')       \n",
    "    api=api.replace(u'@',u'ə')\n",
    "    api=api.replace(u'n\"',u'n') \n",
    "    api=api.replace(u't\"',u't') \n",
    "    api=api.replace(u'z\"',u'z') \n",
    "    api=api.replace(u'R\"',u'ʁ') \n",
    "    api=api.replace(u'p\"',u'p') \n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Vérifier si la liaison est possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant ne sont pas dans lexicon, pas de liaison\n",
    "+ si le mot a une consonne dans le champ de la voyelle de liaison, check1 est vrai\n",
    "+ si le mot suivant commence par une voyelle, check2 est vrai\n",
    "\n",
    "  si check1 et check2 sont vrais, il y a liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def liaison_possible(phrase ,mot , mot_numero):\n",
    "    check1=0\n",
    "    check2=0\n",
    "    if mot in phon and len(phrase)>mot_numero+1 and phrase[mot_numero+1] in phon:\n",
    "        consonnes=['k\"', '(kt)\"', 'n\"', 'p\"', 'R\"', '@t\"', 't\"', '-V', '+V', '@z\"', 'z\"']\n",
    "        phoneme=phon[mot][2]\n",
    "        for phoneme in consonnes:\n",
    "            check1=1\n",
    "        \n",
    "        voyelles=[\"H\", \"j\", \"w\", \"E\", \"a\", \"2\", \"9\", \"6\", \"@\", \"y\", \"u\", \"O\", u\"ò\", \"o\", \"e\", u\"è\", u\"ê\", u\"û\", u\"ô\", \"i\"]\n",
    "        mot_suivant=phon[phrase[mot_numero+1]][1]\n",
    "        for v in voyelles:\n",
    "            if mot_suivant.startswith(v):\n",
    "                check2=1\n",
    "\n",
    "    if check1 and check2 :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. vérifier si la liaison est obligatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def liaison_obligatoire(phrase, mot, mot_numero):\n",
    "    determinant=[\"d\", \"P\"]\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    pronompers=[\"P\"]\n",
    "    verbe=[\"V\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "\n",
    "    if catgram_mot1 in determinant and catgram_mot2 in nom :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in determinant and catgram_mot2 in adjectif :\n",
    "        return True\n",
    " \n",
    "    elif catgram_mot1 in pronompers and catgram_mot2 in verbe :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in verbe and catgram_mot2 in pronompers :\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles:\n",
    "\n",
    "- DET + N\n",
    "    * ri + N:   d'animal, \n",
    "    * di + N:   certains éléphants\n",
    "    * rd + N:   les animaux\n",
    "    * dd + N:   ces étés, cet été\n",
    "    * dp + N:   ton anorak\n",
    "    * rc + N:   aux armes\n",
    "- DET + ADJ:\n",
    "    * ri + ADJ:   d'énormes\n",
    "    * di + ADJ:   plusieurs immenses\n",
    "    * rd + ADJ:   les immenses\n",
    "    * dd + ADJ:   cet immense\n",
    "    * dp + ADJ:   son immense\n",
    "    * rc + ADJ:   aux immenses\n",
    "- PERS + V:\n",
    "    * SS + V:   m'épate\n",
    "- V + PRO PERS: \n",
    "    * V + SS:   vont-ils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vérifier si la liaison est facultative\n",
    "def liaison_facultative(phrase, mot, mot_numero):\n",
    "    #pdb.set_trace()\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    pluriel=[\"MP\", \"FP\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    verbe=[\"V\"]\n",
    "    pronompers=[\"P\"]\n",
    "    adverbe=[\"A\"]\n",
    "    preposition=[\"p\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "    genre_mot1=phon[phrase[mot_numero]][4]\n",
    "    \n",
    "    if (catgram_mot1 in nom) and (phon[phrase[mot_numero]][4] in pluriel) and (catgram_mot2 in adjectif) : \n",
    "        return True\n",
    "\n",
    "    elif (catgram_mot1 in verbe) and (catgram_mot2 not in pronompers):\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in adverbe :\n",
    "        return True\n",
    "    \n",
    "    elif catgram_mot1 in preposition : \n",
    "        return True\n",
    "\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles :\n",
    "\n",
    "- N pl + ADJ: \n",
    "    * N + ADJ: monstres énormes \n",
    "    * G + ADJ: rivaux énormes\n",
    "- VERBE + TOUT-SAUF-PRO-PERS:\n",
    "    * V + N sont éléphants\n",
    "    * V + G sommes abdicaires\n",
    "    * V + V sommes assis\n",
    "    * V + A sommes admirablement\n",
    "    * V + p sommes autour de\n",
    "    * V + di ont aucune\n",
    "    * V + rc sommes au\n",
    "- ADV + QQCH:\n",
    "    * ADV + N vraiment abruti\n",
    "    * ADV + G vraiment abandonné\n",
    "    * ADV + V vraiment aimé\n",
    "    * ADV + J vraiment étonnant\n",
    "    * ADV + ss vraiment ils\n",
    "    * ADV + A vraiment étonnamment\n",
    "    * ADV + p vraiment attendu\n",
    "    * ADV + di vraiment autre \n",
    "    * ADV + rc vraiment au\n",
    "- PREP + QQCH:\n",
    "    * PREP + N très amoureux\n",
    "    * PREP + G très abandonné\n",
    "    * PREP + V très aimé\n",
    "    * PREP + J très étonnant\n",
    "    * PREP + SS très ils\n",
    "    * PREP + A très étonnamment\n",
    "    * PREP + p très attendu\n",
    "    * PREP + di très autre\n",
    "    * PREP + rc très au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Partie 1\n",
    "*chaque phrase est prise individuellement,\n",
    "    * découpée en blocs,\n",
    "        * qui sont chacuns trimés si ce sont des mots\n",
    "        * s'il y a plusieurs mots dans le bloc, ils sont séparés\n",
    "    + Partie 2\n",
    "    * pour chaque couple de mots\n",
    "        * si la liaison est possible,\n",
    "            * et qu'elle est obligatoire, l'api avec la liaison est généré\n",
    "            * et qu'elle est facultative,\n",
    "                * si l'utilisateur l'a choisi, l'api avec la liaison est généré\n",
    "                * sinon l'api sans la liaison est généré\n",
    "\n",
    "        + Partie 3\n",
    "        * si la liaison n'est pas possible,\n",
    "            * si le mot est dans bdlex, l'api est généré\n",
    "            * sinon le mot est laissé tel quel (il a déjà les étoiles)        \n",
    "\n",
    "    * pour le dernier mot de la phrase, \n",
    "        * si le mot est dans bdlex, l'api est généré\n",
    "        * sinon le mot est laissé tel quel (il a déjà les étoiles) \n",
    "\n",
    "+ Partie 4\n",
    "* le message à l'utilisateur et la phrase en api est imprimée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- suppression du délai dans la boucle\n",
    " - pour 1500 lignes => 3 secondes sans ralentisseur, 1503 secondes avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml.builder import E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compterVoyelles(chaine):\n",
    "    result=0\n",
    "    for element in chaine:\n",
    "        if element in voyelles:\n",
    "            result+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Début de l'enchassement en XML (7/12/15)\n",
    "- récupérer la ponctuation et les sauts de lignes pour rendre le texte lisible\n",
    "- ajouter le reste des informations du lexique dans la balise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def enchasseBDLexique(nphrase,nmot,liaison=False):\n",
    "    boolAbrege=False\n",
    "    motTRS=motsPhrases[nphrase][nmot]\n",
    "    if motTRS in motsAbreges:\n",
    "        mot=motsAbreges[motTRS][\"lexical\"]\n",
    "        graphie=motsAbreges[motTRS][\"graphie\"]\n",
    "        boolAbrege=True\n",
    "    else:\n",
    "        mot=motTRS\n",
    "        graphie=motTRS\n",
    "    if mot in phon: \n",
    "        phono=sampa2api(phon[mot][1])\n",
    "        if liaison:\n",
    "            phono+=sampa2api(phon[mot][2])\n",
    "        cat=phon[mot][3]\n",
    "        if cat in [u\"J\",u\"K\"]:\n",
    "            cat=u\"Adj\"\n",
    "        ms=phon[mot][4]\n",
    "        vs=phon[mot][5]\n",
    "        lexeme=phon[mot][6].upper()\n",
    "        freq=phon[mot][8]\n",
    "        nbVoyelles=str(compterVoyelles(phon[mot][1]))\n",
    "        if u\" \" in vs:\n",
    "            vs=u\"\"\n",
    "    else:\n",
    "        phono=verifier_mot(mot)[:-1]\n",
    "        cat=u\"???\"\n",
    "        ms=\"\"\n",
    "        vs=\"\"\n",
    "        lexeme=\"???\"\n",
    "        freq=\"\"\n",
    "        nbVoyelles=\"\"\n",
    "    motAttributs={\"BDLcat\":cat,\"ms\":ms,\"vs\":vs,\"phon\":phono,\"nbsyll\":nbVoyelles, \"BDLlexeme\":lexeme, \"freq\":freq, \"id\":\"%05d%03d\"%(nphrase,nmot)}\n",
    "    if boolAbrege:\n",
    "        motAttributs[\"ABnbsyll\"]=\"\"\n",
    "        motAttributs[\"ABphon\"]=\"\"\n",
    "    result=E.mot(graphie,motAttributs)\n",
    "    return result\n",
    "    \n",
    "def enchasseXML(mot, phono):\n",
    "    if isinstance(phono,str):\n",
    "        phono=phono.decode(\"utf8\")\n",
    "    result=E.mot(mot,{\"phon\":phono})\n",
    "    return result\n",
    "\n",
    "def enchasseTour(phrase):\n",
    "    result=E.tour(phrase,{\"id\":\"%06d\"%nPhrase})\n",
    "    return result\n",
    "\n",
    "def enchasseNonMot(nonmot):\n",
    "    result=E.punct(nonmot)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addTTTags(list_lemm, list_tag, eltX, numero):\n",
    "    if list_lemm != [] and list_tag != []:\n",
    "        eltX.attrib[\"TTlexeme\"] = list_lemm[numero].upper()\n",
    "        if len(list_tag[numero].split(\":\")) > 1:\n",
    "            eltX.attrib[\"TTcat\"] = list_tag[numero].split(\":\")[0]\n",
    "            eltX.attrib[\"TTtype\"] = list_tag[numero].split(\":\")[1].lower()\n",
    "        else:\n",
    "            eltX.attrib[\"TTcat\"] = list_tag[numero]\n",
    "            eltX.attrib[\"TTtype\"] = \"\"\n",
    "    else:\n",
    "        eltX.attrib[\"TTlexeme\"] = \"\"\n",
    "        eltX.attrib[\"TTcat\"] = \"\"\n",
    "        eltX.attrib[\"TTtype\"] = \"\"\n",
    "    return eltX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def traitementTRS(rootTRS):\n",
    "    a=1\n",
    "    nPhrase=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        phrase=ligne.strip() # strip the sequence\n",
    "        line_clean = [] # Modif wrt TreeTagger format\n",
    "        words = phrase.split(\"\\n\") # get individual TT-words: list of TT-words\n",
    "        tags = []\n",
    "        lemms = []\n",
    "        if words != ['']:\n",
    "            for word in words:\n",
    "                w = word.split(\"\\t\")\n",
    "                line_clean.append(w[0])\n",
    "                tags.append(w[1])\n",
    "                lemms.append(w[2])\n",
    "            phrase = \" \".join(line_clean) # list of raw words         \n",
    "        api=E.tour()\n",
    "        mot_numero=0\n",
    "        element_numero=0\n",
    "        while elementsPhrases[nPhrase] and element_numero < len(elementsPhrases[nPhrase]):\n",
    "            if lowercase == True:\n",
    "                elementsPhrases[nPhrase][element_numero] = elementsPhrases[nPhrase][element_numero].lower()\n",
    "            if not mot_numero < len(motsPhrases[nPhrase]) or motsPhrases[nPhrase][mot_numero]!=elementsPhrases[nPhrase][element_numero]: # .lower():\n",
    "                api.append(enchasseNonMot(elementsPhrases[nPhrase][element_numero]))\n",
    "            elif liaison_possible(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                if liaison_obligatoire(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    result = enchasseBDLexique(nPhrase,mot_numero,True)\n",
    "                    result = addTTTags(lemms, tags, result, element_numero)\n",
    "                    api.append(result) #enchasseBDLexique(nPhrase,mot_numero,True)\n",
    "                elif liaison_facultative(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    if facultatives:\n",
    "                        result = enchasseBDLexique(nPhrase,mot_numero,True)\n",
    "                        result = addTTTags(lemms, tags, result, element_numero)\n",
    "                        api.append(result) # enchasseBDLexique(nPhrase,mot_numero,True)\n",
    "                    else :\n",
    "                        result = enchasseBDLexique(nPhrase,mot_numero,True)\n",
    "                        result = addTTTags(lemms, tags, result,element_numero)\n",
    "                        api.append(result)\n",
    "                        # api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                else:\n",
    "                    result = enchasseBDLexique(nPhrase,mot_numero)\n",
    "                    result = addTTTags(lemms, tags, result, element_numero)\n",
    "                    api.append(result)\n",
    "                    # api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero+=1\n",
    "            else:\n",
    "                result = enchasseBDLexique(nPhrase,mot_numero)\n",
    "                result = addTTTags(lemms, tags, result, element_numero)\n",
    "                api.append(result)\n",
    "                # api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero = mot_numero+1\n",
    "            element_numero+=1\n",
    "        a=a+1\n",
    "        if phrase!=\"\":\n",
    "            phraseConnecteurs=set()\n",
    "            for connecteur in connecteurs:\n",
    "                if \" \" in connecteur:\n",
    "                    connecteurParties=connecteur.split(\" \")\n",
    "                else:\n",
    "                    connecteurParties=[connecteur]\n",
    "                for i in range(len(elementsPhrases[nPhrase])-len(connecteurParties)+1):\n",
    "                    if connecteurParties==elementsPhrases[nPhrase][i:i+len(connecteurParties)]:\n",
    "                        phraseConnecteurs.add(connecteur)\n",
    "            if phraseConnecteurs:\n",
    "#                print phraseConnecteurs\n",
    "                api.set(\"connecteurs\",\",\".join(phraseConnecteurs))\n",
    "            api.set(\"nbmots\",str(len(api.xpath(\"//tour/mot\"))))\n",
    "            api.set(\"id\",\"%06d\"%nPhrase)\n",
    "            noeudAttachement=ligne.getparent()\n",
    "            #print noeudAttachement\n",
    "            if noeudAttachement.text==None:\n",
    "                noeudAttachement.tail=None\n",
    "                noeudAttachement.addnext(api)\n",
    "            else:\n",
    "                noeudAttachement.text=None\n",
    "                try:\n",
    "                    noeudAttachement.append(api)\n",
    "                except TypeError:\n",
    "                    print phrase, noeudAttachement\n",
    "                    noeudAttachement.append(api)\n",
    "        else:\n",
    "            ligne.getparent().tail=None\n",
    "        nPhrase+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- Insertion d'un set sur les nouvellesExceptions pour éviter les entrées multiples\n",
    "- Ajout d'un test pour vérifier que les nouvellesExceptions sont nouvelles\n",
    "\n",
    "#TO DO\n",
    "- Ajouter un message pour dire que le résultat a été concaténé au fichier existant si c'est le cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extraireMotsTRS(motsCorpus,phon):\n",
    "    for entry in bdlexique:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(u';')\n",
    "        if lowercase == True:\n",
    "            p[0] = p[0].lower()\n",
    "        if p[0] in motsCorpus: \n",
    "            if p[2]==\"@\" and not p[3] in [\"N\",\"V\",\"J\",\"K\"]:\n",
    "                p[1]+=p[2]\n",
    "                p[2]=\"\"\n",
    "                if len(p)<7:\n",
    "                    for i in range(len(p)+1,7):\n",
    "                        p.append(\"\")\n",
    "            phon[p[0]]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8],p[9]) \n",
    "    return phon\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if fichier_exceptions:\n",
    "    oldExceptions=[]\n",
    "    for entry in inconnus:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(\";\")\n",
    "        if len(p[1])!=0:\n",
    "            if len(p)<9:\n",
    "                for i in range(len(p)+1,7):\n",
    "                    p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "        oldExceptions.append(p[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.2.b. mettre les phrases phonémisées dans un fichier\n",
    "enteteXML=[\n",
    "            u'<?xml version=\"1.0\" encoding=\"UTF8\" standalone=\"yes\"?>',\n",
    "            u'<?xml-stylesheet type=\"text/xsl\" href=\"phonemise-TRS.xsl\"?>',\n",
    "            u'<!DOCTYPE Trans SYSTEM \"trans-14-corpus.dtd\">'\n",
    "          ]\n",
    "\n",
    "#print [etree.tostring(rootTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\")]\n",
    "motsAbreges={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baliserTRS(nomTRS):\n",
    "    with open(nomTRS,\"r\") as temp:\n",
    "        header= temp.readlines()[0]\n",
    "        s=re.search(ur'encoding=\"(.+)\"',header)\n",
    "        if s:\n",
    "            TRS=codecs.open(nomTRS,\"r\",encoding=s.group(1)).readlines()\n",
    "        else:\n",
    "            TRS=open(nomTRS,\"r\").readlines()\n",
    "    sortie=\"\"\n",
    "    fins=[]\n",
    "    debs=[]\n",
    "    for numLigne,ligne in enumerate(TRS): # [2:]):\n",
    "        ligne=ligne.strip()\n",
    "        ligne=ligne.replace(\"<unknown>\", \"???\")\n",
    "        if 0<=numLigne <=10:\n",
    "            print ligne\n",
    "        disfluenceGen=re.match('<Event desc=\"disflu\" type=\"(noise|lexical|pronounce|language|entities)\" extent=\"(begin|end)\"/>',ligne)\n",
    "        disfluenceSpec=re.match('<Event desc=\"([Mm]d|[Rr]ep|[Aa]uto[Cc]|[Nn]on[Ff]inie|[Mm][Cc]oup)\" type=\"pronounce\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        eventAutre=re.match('<Event desc=\"([^\"]+)\" type=\"([^\"]+)\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        tagTurn=re.match('<(/?)Turn.*>',ligne)        \n",
    "        if disfluenceGen:\n",
    "            if debug: print \"disfluGen\",disfluenceGen.group(2)\n",
    "            if disfluenceGen.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceGen.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceGen.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif disfluenceSpec:\n",
    "            if debug: print \"disfluSpec\",disfluenceSpec.group(2)\n",
    "            if disfluenceSpec.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceSpec.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceSpec.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif eventAutre:\n",
    "            if debug: print \"Autre\",eventAutre.group(3)\n",
    "            descEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(1)])\n",
    "            typeEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(2)])\n",
    "            if eventAutre.group(3)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<%s desc=\"%s\">'%(typeEvent,descEvent)+\"\\n\")\n",
    "                fins.append(\"</%s>\"%typeEvent)\n",
    "            elif eventAutre.group(3)==\"end\":\n",
    "#                print numLigne\n",
    "                if fins:\n",
    "                    sortie+=(\"</%s>\"%typeEvent+\"\\n\")\n",
    "                    chaine=fins.pop()\n",
    "                else:\n",
    "                    print \"PB no stack to pop\", typeEvent,numLigne\n",
    "                if chaine!=\"</%s>\"%typeEvent:\n",
    "                    print \"PB\",chaine, typeEvent,numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif tagTurn:\n",
    "            if debug: print tagTurn.group(1)+\"Turn\"\n",
    "            if tagTurn.group(1)==\"/\" and fins:\n",
    "                lenFins=len(fins)\n",
    "                for num in range(lenFins):\n",
    "                    chaine=fins.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    debs.append(chaine.replace(\"/\",\"\"))\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "            if tagTurn.group(1)==\"\" and debs:\n",
    "                lenDebs=len(debs)\n",
    "                for num in range(lenDebs):\n",
    "                    chaine=debs.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    fins.append(chaine.replace(\"<\",\"</\"))\n",
    "        else:\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "        if debug and (debs or fins):\n",
    "            print debs, fins\n",
    "    return sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to transform a TT-annotated file into an XML: Document (root tag) and Turn (segmentation on sentences)\n",
    "def annotatedFile(name):\n",
    "    result = \"<Document><Turn>\"\n",
    "    with codecs.open(name, \"r\",\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.replace(\"_\",\"\")\n",
    "        slots = line.split(\"\\t\")\n",
    "        if slots[1] == \"SENT\":\n",
    "            result += line +\"</Turn><Turn>\\n\"\n",
    "        else:\n",
    "            result += line \n",
    "    result += \"</Turn></Document>\"\n",
    "    new_name = name[:-3]+\".trs\"\n",
    "    with codecs.open(new_name, \"w\", \"utf8\") as w:\n",
    "        w.write(result)\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ania/Documents/BdLife/M1-Tools4NLP/Outils_2016-17/CM4/\n",
      "/Users/ania/Documents/BdLife/M1-Tools4NLP/Outils_2016-17/CM4/Ch1Tour_du_monde.TT\n",
      "<Document><Turn>En\tPRP\ten\n",
      "l'\tDET:ART\tle\n",
      "année\tNOM\tannée\n",
      "1872\tNUM\t@card@\n",
      ",\tPUN\t,\n",
      "la\tDET:ART\tle\n",
      "maison\tNOM\tmaison\n",
      "portant\tVER:ppre\tporter\n",
      "le\tDET:ART\tle\n",
      "numéro\tNOM\tnuméro\n",
      "7\tNUM\t@card@\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "en l' année 1872 la maison portant le numéro 7 de saville-row burlington gardens maison dans laquelle sheridan mourut en 1814 était habitée par phileas fogg esq \n",
      "l' un des membres les plus singuliers et les plus remarqués du reform-club de londres bien qu' il semblât prendre à tâche de ne rien faire qui pût attirer l' attention \n",
      "a l' un des plus grands orateurs qui honorent l' angleterre succédait donc ce phileas fogg personnage énigmatique dont on ne savait rien sinon que c' était un fort galant homme et l' un des plus beaux gentlemen de la haute société anglaise \n",
      "on disait qu' il ressemblait à byron par la tête car il était irréprochable quant aux pieds mais un byron à moustaches et à favoris un byron impassible qui aurait vécu mille ans sans vieillir \n",
      "anglais à coup sûr phileas fogg n' était peut-être pas londonner \n",
      "on ne l' avait jamais vu ni à la bourse ni à la banque ni dans aucun des comptoirs de la cité \n",
      "ni les bassins ni les docks de londres n' avaient jamais reçu un navire ayant pour armateur phileas fogg \n",
      "ce gentleman ne figurait dans aucun comité d' administration \n",
      "son nom n' avait jamais retenti dans un collège d' avocats ni au temple ni à lincoln's-inn ni à gray's-inn \n",
      "jamais il ne plaida ni à la cour du chancelier ni au banc de la reine ni à l' échiquier ni en cour ecclésiastique \n",
      "il n' était ni industriel ni négociant ni marchand ni agriculteur \n",
      "il ne faisait partie ni de l' institution royale de la grande-bretagne ni de l' institution de londres ni de l' institution des artisans ni de l' institution russell ni de l' institution littéraire de l' ouest ni de l' institution du droit ni de cette institution des arts et des sciences réunis qui est placée sous le patronage direct de sa gracieuse majesté \n",
      "il n' appartenait enfin à aucune des nombreuses sociétés qui pullulent dans la capitale de l' angleterre depuis la société de l' armonica jusqu' à la société entomologique fondée principalement dans le but de détruire les insectes nuisibles \n",
      "phileas fogg était membre du reform-club et voilà tout \n",
      "a qui s' étonnerait de ce qu' un gentleman aussi mystérieux comptât parmi les membres de cette honorable association on répondra qu' il passa sur la recommandation de mm \n",
      "baring frères chez lesquels il avait un crédit ouvert \n",
      "de là une certaine surface due à ce que ses chèques étaient régulièrement payés à vue par le débit de son compte courant invariablement créditeur \n",
      "ce phileas fogg était -il riche  \n",
      "incontestablement \n",
      "mais comment il avait fait fortune c' est ce que les mieux informés ne pouvaient dire et mr \n",
      "fogg était le dernier auquel il convînt de s' adresser pour l' apprendre \n",
      "en tout cas il n' était prodigue de rien mais non avare car partout où il manquait un appoint pour une chose noble utile ou généreuse il l' apportait silencieusement et même anonymement \n",
      "en somme rien de moins communicatif que ce gentleman \n",
      "il parlait aussi peu que possible et semblait d'autant plus mystérieux qu' il était silencieux \n",
      "cependant sa vie était à jour mais ce qu' il faisait était si mathématiquement toujours la même chose que l' imagination mécontente cherchait au-delà \n",
      "avait -il voyagé  \n",
      "c' était probable car personne ne possédait mieux que lui la carte du monde \n",
      "il n' était endroit si reculé dont il ne parût avoir une connaissance spéciale \n",
      "quelquefois mais en peu de mots brefs et clairs il redressait les mille propos qui circulaient dans le club au sujet des voyageurs perdus ou égarés  il indiquait les vraies probabilités et ses paroles s' étaient trouvées souvent comme inspirées par une seconde vue tant l' événement finissait toujours par les justifier \n",
      "c' était un homme qui avait dû voyager partout en esprit tout au moins \n",
      "ce qui était certain toutefois c' est que depuis de longues années phileas fogg n' avait pas quitté londres \n",
      "ceux qui avaient l' honneur de le connaître un peu plus que les autres attestaient que si ce n' est sur ce chemin direct qu' il parcourait chaque jour pour venir de sa maison au club personne ne pouvait prétendre l' avoir jamais vu ailleurs \n",
      "son seul passe-temps était de lire les journaux et de jouer au whist \n",
      "a ce jeu du silence si bien approprié à sa nature il gagnait souvent mais ses gains n' entraient jamais dans sa bourse et figuraient pour une somme importante à son budget de charité \n",
      "d'ailleurs il faut le remarquer mr \n",
      "fogg jouait évidemment pour jouer non pour gagner \n",
      "le jeu était pour lui un combat une lutte contre une difficulté mais une lutte sans mouvement sans déplacement sans fatigue et cela allait à son caractère \n",
      "on ne connaissait à phileas fogg ni femme ni enfants ce qui peut arriver aux gens les plus honnêtes ni parents ni amis ce qui est plus rare en vérité \n",
      "phileas fogg vivait seul dans sa maison de saville-row où personne ne pénétrait \n",
      "de son intérieur jamais il n' était question \n",
      "un seul domestique suffisait à le servir \n",
      "déjeunant dînant au club à des heures chronométriquement déterminées dans la même salle à la même table ne traitant point ses collègues n' invitant aucun étranger il ne rentrait chez lui que pour se coucher à minuit précis sans jamais user de ces chambres confortables que le reform-club tient à la disposition des membres du cercle \n",
      "sur vingt-quatre heures il en passait dix à son domicile soit qu' il dormît soit qu' il s' occupât de sa toilette \n",
      "s' il se promenait c' était invariablement d' un pas égal dans la salle d' entrée parquetée en marqueterie ou sur la galerie circulaire au-dessus de laquelle s' arrondit un dôme à vitraux bleus que supportent vingt colonnes ioniques en porphyre rouge \n",
      "s' il dînait ou déjeunait c' étaient les cuisines le garde-manger l' office la poissonnerie la laiterie du club qui fournissaient à sa table leurs succulentes réserves  c' étaient les domestiques du club graves personnages en habit noir chaussés de souliers à semelles de molleton qui le servaient dans une porcelaine spéciale et sur un admirable linge en toile de saxe  c' étaient les cristaux à moule perdu du club qui contenaient son sherry son porto ou son claret mélangé de cannelle de capillaire et de cinnamome  c' était enfin la glace du club glace venue à grands frais des lacs d' amérique qui entretenait ses boissons dans un satisfaisant état de fraîcheur \n",
      "si vivre dans ces conditions c' est être un excentrique il faut convenir que l' excentricité a du bon  \n",
      "la maison de saville-row sans être somptueuse se recommandait par un extrême confort \n",
      "d'ailleurs avec les habitudes invariables du locataire le service s' y réduisait à peu \n",
      "toutefois phileas fogg exigeait de son unique domestique une ponctualité une régularité extraordinaires \n",
      "ce jour-là même 2 octobre phileas fogg avait donné son congé à james forster ce garçon s' étant rendu coupable de lui avoir apporté pour sa barbe de l' eau à quatre-vingt-quatre degrés fahrenheit au lieu de quatre-vingt-six et il attendait son successeur qui devait se présenter entre onze heures et onze heures et demie \n",
      "phileas fogg carrément assis dans son fauteuil les deux pieds rapprochés comme ceux d' un soldat à la parade les mains appuyées sur les genoux le corps droit la tête haute regardait marcher l' aiguille de la pendule appareil compliqué qui indiquait les heures les minutes les secondes les jours les quantièmes et l' année \n",
      "a onze heures et demie sonnant mr \n",
      "fogg devait suivant sa quotidienne habitude quitter la maison et se rendre au reform-club \n",
      "en ce moment on frappa à la porte du petit salon dans lequel se tenait phileas fogg \n",
      "james forster le congédié apparut \n",
      "le nouveau domestique dit -il un garçon âgé d' une trentaine d' années se montra et salua \n",
      "vous êtes français et vous vous nommez john  \n",
      "lui demanda phileas fogg \n",
      "jean n' en déplaise à monsieur répondit le nouveau venu jean passepartout un surnom qui m' est resté et que justifiait mon aptitude naturelle à me tirer d' affaire \n",
      "je crois être un honnête garçon monsieur mais pour être franc j' ai fait plusieurs métiers \n",
      "j' ai été chanteur ambulant écuyer dans un cirque faisant de la voltige comme léotard et dansant sur la corde comme blondin  puis je suis devenu professeur de gymnastique afin de rendre mes talents plus utiles et en dernier lieu j' étais sergent de pompiers à paris \n",
      "j' ai même dans mon dossier des incendies remarquables \n",
      "mais voilà cinq ans que j' ai quitté la france et que voulant goûter de la vie de famille je suis valet de chambre en angleterre \n",
      "or me trouvant sans place et ayant appris que m phileas fogg était l' homme le plus exact et le plus sédentaire du royaume-uni je me suis présenté chez monsieur avec l' espérance d' y vivre tranquille et d' oublier jusqu' à ce nom de passepartout  passepartout me convient répondit le gentleman \n",
      "vous m' êtes recommandé \n",
      "j' ai de bons renseignements sur votre compte \n",
      "vous connaissez mes conditions  \n",
      "oui monsieur \n",
      "bien \n",
      "quelle heure avez -vous  \n",
      "onze heures vingt-deux répondit passepartout en tirant des profondeurs de son gousset une énorme montre d' argent \n",
      "vous retardez dit mr \n",
      "fogg \n",
      "que monsieur me pardonne mais c' est impossible \n",
      "vous retardez de quatre minutes \n",
      "n' importe \n",
      "il suffit de constater l' écart \n",
      "donc à partir de ce moment onze heures vingt-neuf du matin ce mercredi 2 octobre 1872 vous êtes à mon service \n",
      "cela dit phileas fogg se leva prit son chapeau de la main gauche le plaça sur sa tête avec un mouvement d' automate et disparut sans ajouter une parole \n",
      "passepartout entendit la porte de la rue se fermer une première fois c' était son nouveau maître qui sortait  puis une seconde fois c' était son prédécesseur james forster qui s' en allait à son tour \n",
      "passepartout demeura seul dans la maison de saville-row \n",
      "\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n"
     ]
    }
   ],
   "source": [
    "for dossier in listeDossiersTRS[numPremierDossier:]:\n",
    "    print dossier\n",
    "    fichiersTRS=glob.glob(dossier+\"/*TT\") \n",
    "    fichierExceptions=dossiersTRS[dossier]\n",
    "    boolExceptions=True\n",
    "    try:\n",
    "        exceptions=codecs.open(fichierExceptions,\"r\",encoding='utf8')\n",
    "        inconnus=exceptions.readlines()\n",
    "        exceptions.close()\n",
    "    except IOError:\n",
    "        boolExceptions=False\n",
    "    if fichier_exceptions and boolExceptions:\n",
    "        oldExceptions=[]\n",
    "        for entry in inconnus:\n",
    "            entry=entry.strip()\n",
    "            if 0: print entry\n",
    "            p=entry.split(\";\")\n",
    "            if len(p)<9:\n",
    "                for i in range(len(p)+1,10):\n",
    "                    p.append(u\"\")\n",
    "            if 0: print p\n",
    "            if lowercase == True:\n",
    "                p[0] = p[0].lower()\n",
    "            if len(p[1])!=0:\n",
    "                phon[p[0]]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8]) \n",
    "            oldExceptions.append(p[0]) \n",
    "    for numTRS,nomTRS in enumerate(fichiersTRS):\n",
    "        print nomTRS\n",
    "        fichierBDL=nomTRS[:-4]+\"-BDL2TT.xml\"\n",
    "        if nomTRS.split(\"/\")[-1] in sansRebalisageFichiers:\n",
    "            print \"SANS reBALISER\"\n",
    "            xmlTRS=etree.parse(nomTRS,parser)\n",
    "            print \"FIN parse\"\n",
    "        else:\n",
    "            fichierTRS=baliserTRS(annotatedFile(nomTRS))\n",
    "            print \"FIN reBALISER\"\n",
    "            xmlTRS=etree.fromstring(fichierTRS,parser)\n",
    "            print \"FIN fromstring\"\n",
    "        (motsCorpus,motsPhrases,elementsPhrases)=listerMotsCorpus(xmlTRS)\n",
    "        print \"FIN lister mots\"\n",
    "        phon=extraireMotsTRS(motsCorpus,phon)\n",
    "        print \"FIN extraire mots\"\n",
    "        traitementTRS(xmlTRS)\n",
    "        print \"FIN traitement\"\n",
    "        with codecs.open(fichierBDL, \"w\", encoding='utf8') as f:\n",
    "            for ligne in enteteXML:\n",
    "                f.write(ligne+u\"\\n\")\n",
    "            f.write(etree.tostring(xmlTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\"))\n",
    "    with codecs.open(fichierExceptions, \"a\", encoding='utf8') as f:\n",
    "        for n in set(nouvellesExceptions):\n",
    "            if not (n in oldExceptions): \n",
    "                f.write(n+u\";;;;;;;;;;;;\")\n",
    "                f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print fichierTRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
