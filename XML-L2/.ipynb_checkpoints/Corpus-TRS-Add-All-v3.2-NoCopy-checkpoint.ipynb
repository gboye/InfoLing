{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des TRS pour ajouter les informations de BDLexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import codecs\n",
    "import re\n",
    "import pdb # ajouter pdb.set_trace() à l'endroit où on veut le débugueur\n",
    "from lxml import etree\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os, fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS À FAIRE :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS FAITES :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. ajouter un #id aux tours et aux mots => **22/12/15**\n",
    "1. gérer les parenthèses => **22/12/15**\n",
    "  - les troncations\n",
    "    - version longue pour BDLexique\n",
    "    - version courte pour la transcription\n",
    "  - les champs supplémentaires\n",
    "    - mot => nbsyllabes à saisir\n",
    "    - tour => raccourci\n",
    "1. gérer les balises Event auto-fermantes => **23/12/15**\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'environnement pour le script\n",
    "- *dossier* doit être le répertoire où se trouvent vos fichiers (devrait finir par un /)\n",
    "- *fichierTRS* contient la liste des noms de vos fichiers TRS à traiter (rempli automatiquement)\n",
    "- *fichierLexique* doit être le nom du fichier BDLEXIQUE\n",
    "- *fichierExceptions* doit être le nom de votre fichier INCONNUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connecteurs=[\n",
    "    u\"et\", u\"alors\", u\"du coup\", u\"sinon\", u\"par contre\", u\"ça veut dire\", u\"enfin\",\n",
    "u\"après\", u\"donc\", u\"puisque\", u\"puisqu'\", u\"en fait\", u\"mais\", u\"parce que\", u\"parce qu'\", u\"même si\" , u\"d'abord\", u\"et puis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dossierCorpus=\"/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/\"\n",
    "dossiersTRS={dossierCorpus:\"inconnus.txt\"}\n",
    "listeDossiersTRS=sorted(dossiersTRS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/\n"
     ]
    }
   ],
   "source": [
    "dossierCorpus=\"/Users/gilles/Copy/Corpus 2015-2016/\"\n",
    "dossierCorpus=\"/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/\"\n",
    "dossiersHorsCorpus=[\"Ponctuation\", \"Transcription Phonétique\",\"Exemple transcription pour cours d'informatique\"]\n",
    "dossiersSpeciaux=[]\n",
    "dossiersRestants=[]\n",
    "sansRebalisageFichiers=[\n",
    "    \"6 - L'amour à la plage.trs\",\n",
    "    \"7 - Les Mostaganems de saluent.trs\"\n",
    "]\n",
    "dossiersTRS={}\n",
    "inconnusTRS={}\n",
    "for root, dirs, files in os.walk(dossierCorpus):\n",
    "    if \"Corpus 2015-2016/\" in dossierCorpus:\n",
    "        dossierGroupe=root.split(\"Corpus 2015-2016/\")[1].split(\"/\")[0]\n",
    "        if not dossierGroupe in dossiersHorsCorpus+dossiersSpeciaux and dossierGroupe in dossiersRestants:\n",
    "            trs=fnmatch.filter(files, \"*.trs\")\n",
    "            if trs:\n",
    "                dossiersTRS[root]=dossierGroupe\n",
    "            inconnus=fnmatch.filter(files, \"*-inconnus.txt\")\n",
    "            if inconnus:\n",
    "                inconnusTRS[dossierGroupe]=root+\"/\"+inconnus[0]\n",
    "        else:\n",
    "            print \"dossier évité :\",dossierGroupe\n",
    "    else:\n",
    "        dossiersTRS[dossierCorpus]=dossierCorpus+\"inconnus.txt\"\n",
    "        \n",
    "for element in dossiersTRS:\n",
    "    if dossiersTRS[element] in inconnusTRS:\n",
    "        dossiersTRS[element]=inconnusTRS[dossiersTRS[element]]\n",
    "    else:\n",
    "        dossiersTRS[element]=element+\"/inconnus.txt\"\n",
    "if 0:\n",
    "    print \"INC\"\n",
    "    for element in sorted(dossiersTRS):\n",
    "        print element\n",
    "        print dossiersTRS[element]\n",
    "        print\n",
    "listeDossiersTRS=sorted(dossiersTRS.keys())\n",
    "for num,element in enumerate(listeDossiersTRS):\n",
    "    print num, element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPremierDossier=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dossiers=[\"/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/\"]\n",
    "#dossier=\"/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/\"\n",
    "#fichiersTRS=glob.glob(dossier+\"TRS/*.trs\")\n",
    "fichierLexique=\"/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/bdlexique.txt\"\n",
    "#fichierExceptions=dossier+\"inconnus.txt\"\n",
    "fichier_exceptions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voyelles=u\"ieɛayøœəuoɔɑɛ̃ɔ̃ɑ̃\"\n",
    "voyelles=u\"ieEay296@uoOòèâêûô\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous n'avez pas de fichier *inconnus.txt* \n",
    ">mettez *fichier_exceptions=False* au dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- mise en texte des deux blocs de traitement de la ligne de commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicon=codecs.open(fichierLexique,\"r\",encoding='utf8')\n",
    "bdlexique=lexicon.readlines()\n",
    "lexicon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facultatives = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phon={}\n",
    "result=[]\n",
    "nouvellesExceptions = []\n",
    "output=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "ajouter chaque ligne du fichier à phrases[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lowerAccents(chaine):\n",
    "    return chaine.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser le mot en cours\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ la ponctuation est remplacée par un espace\n",
    "+ les espaces aux extrémités sont effacés\n",
    "+ le mot est mis en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trimer(mot):\n",
    "    mot=lowerAccents(mot)\n",
    "#    for p in u',;.:-?!()“”‘’‛‟′″´˝\"«»':\n",
    "    for p in u',;.:-?!“”‘’‛‟′″´˝\"«»':   # Modifié le 22/12/15 pour gérer les parenthèses comme marqueur dans les mots\n",
    "        mot=mot.replace(p, ' ')\n",
    "    mot=mot.strip()\n",
    "    return mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def listerMotsCorpus(rootTRS):\n",
    "    phrases=[]\n",
    "    motsPhrases=[]\n",
    "    elementsPhrases=[]\n",
    "    motsCorpus=set()\n",
    "    nPhrases=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        line=ligne.strip()\n",
    "        if 0: print [line]\n",
    "    #    print nPhrases, line\n",
    "        phrases.append(line)\n",
    "#        elements=re.findall(ur\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", line)\n",
    "        elements=re.findall(ur\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ()]+['’]?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", line)\n",
    "        mots=[x for x in elements if not x in u\"-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~:\" and not x in [u\" ;\",u\" !\",u\" ?\",u\" :\"]]\n",
    "        elements=[x for x in elements if x!=u\" \"]\n",
    "        elementsPhrases.append(elements)\n",
    "        phrasePropre = u\"\"\n",
    "        for mot in mots:\n",
    "            mot = trimer(mot)\n",
    "            phrasePropre += mot+u\" \"\n",
    "            m=re.search(ur\"\\(.*\\)\",mot)\n",
    "            forme=mot\n",
    "            graphie=mot\n",
    "            if m :\n",
    "                forme=re.sub(ur\"\\((.*)\\)\",\"\\g<1>\", mot)\n",
    "                graphie=re.sub(ur\"\\(([\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?)\\)\",\"'\", mot)\n",
    "                motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}    \n",
    "            motsCorpus.add(forme)\n",
    "#        phraseMots = phrasePropre.strip()\n",
    "        phraseMots = phrasePropre.split()        \n",
    "        motsPhrases.append(phraseMots)\n",
    "        nPhrases+=1\n",
    "    return (motsCorpus,motsPhrases,elementsPhrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire de BDLex 0.forme fléchie, 1.phonétique, 2.liaison, 3.cat-gram, 4.genre+nombre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire du fichier d'exceptions les mêmes données que pour BDLex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- fait une liste des exceptions lues pour ne pas les rajouter à la fin\n",
    "- éviter de tenir compte des exceptions non renseignées\n",
    " - les mots du fichier exceptions sans transcriptions étaient transcrits par une chaine vide..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier si le mot existe\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ si le mot est dans BDLex, ok\n",
    "+ s'il y a un espace dans le mot,\n",
    "    * le mot est divisé en deux et\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ s'il y a un apostrophe dans le mot,\n",
    "    * le mot est divisé en deux\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ dans les autres cas, le mot est ajouté aux nouvelles exceptions et mis entre étoiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def verifier_mot(mot):\n",
    "        sampa=\"\"\n",
    "        if mot in phon.keys():\n",
    "            sampa += phon[mot][0]\n",
    "        elif \" \" in mot:\n",
    "            mots = mot.split()\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif \"'\" in mot:\n",
    "            mots = mot.split(\"'\")\n",
    "            mots[0]=mots[0]+\"'\"\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif mot != \"\": \n",
    "            nouvellesExceptions.append(mot)\n",
    "            sampa=\"***\"+mot+\"*** \"\n",
    "        return sampa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. traduire le SAMPA de BDLexique en API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- ajout du r et du â\n",
    "- ajout des exemples associés en dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# traduire SAMPA-BDLex en API\n",
    "\n",
    "def sampa2api(sampa):\n",
    "    if isinstance(sampa,str):\n",
    "        api=sampa.decode(\"utf8\")\n",
    "    else:\n",
    "        api=sampa\n",
    "    api=api.replace(u'S',u'ʃ') \n",
    "    api=api.replace(u'Z',u'ʒ')\n",
    "    api=api.replace(u'N',u'ŋ')\n",
    "    api=api.replace(u'J',u'ɲ')\n",
    "    api=api.replace(u'r',u'ʁ') \n",
    "    api=api.replace(u'H',u'ɥ')\n",
    "    api=api.replace(u'E',u'ɛ')\n",
    "    api=api.replace(u'2',u'ø')\n",
    "    api=api.replace(u'9',u'œ')\n",
    "    api=api.replace(u'6',u'ə')\n",
    "    api=api.replace(u'O',u'ɔ')\n",
    "    api=api.replace(u'è',u'e')   \n",
    "    api=api.replace(u'ò',u'o')    \n",
    "    api=api.replace(u'â',u'ɑ̃')   \n",
    "    api=api.replace(u'ê',u'ɛ̃')   \n",
    "    api=api.replace(u'û',u'œ̃')  \n",
    "    api=api.replace(u'ô',u'ɔ̃')       \n",
    "    api=api.replace(u'@',u'ə')\n",
    "    api=api.replace(u'n\"',u'n') \n",
    "    api=api.replace(u't\"',u't') \n",
    "    api=api.replace(u'z\"',u'z') \n",
    "    api=api.replace(u'R\"',u'ʁ') \n",
    "    api=api.replace(u'p\"',u'p') \n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Vérifier si la liaison est possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant ne sont pas dans lexicon, pas de liaison\n",
    "+ si le mot a une consonne dans le champ de la voyelle de liaison, check1 est vrai\n",
    "+ si le mot suivant commence par une voyelle, check2 est vrai\n",
    "\n",
    "  si check1 et check2 sont vrais, il y a liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def liaison_possible(phrase ,mot , mot_numero):\n",
    "    check1=0\n",
    "    check2=0\n",
    "    if mot in phon and len(phrase)>mot_numero+1 and phrase[mot_numero+1] in phon:\n",
    "        consonnes=['k\"', '(kt)\"', 'n\"', 'p\"', 'R\"', '@t\"', 't\"', '-V', '+V', '@z\"', 'z\"']\n",
    "        phoneme=phon[mot][2]\n",
    "        for phoneme in consonnes:\n",
    "            check1=1\n",
    "        \n",
    "        voyelles=[\"H\", \"j\", \"w\", \"E\", \"a\", \"2\", \"9\", \"6\", \"@\", \"y\", \"u\", \"O\", u\"ò\", \"o\", \"e\", u\"è\", u\"ê\", u\"û\", u\"ô\", \"i\"]\n",
    "        mot_suivant=phon[phrase[mot_numero+1]][1]\n",
    "        for v in voyelles:\n",
    "            if mot_suivant.startswith(v):\n",
    "                check2=1\n",
    "\n",
    "    if check1 and check2 :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. vérifier si la liaison est obligatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def liaison_obligatoire(phrase, mot, mot_numero):\n",
    "    determinant=[\"d\", \"P\"]\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    pronompers=[\"P\"]\n",
    "    verbe=[\"V\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "\n",
    "    if catgram_mot1 in determinant and catgram_mot2 in nom :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in determinant and catgram_mot2 in adjectif :\n",
    "        return True\n",
    " \n",
    "    elif catgram_mot1 in pronompers and catgram_mot2 in verbe :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in verbe and catgram_mot2 in pronompers :\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles:\n",
    "\n",
    "- DET + N\n",
    "    * ri + N:   d'animal, \n",
    "    * di + N:   certains éléphants\n",
    "    * rd + N:   les animaux\n",
    "    * dd + N:   ces étés, cet été\n",
    "    * dp + N:   ton anorak\n",
    "    * rc + N:   aux armes\n",
    "- DET + ADJ:\n",
    "    * ri + ADJ:   d'énormes\n",
    "    * di + ADJ:   plusieurs immenses\n",
    "    * rd + ADJ:   les immenses\n",
    "    * dd + ADJ:   cet immense\n",
    "    * dp + ADJ:   son immense\n",
    "    * rc + ADJ:   aux immenses\n",
    "- PERS + V:\n",
    "    * SS + V:   m'épate\n",
    "- V + PRO PERS: \n",
    "    * V + SS:   vont-ils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vérifier si la liaison est facultative\n",
    "def liaison_facultative(phrase, mot, mot_numero):\n",
    "    #pdb.set_trace()\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    pluriel=[\"MP\", \"FP\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    verbe=[\"V\"]\n",
    "    pronompers=[\"P\"]\n",
    "    adverbe=[\"A\"]\n",
    "    preposition=[\"p\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "    genre_mot1=phon[phrase[mot_numero]][4]\n",
    "    \n",
    "    if (catgram_mot1 in nom) and (phon[phrase[mot_numero]][4] in pluriel) and (catgram_mot2 in adjectif) : \n",
    "        return True\n",
    "\n",
    "    elif (catgram_mot1 in verbe) and (catgram_mot2 not in pronompers):\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in adverbe :\n",
    "        return True\n",
    "    \n",
    "    elif catgram_mot1 in preposition : \n",
    "        return True\n",
    "\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles :\n",
    "\n",
    "- N pl + ADJ: \n",
    "    * N + ADJ: monstres énormes \n",
    "    * G + ADJ: rivaux énormes\n",
    "- VERBE + TOUT-SAUF-PRO-PERS:\n",
    "    * V + N sont éléphants\n",
    "    * V + G sommes abdicaires\n",
    "    * V + V sommes assis\n",
    "    * V + A sommes admirablement\n",
    "    * V + p sommes autour de\n",
    "    * V + di ont aucune\n",
    "    * V + rc sommes au\n",
    "- ADV + QQCH:\n",
    "    * ADV + N vraiment abruti\n",
    "    * ADV + G vraiment abandonné\n",
    "    * ADV + V vraiment aimé\n",
    "    * ADV + J vraiment étonnant\n",
    "    * ADV + ss vraiment ils\n",
    "    * ADV + A vraiment étonnamment\n",
    "    * ADV + p vraiment attendu\n",
    "    * ADV + di vraiment autre \n",
    "    * ADV + rc vraiment au\n",
    "- PREP + QQCH:\n",
    "    * PREP + N très amoureux\n",
    "    * PREP + G très abandonné\n",
    "    * PREP + V très aimé\n",
    "    * PREP + J très étonnant\n",
    "    * PREP + SS très ils\n",
    "    * PREP + A très étonnamment\n",
    "    * PREP + p très attendu\n",
    "    * PREP + di très autre\n",
    "    * PREP + rc très au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Partie 1\n",
    "*chaque phrase est prise individuellement,\n",
    "    * découpée en blocs,\n",
    "        * qui sont chacuns trimés si ce sont des mots\n",
    "        * s'il y a plusieurs mots dans le bloc, ils sont séparés\n",
    "    + Partie 2\n",
    "    * pour chaque couple de mots\n",
    "        * si la liaison est possible,\n",
    "            * et qu'elle est obligatoire, l'api avec la liaison est généré\n",
    "            * et qu'elle est facultative,\n",
    "                * si l'utilisateur l'a choisi, l'api avec la liaison est généré\n",
    "                * sinon l'api sans la liaison est généré\n",
    "\n",
    "        + Partie 3\n",
    "        * si la liaison n'est pas possible,\n",
    "            * si le mot est dans bdlex, l'api est généré\n",
    "            * sinon le mot est laissé tel quel (il a déjà les étoiles)        \n",
    "\n",
    "    * pour le dernier mot de la phrase, \n",
    "        * si le mot est dans bdlex, l'api est généré\n",
    "        * sinon le mot est laissé tel quel (il a déjà les étoiles) \n",
    "\n",
    "+ Partie 4\n",
    "* le message à l'utilisateur et la phrase en api est imprimée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- suppression du délai dans la boucle\n",
    " - pour 1500 lignes => 3 secondes sans ralentisseur, 1503 secondes avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml.builder import E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compterVoyelles(chaine):\n",
    "    result=0\n",
    "    for element in chaine:\n",
    "        if element in voyelles:\n",
    "            result+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Début de l'enchassement en XML (7/12/15)\n",
    "- récupérer la ponctuation et les sauts de lignes pour rendre le texte lisible\n",
    "- ajouter le reste des informations du lexique dans la balise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def enchasseBDLexique(nphrase,nmot,liaison=False):\n",
    "    boolAbrege=False\n",
    "    motTRS=motsPhrases[nphrase][nmot]\n",
    "    if motTRS in motsAbreges:\n",
    "        mot=motsAbreges[motTRS][\"lexical\"]\n",
    "        graphie=motsAbreges[motTRS][\"graphie\"]\n",
    "        boolAbrege=True\n",
    "    else:\n",
    "        mot=motTRS\n",
    "        graphie=motTRS\n",
    "#    print mot\n",
    "    if mot in phon: \n",
    "        phono=sampa2api(phon[mot][1])\n",
    "        if liaison:\n",
    "            phono+=sampa2api(phon[mot][2])\n",
    "        cat=phon[mot][3]\n",
    "        if cat in [u\"J\",u\"K\"]:\n",
    "            cat=u\"Adj\"\n",
    "        ms=phon[mot][4]\n",
    "        vs=phon[mot][5]\n",
    "        lexeme=phon[mot][6].upper()\n",
    "        freq=phon[mot][8]\n",
    "        nbVoyelles=str(compterVoyelles(phon[mot][1]))\n",
    "        if u\" \" in vs:\n",
    "            vs=u\"\"\n",
    "    else:\n",
    "        phono=verifier_mot(mot)[:-1]\n",
    "        cat=u\"???\"\n",
    "        ms=\"\"\n",
    "        vs=\"\"\n",
    "        lexeme=\"???\"\n",
    "        freq=\"\"\n",
    "        nbVoyelles=\"\"\n",
    "    motAttributs={\"cat\":cat,\"ms\":ms,\"vs\":vs,\"phon\":phono,\"nbsyll\":nbVoyelles, \"lexeme\":lexeme, \"freq\":freq, \"id\":\"%05d%03d\"%(nphrase,nmot)}\n",
    "    if boolAbrege:\n",
    "        motAttributs[\"ABnbsyll\"]=\"\"\n",
    "        motAttributs[\"ABphon\"]=\"\"\n",
    "    result=E.motBDL(graphie,motAttributs)\n",
    "#    print etree.tostring(result,encoding=\"utf8\")\n",
    "#    print (cat,ms,vs,phono,mot)\n",
    "#    u'<mot cat=\"%s\" ms=\"%s\" vs=\"%s\" phon=\"%s\">%s</mot>' % (cat,ms,vs,phono,mot)\n",
    "    return result\n",
    "    \n",
    "def enchasseXML(mot, phono):\n",
    "    if isinstance(phono,str):\n",
    "        phono=phono.decode(\"utf8\")\n",
    "    result=E.motBDL(mot,{\"phon\":phono})\n",
    "#    u'<mot phon=\"%s\">%s</mot>' % (phono, mot)\n",
    "    return result\n",
    "\n",
    "def enchasseTour(phrase):\n",
    "    result=E.tour(phrase,{\"id\":\"%06d\"%nPhrase})\n",
    "    return result\n",
    "\n",
    "def enchasseNonMot(nonmot):\n",
    "    result=E.punct(nonmot)\n",
    "#    u'<punct>%s</punct>' % (nonmot)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def traitementTRS(rootTRS):\n",
    "    a=1\n",
    "    nPhrase=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        phrase=ligne.strip()\n",
    "        api=E.tour()\n",
    "        mot_numero=0\n",
    "        element_numero=0\n",
    "        while elementsPhrases[nPhrase] and element_numero < len(elementsPhrases[nPhrase]):\n",
    "            if not mot_numero < len(motsPhrases[nPhrase]) or motsPhrases[nPhrase][mot_numero]!=elementsPhrases[nPhrase][element_numero].lower():\n",
    "                api.append(enchasseNonMot(elementsPhrases[nPhrase][element_numero]))\n",
    "            elif liaison_possible(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                if liaison_obligatoire(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    api.append(enchasseBDLexique(nPhrase,mot_numero,True))\n",
    "                elif liaison_facultative(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    if facultatives:\n",
    "                        api.append(enchasseBDLexique(nPhrase,mot_numero,True))\n",
    "                    else :\n",
    "                        api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                else:\n",
    "                    api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero+=1\n",
    "            else:\n",
    "                api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero = mot_numero+1\n",
    "            element_numero+=1\n",
    "        a=a+1\n",
    "        if phrase!=\"\":\n",
    "            phraseConnecteurs=set()\n",
    "            for connecteur in connecteurs:\n",
    "                if \" \" in connecteur:\n",
    "                    connecteurParties=connecteur.split(\" \")\n",
    "                else:\n",
    "                    connecteurParties=[connecteur]\n",
    "                for i in range(len(elementsPhrases[nPhrase])-len(connecteurParties)+1):\n",
    "                    if connecteurParties==elementsPhrases[nPhrase][i:i+len(connecteurParties)]:\n",
    "                        phraseConnecteurs.add(connecteur)\n",
    "            if phraseConnecteurs:\n",
    "#                print phraseConnecteurs\n",
    "                api.set(\"connecteurs\",\",\".join(phraseConnecteurs))\n",
    "            api.set(\"nbmots\",str(len(api.xpath(\"//tour/motBDL\"))))\n",
    "            api.set(\"id\",\"%06d\"%nPhrase)\n",
    "            noeudAttachement=ligne.getparent()\n",
    "            if noeudAttachement.text==None:\n",
    "                noeudAttachement.tail=None\n",
    "                noeudAttachement.addnext(api)\n",
    "            else:\n",
    "                noeudAttachement.text=None\n",
    "                try:\n",
    "                    noeudAttachement.append(api)\n",
    "                except TypeError:\n",
    "                    print phrase, noeudAttachement\n",
    "                    noeudAttachement.append(api)\n",
    "        else:\n",
    "            ligne.getparent().tail=None\n",
    "        nPhrase+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- Insertion d'un set sur les nouvellesExceptions pour éviter les entrées multiples\n",
    "- Ajout d'un test pour vérifier que les nouvellesExceptions sont nouvelles\n",
    "\n",
    "#TO DO\n",
    "- Ajouter un message pour dire que le résultat a été concaténé au fichier existant si c'est le cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extraireMotsTRS(motsCorpus,phon):\n",
    "    for entry in bdlexique:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(u';')\n",
    "        if p[0].lower() in motsCorpus:\n",
    "            if p[2]==\"@\" and not p[3] in [\"N\",\"V\",\"J\",\"K\"]:\n",
    "                p[1]+=p[2]\n",
    "                p[2]=\"\"\n",
    "                if len(p)<7:\n",
    "                    for i in range(len(p)+1,7):\n",
    "                        p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8],p[9])\n",
    "    return phon\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if fichier_exceptions:\n",
    "    oldExceptions=[]\n",
    "    for entry in inconnus:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(\";\")\n",
    "        if len(p[1])!=0:\n",
    "            if len(p)<9:\n",
    "                for i in range(len(p)+1,7):\n",
    "                    p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "        oldExceptions.append(p[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.2.b. mettre les phrases phonémisées dans un fichier\n",
    "enteteXML=[\n",
    "            u'<?xml version=\"1.0\" encoding=\"UTF8\" standalone=\"yes\"?>',\n",
    "            u'<?xml-stylesheet type=\"text/xsl\" href=\"phonemise-TRS.xsl\"?>',\n",
    "            u'<!DOCTYPE Trans SYSTEM \"trans-14-corpus.dtd\">'\n",
    "          ]\n",
    "\n",
    "#print [etree.tostring(rootTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\")]\n",
    "motsAbreges={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baliserTRS(nomTRS):\n",
    "    with open(nomTRS,\"r\") as temp:\n",
    "        header= temp.readlines()[0]\n",
    "        s=re.search(ur'encoding=\"(.+)\"',header)\n",
    "        if s:\n",
    "            TRS=codecs.open(nomTRS,\"r\",encoding=s.group(1)).readlines()\n",
    "        else:\n",
    "            TRS=open(nomTRS,\"r\").readlines()\n",
    "    sortie=\"\"\n",
    "    fins=[]\n",
    "    debs=[]\n",
    "    for numLigne,ligne in enumerate(TRS[2:]):\n",
    "        ligne=ligne.strip()\n",
    "        if 0<=numLigne <=10:\n",
    "            print ligne\n",
    "        disfluenceGen=re.match('<Event desc=\"disflu\" type=\"(noise|lexical|pronounce|language|entities)\" extent=\"(begin|end)\"/>',ligne)\n",
    "        disfluenceSpec=re.match('<Event desc=\"([Mm]d|[Rr]ep|[Aa]uto[Cc]|[Nn]on[Ff]inie|[Mm][Cc]oup)\" type=\"pronounce\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        eventAutre=re.match('<Event desc=\"([^\"]+)\" type=\"([^\"]+)\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        tagTurn=re.match('<(/?)Turn.*>',ligne)        \n",
    "        if disfluenceGen:\n",
    "            if debug: print \"disfluGen\",disfluenceGen.group(2)\n",
    "            if disfluenceGen.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceGen.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceGen.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif disfluenceSpec:\n",
    "            if debug: print \"disfluSpec\",disfluenceSpec.group(2)\n",
    "            if disfluenceSpec.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceSpec.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceSpec.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif eventAutre:\n",
    "            if debug: print \"Autre\",eventAutre.group(3)\n",
    "            descEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(1)])\n",
    "            typeEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(2)])\n",
    "            if eventAutre.group(3)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<%s desc=\"%s\">'%(typeEvent,descEvent)+\"\\n\")\n",
    "                fins.append(\"</%s>\"%typeEvent)\n",
    "            elif eventAutre.group(3)==\"end\":\n",
    "#                print numLigne\n",
    "                if fins:\n",
    "                    sortie+=(\"</%s>\"%typeEvent+\"\\n\")\n",
    "                    chaine=fins.pop()\n",
    "                else:\n",
    "                    print \"PB no stack to pop\", typeEvent,numLigne\n",
    "                if chaine!=\"</%s>\"%typeEvent:\n",
    "                    print \"PB\",chaine, typeEvent,numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif tagTurn:\n",
    "            if debug: print tagTurn.group(1)+\"Turn\"\n",
    "            if tagTurn.group(1)==\"/\" and fins:\n",
    "                lenFins=len(fins)\n",
    "                for num in range(lenFins):\n",
    "                    chaine=fins.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    debs.append(chaine.replace(\"/\",\"\"))\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "            if tagTurn.group(1)==\"\" and debs:\n",
    "                lenDebs=len(debs)\n",
    "                for num in range(lenDebs):\n",
    "                    chaine=debs.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    fins.append(chaine.replace(\"<\",\"</\"))\n",
    "        else:\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "        if debug and (debs or fins):\n",
    "            print debs, fins\n",
    "    return sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/\n",
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/Animatrice personnel.trs\n",
      "<Trans scribe=\"Valentine\" audio_filename=\"Animatrice personnel\" version=\"16\" version_date=\"151208\">\n",
      "<Topics>\n",
      "<Topic id=\"to1\" desc=\"Début\"/>\n",
      "<Topic id=\"to2\" desc=\"Fin\"/>\n",
      "</Topics>\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Animatrice\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"*\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"nontrans\" startTime=\"0\" endTime=\"179.161\">\n",
      "PB no stack to pop pronounce 1258\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/Animatrice professionnel.trs\n",
      "<Trans scribe=\"Valentine\" audio_filename=\"Animatrice professionnel\" version=\"11\" version_date=\"151208\">\n",
      "<Topics>\n",
      "<Topic id=\"to1\" desc=\"Début\"/>\n",
      "<Topic id=\"to2\" desc=\"Fin\"/>\n",
      "</Topics>\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Animatrice\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk2\" name=\"Madame V\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk3\" name=\"Madame B\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk4\" name=\"Madame M\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk5\" name=\"Monsieur R\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "PB no stack to pop noise 1369\n",
      "PB </disfluence> noise 1369\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/Argonne.trs\n",
      "<Trans scribe=\"Catherine\" audio_filename=\"Argonne\" version=\"5\" version_date=\"141215\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker R\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"français\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker P\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"français\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"elle est marrante\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"1067.729\">\n",
      "<Turn startTime=\"0\" endTime=\"1.936\">\n",
      "<Sync time=\"0\"/>\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/CM1_CM2_trans.trs\n",
      "<?xml-stylesheet type=\"text/xsl\" href=\"TRS-Speakers.xsl\" ?>\n",
      "<Trans scribe=\"léa\" audio_filename=\"CM1_CM2\" version=\"1\" version_date=\"141127\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#maitresse\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#1\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"speaker#2\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk4\" name=\"speaker#3\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk5\" name=\"speaker#4\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk6\" name=\"speaker#5\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk7\" name=\"speaker#6\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk8\" name=\"speaker#7\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/Enregistrement1-UTF8.trs\n",
      "<Trans scribe=\"AN-MOUSE\" audio_filename=\"Enregistrement CHA\" version=\"4\" version_date=\"151122\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Lucie\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk2\" name=\"Cha\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Topics>\n",
      "<Topic id=\"to1\" desc=\"Passion\"/>\n",
      "<Topic id=\"to2\" desc=\"Enervement\"/>\n",
      "<Topic id=\"to3\" desc=\"\"/>\n",
      "<Topic id=\"to4\" desc=\"\"/>\n",
      "<Topic id=\"to5\" desc=\"Dégout\"/>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/Instituteur personnel.trs\n",
      "<Trans scribe=\"Valentine\" audio_filename=\"Institeur personnel\" version=\"11\" version_date=\"151209\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Instituteur\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Valentine\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"Stéphanie\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Topics>\n",
      "<Topic id=\"to1\" desc=\"Début\"/>\n",
      "<Topic id=\"to2\" desc=\"Fin\"/>\n",
      "</Topics>\n",
      "<Episode>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/Instituteur professionnel.trs\n",
      "<Trans scribe=\"estelle\" audio_filename=\"Instituteur professionnel\" version=\"17\" version_date=\"151209\">\n",
      "<Topics>\n",
      "<Topic id=\"to1\" desc=\"Début\"/>\n",
      "<Topic id=\"to2\" desc=\"Fin\"/>\n",
      "</Topics>\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Instituteur\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"speaker#3\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk4\" name=\"speaker#4\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk5\" name=\"speaker#5\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/TRS/Manager personnel.trs\n",
      "<Trans scribe=\"estelle\" audio_filename=\"Manager personnel\" version=\"11\" version_date=\"151210\">\n",
      "<Topics>\n",
      "<Topic id=\"to1\" desc=\"Début\"/>\n",
      "</Topics>\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Manager PGC\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"nontrans\" startTime=\"0\" endTime=\"14.219\">\n",
      "<Turn startTime=\"0\" endTime=\"14.219\">\n",
      "<Sync time=\"0\"/>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-f479af8ff736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"FIN parse\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mfichierTRS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaliserTRS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnomTRS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"FIN reBALISER\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mxmlTRS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfichierTRS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-68d014d640d0>\u001b[0m in \u001b[0;36mbaliserTRS\u001b[0;34m(nomTRS)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mdisfluenceSpec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0msortie\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</disfluence>\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mchaine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchaine\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"</disfluence>\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"PB\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchaine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"</disfluence>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumLigne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "for dossier in listeDossiersTRS[numPremierDossier:]:\n",
    "    print dossier\n",
    "    fichiersTRS=glob.glob(dossier+\"/*.trs\")\n",
    "    fichierExceptions=dossiersTRS[dossier]\n",
    "    boolExceptions=True\n",
    "    try:\n",
    "        exceptions=codecs.open(fichierExceptions,\"r\",encoding='utf8')\n",
    "        inconnus=exceptions.readlines()\n",
    "        exceptions.close()\n",
    "    except IOError:\n",
    "        boolExceptions=False\n",
    "    if fichier_exceptions and boolExceptions:\n",
    "        oldExceptions=[]\n",
    "        for entry in inconnus:\n",
    "            entry=entry.strip()\n",
    "            if 0: print entry\n",
    "            p=entry.split(\";\")\n",
    "            if len(p)<9:\n",
    "                for i in range(len(p)+1,10):\n",
    "                    p.append(u\"\")\n",
    "            if 0: print p\n",
    "            if len(p[1])!=0:\n",
    "                phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "            oldExceptions.append(p[0].lower())\n",
    "    for numTRS,nomTRS in enumerate(fichiersTRS):\n",
    "        print nomTRS\n",
    "        fichierBDL=nomTRS[:-4]+\"-BDL2.xml\"\n",
    "        if nomTRS.split(\"/\")[-1] in sansRebalisageFichiers:\n",
    "            print \"SANS reBALISER\"\n",
    "            xmlTRS=etree.parse(nomTRS,parser)\n",
    "            print \"FIN parse\"\n",
    "        else:\n",
    "            fichierTRS=baliserTRS(nomTRS)\n",
    "            print \"FIN reBALISER\"\n",
    "            xmlTRS=etree.fromstring(fichierTRS,parser)\n",
    "            print \"FIN fromstring\"\n",
    "        (motsCorpus,motsPhrases,elementsPhrases)=listerMotsCorpus(xmlTRS)\n",
    "        print \"FIN lister mots\"\n",
    "        phon=extraireMotsTRS(motsCorpus,phon)\n",
    "        print \"FIN extraire mots\"\n",
    "        traitementTRS(xmlTRS)\n",
    "        print \"FIN traitement\"\n",
    "        with codecs.open(fichierBDL, \"w\", encoding='utf8') as f:\n",
    "            for ligne in enteteXML:\n",
    "                f.write(ligne+u\"\\n\")\n",
    "            f.write(etree.tostring(xmlTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\"))\n",
    "    with codecs.open(fichierExceptions, \"a\", encoding='utf8') as f:\n",
    "        for n in set(nouvellesExceptions):\n",
    "            if not (n in oldExceptions): \n",
    "                f.write(n+u\";;;;;;;;;;;;\")\n",
    "                f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print fichierTRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
