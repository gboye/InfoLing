{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des TRS pour ajouter les informations de BDLexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import codecs\n",
    "import re\n",
    "import pdb # ajouter pdb.set_trace() à l'endroit où on veut le débugueur\n",
    "from lxml import etree\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os, fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS À FAIRE :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS FAITES :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. ajouter un #id aux tours et aux mots => **22/12/15**\n",
    "1. gérer les parenthèses => **22/12/15**\n",
    "  - les troncations\n",
    "    - version longue pour BDLexique\n",
    "    - version courte pour la transcription\n",
    "  - les champs supplémentaires\n",
    "    - mot => nbsyllabes à saisir\n",
    "    - tour => raccourci\n",
    "1. gérer les balises Event auto-fermantes => **23/12/15**\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'environnement pour le script\n",
    "- *dossier* doit être le répertoire où se trouvent vos fichiers (devrait finir par un /)\n",
    "- *fichierTRS* contient la liste des noms de vos fichiers TRS à traiter (rempli automatiquement)\n",
    "- *fichierLexique* doit être le nom du fichier BDLEXIQUE\n",
    "- *fichierExceptions* doit être le nom de votre fichier INCONNUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecteurs=[\n",
    "    u\"et\", u\"alors\", u\"du coup\", u\"sinon\", u\"par contre\", u\"ça veut dire\", u\"enfin\",\n",
    "u\"après\", u\"donc\", u\"puisque\", u\"puisqu'\", u\"en fait\", u\"mais\", u\"parce que\", u\"parce qu'\", u\"même si\" , u\"d'abord\", u\"et puis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "update=True\n",
    "dossierCorpus=\"/Users/gilles/Downloads/LNS3U5/\"\n",
    "dossierCorpus=\"/Users/gilles/pCloud Drive/FOD/Corpus-2017/0 Groupes/\"\n",
    "dossierCorpus=\"/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/\"\n",
    "fichierXSLT=\"/Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl\"\n",
    "corpusDossiers=glob.glob(dossierCorpus+\"*/\")\n",
    "dossiersTRS={dCorpus:dCorpus+\"inconnus.txt\" for dCorpus in corpusDossiers}\n",
    "sansRebalisageFichiers=[\n",
    "#                        \"Chantal Véronique Giacomo.trs\",\n",
    "#                        \"Les Filles à la fac 2211.trs\",\n",
    "#                        \"Lili et Axelle au mcdo-transcription.trs\",\n",
    "#                        \"heartstone.trs\",\n",
    "#                        \"KirchnerovaAneta.trs\",\n",
    "#                        \"Xeleko-4.3.trs\",\n",
    "#                        \"KevinAzaisCesarMeilleurEspoirMasculin.trs\",\n",
    "#                        \"Donald Trump Talks Media Coverage, Polls and His Vocal Transformation.trs\",\n",
    "#                        \"Nicolas Sarkozy et questions libres.trs\",\n",
    "#                        \"les filles à la fac 22nov.trs\",\n",
    "#                        \"Linguistique (1) (mp3cut.net) (1).trs\",\n",
    "#                        \"trs_3.trs\",\n",
    "#                        \"trs_8.trs\",\n",
    "#                        \"3Cours_Latin 5e _Jean-Pierre_Anne.trs\"\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/',\n",
       " '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listeDossiersTRS=corpusDossiers\n",
    "if update:\n",
    "    updatedDossiers=glob.glob(dossierCorpus.replace(\"0 Groupes/\",\"\")+\"[a-zA-Z]*/\")\n",
    "    filtreDossiers=[n.split(\"/\")[-2] for n in updatedDossiers]\n",
    "    filtreDossiers\n",
    "\n",
    "    listeDossiersTRS=[c for c in corpusDossiers if c.split(\"/\")[-2] in filtreDossiers or \"Guerin\" in c]\n",
    "listeDossiersTRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPremierDossier=0\n",
    "numDernierDossier=0\n",
    "if numDernierDossier<numPremierDossier or numDernierDossier==0:\n",
    "    numDernierDossier=100\n",
    "elif numDernierDossier==numPremierDossier:\n",
    "    numDernierDossier+=1\n",
    "numDossiers=range(numPremierDossier,numDernierDossier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichierLexique=\"/Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/bdlexique.txt\"\n",
    "fichier_exceptions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "voyelles=u\"ieɛayøœəuoɔɑɛ̃ɔ̃ɑ̃\"\n",
    "voyelles=u\"ieEay296@uoOòèâêûô\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous n'avez pas de fichier *inconnus.txt* \n",
    ">mettez *fichier_exceptions=False* au dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- mise en texte des deux blocs de traitement de la ligne de commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon=codecs.open(fichierLexique,\"r\",encoding='utf8')\n",
    "bdlexique=lexicon.readlines()\n",
    "lexicon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "facultatives = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon={}\n",
    "result=[]\n",
    "nouvellesExceptions = []\n",
    "output=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "ajouter chaque ligne du fichier à phrases[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerAccents(chaine):\n",
    "    return chaine.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser le mot en cours\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ la ponctuation est remplacée par un espace\n",
    "+ les espaces aux extrémités sont effacés\n",
    "+ le mot est mis en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimer(mot):\n",
    "    mot=lowerAccents(mot)\n",
    "#    for p in u',;.:-?!()“”‘’‛‟′″´˝\"«»':\n",
    "    for p in u',;.:-?!“”‘’‛‟′″´˝\"«»':   # Modifié le 22/12/15 pour gérer les parenthèses comme marqueur dans les mots\n",
    "        mot=mot.replace(p, ' ')\n",
    "    mot=mot.strip()\n",
    "    return mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deparentheser(mot):\n",
    "    forme=mot\n",
    "    graphie=mot\n",
    "    m=re.search(ur\"\\([^)]*\\)\",forme)\n",
    "    while (m):\n",
    "        forme=re.sub(ur\"\\(([^)]*)\\)\",\"\\g<1>\", forme)\n",
    "        graphie=re.sub(ur\"\\(([\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?)\\)\",\"'\", graphie)\n",
    "        m=re.search(ur\"\\([^)]*\\)\",forme)\n",
    "    return(forme,graphie)\n",
    "#    motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'th\\xe9rapeutique', u\"th'rapeutiq'\")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deparentheser(u\"th(é)rapeutiq(ue)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listerMotsCorpus(rootTRS):\n",
    "    phrases=[]\n",
    "    motsPhrases=[]\n",
    "    elementsPhrases=[]\n",
    "    motsCorpus=set()\n",
    "    nPhrases=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        line=ligne.strip()\n",
    "        if 0: print [line]\n",
    "    #    print nPhrases, line\n",
    "        phrases.append(line)\n",
    "#        elements=re.findall(ur\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", line)\n",
    "        elements=re.findall(ur\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ()]+['’]?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", line)\n",
    "        mots=[x for x in elements if not x in u\"-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~:\" and not x in [u\" ;\",u\" !\",u\" ?\",u\" :\"]]\n",
    "        elements=[x for x in elements if x!=u\" \"]\n",
    "        elementsPhrases.append(elements)\n",
    "        phrasePropre = u\"\"\n",
    "        for mot in mots:\n",
    "            mot = trimer(mot)\n",
    "            phrasePropre += mot+u\" \"\n",
    "            (forme,graphie)=deparentheser(mot)\n",
    "#            m=re.search(ur\"\\(.*\\)\",mot)\n",
    "#            forme=mot\n",
    "#            graphie=mot\n",
    "#            if m :\n",
    "#                forme=re.sub(ur\"\\((.*)\\)\",\"\\g<1>\", mot)\n",
    "#                graphie=re.sub(ur\"\\(([\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?)\\)\",\"'\", mot)\n",
    "#                motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}    \n",
    "            motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}\n",
    "            motsCorpus.add(forme)\n",
    "#        phraseMots = phrasePropre.strip()\n",
    "        phraseMots = phrasePropre.split()        \n",
    "        motsPhrases.append(phraseMots)\n",
    "        nPhrases+=1\n",
    "    return (motsCorpus,motsPhrases,elementsPhrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire de BDLex 0.forme fléchie, 1.phonétique, 2.liaison, 3.cat-gram, 4.genre+nombre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire du fichier d'exceptions les mêmes données que pour BDLex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- fait une liste des exceptions lues pour ne pas les rajouter à la fin\n",
    "- éviter de tenir compte des exceptions non renseignées\n",
    " - les mots du fichier exceptions sans transcriptions étaient transcrits par une chaine vide..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier si le mot existe\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ si le mot est dans BDLex, ok\n",
    "+ s'il y a un espace dans le mot,\n",
    "    * le mot est divisé en deux et\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ s'il y a un apostrophe dans le mot,\n",
    "    * le mot est divisé en deux\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ dans les autres cas, le mot est ajouté aux nouvelles exceptions et mis entre étoiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_mot(mot):\n",
    "        sampa=\"\"\n",
    "        if mot in phon.keys():\n",
    "            sampa += phon[mot][0]\n",
    "        elif \" \" in mot:\n",
    "            mots = mot.split()\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif \"'\" in mot:\n",
    "            mots = mot.split(\"'\")\n",
    "            mots[0]=mots[0]+\"'\"\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif mot != \"\": \n",
    "            nouvellesExceptions.append(mot)\n",
    "            sampa=\"***\"+mot+\"*** \"\n",
    "        return sampa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. traduire le SAMPA de BDLexique en API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- ajout du r et du â\n",
    "- ajout des exemples associés en dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traduire SAMPA-BDLex en API\n",
    "\n",
    "def sampa2api(sampa):\n",
    "    if isinstance(sampa,str):\n",
    "        api=sampa.decode(\"utf8\")\n",
    "    else:\n",
    "        api=sampa\n",
    "    api=api.replace(u'n\"',u'n') \n",
    "    api=api.replace(u't\"',u't') \n",
    "    api=api.replace(u'z\"',u'z') \n",
    "    api=api.replace(u'R\"',u'ʁ') \n",
    "    api=api.replace(u'p\"',u'p') \n",
    "    api=api.replace(u'S',u'ʃ') \n",
    "    api=api.replace(u'Z',u'ʒ')\n",
    "    api=api.replace(u'N',u'ŋ')\n",
    "    api=api.replace(u'J',u'ɲ')\n",
    "    api=api.replace(u'r',u'ʁ') \n",
    "    api=api.replace(u'H',u'ɥ')\n",
    "    api=api.replace(u'E',u'ɛ')\n",
    "    api=api.replace(u'2',u'ø')\n",
    "    api=api.replace(u'9',u'œ')\n",
    "    api=api.replace(u'6',u'ə')\n",
    "    api=api.replace(u'O',u'ɔ')\n",
    "    api=api.replace(u'è',u'e')   \n",
    "    api=api.replace(u'ò',u'o')    \n",
    "    api=api.replace(u'â',u'ɑ̃')   \n",
    "    api=api.replace(u'ê',u'ɛ̃')   \n",
    "    api=api.replace(u'û',u'œ̃')  \n",
    "    api=api.replace(u'ô',u'ɔ̃')       \n",
    "    api=api.replace(u'@',u'ə')\n",
    "    api=api.replace(u'R',u'ʁ') \n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Vérifier si la liaison est possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant ne sont pas dans lexicon, pas de liaison\n",
    "+ si le mot a une consonne dans le champ de la voyelle de liaison, check1 est vrai\n",
    "+ si le mot suivant commence par une voyelle, check2 est vrai\n",
    "\n",
    "  si check1 et check2 sont vrais, il y a liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liaison_possible(phrase ,mot , mot_numero):\n",
    "    check1=0\n",
    "    check2=0\n",
    "    if mot in phon and len(phrase)>mot_numero+1 and phrase[mot_numero+1] in phon:\n",
    "        consonnes=['k\"', '(kt)\"', 'n\"', 'p\"', 'R\"', '@t\"', 't\"', '-V', '+V', '@z\"', 'z\"']\n",
    "        phoneme=phon[mot][2]\n",
    "        for phoneme in consonnes:\n",
    "            check1=1\n",
    "        \n",
    "        voyelles=[\"H\", \"j\", \"w\", \"E\", \"a\", \"2\", \"9\", \"6\", \"@\", \"y\", \"u\", \"O\", u\"ò\", \"o\", \"e\", u\"è\", u\"ê\", u\"û\", u\"ô\", \"i\"]\n",
    "        mot_suivant=phon[phrase[mot_numero+1]][1]\n",
    "        for v in voyelles:\n",
    "            if mot_suivant.startswith(v):\n",
    "                check2=1\n",
    "\n",
    "    if check1 and check2 :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. vérifier si la liaison est obligatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liaison_obligatoire(phrase, mot, mot_numero):\n",
    "    determinant=[\"d\", \"P\"]\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    pronompers=[\"P\"]\n",
    "    verbe=[\"V\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "\n",
    "    if catgram_mot1 in determinant and catgram_mot2 in nom :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in determinant and catgram_mot2 in adjectif :\n",
    "        return True\n",
    " \n",
    "    elif catgram_mot1 in pronompers and catgram_mot2 in verbe :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in verbe and catgram_mot2 in pronompers :\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles:\n",
    "\n",
    "- DET + N\n",
    "    * ri + N:   d'animal, \n",
    "    * di + N:   certains éléphants\n",
    "    * rd + N:   les animaux\n",
    "    * dd + N:   ces étés, cet été\n",
    "    * dp + N:   ton anorak\n",
    "    * rc + N:   aux armes\n",
    "- DET + ADJ:\n",
    "    * ri + ADJ:   d'énormes\n",
    "    * di + ADJ:   plusieurs immenses\n",
    "    * rd + ADJ:   les immenses\n",
    "    * dd + ADJ:   cet immense\n",
    "    * dp + ADJ:   son immense\n",
    "    * rc + ADJ:   aux immenses\n",
    "- PERS + V:\n",
    "    * SS + V:   m'épate\n",
    "- V + PRO PERS: \n",
    "    * V + SS:   vont-ils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifier si la liaison est facultative\n",
    "def liaison_facultative(phrase, mot, mot_numero):\n",
    "    #pdb.set_trace()\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    pluriel=[\"MP\", \"FP\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    verbe=[\"V\"]\n",
    "    pronompers=[\"P\"]\n",
    "    adverbe=[\"A\"]\n",
    "    preposition=[\"p\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "    genre_mot1=phon[phrase[mot_numero]][4]\n",
    "    \n",
    "    if (catgram_mot1 in nom) and (phon[phrase[mot_numero]][4] in pluriel) and (catgram_mot2 in adjectif) : \n",
    "        return True\n",
    "\n",
    "    elif (catgram_mot1 in verbe) and (catgram_mot2 not in pronompers):\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in adverbe :\n",
    "        return True\n",
    "    \n",
    "    elif catgram_mot1 in preposition : \n",
    "        return True\n",
    "\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles :\n",
    "\n",
    "- N pl + ADJ: \n",
    "    * N + ADJ: monstres énormes \n",
    "    * G + ADJ: rivaux énormes\n",
    "- VERBE + TOUT-SAUF-PRO-PERS:\n",
    "    * V + N sont éléphants\n",
    "    * V + G sommes abdicaires\n",
    "    * V + V sommes assis\n",
    "    * V + A sommes admirablement\n",
    "    * V + p sommes autour de\n",
    "    * V + di ont aucune\n",
    "    * V + rc sommes au\n",
    "- ADV + QQCH:\n",
    "    * ADV + N vraiment abruti\n",
    "    * ADV + G vraiment abandonné\n",
    "    * ADV + V vraiment aimé\n",
    "    * ADV + J vraiment étonnant\n",
    "    * ADV + ss vraiment ils\n",
    "    * ADV + A vraiment étonnamment\n",
    "    * ADV + p vraiment attendu\n",
    "    * ADV + di vraiment autre \n",
    "    * ADV + rc vraiment au\n",
    "- PREP + QQCH:\n",
    "    * PREP + N très amoureux\n",
    "    * PREP + G très abandonné\n",
    "    * PREP + V très aimé\n",
    "    * PREP + J très étonnant\n",
    "    * PREP + SS très ils\n",
    "    * PREP + A très étonnamment\n",
    "    * PREP + p très attendu\n",
    "    * PREP + di très autre\n",
    "    * PREP + rc très au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Partie 1\n",
    "*chaque phrase est prise individuellement,\n",
    "    * découpée en blocs,\n",
    "        * qui sont chacuns trimés si ce sont des mots\n",
    "        * s'il y a plusieurs mots dans le bloc, ils sont séparés\n",
    "    + Partie 2\n",
    "    * pour chaque couple de mots\n",
    "        * si la liaison est possible,\n",
    "            * et qu'elle est obligatoire, l'api avec la liaison est généré\n",
    "            * et qu'elle est facultative,\n",
    "                * si l'utilisateur l'a choisi, l'api avec la liaison est généré\n",
    "                * sinon l'api sans la liaison est généré\n",
    "\n",
    "        + Partie 3\n",
    "        * si la liaison n'est pas possible,\n",
    "            * si le mot est dans bdlex, l'api est généré\n",
    "            * sinon le mot est laissé tel quel (il a déjà les étoiles)        \n",
    "\n",
    "    * pour le dernier mot de la phrase, \n",
    "        * si le mot est dans bdlex, l'api est généré\n",
    "        * sinon le mot est laissé tel quel (il a déjà les étoiles) \n",
    "\n",
    "+ Partie 4\n",
    "* le message à l'utilisateur et la phrase en api est imprimée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- suppression du délai dans la boucle\n",
    " - pour 1500 lignes => 3 secondes sans ralentisseur, 1503 secondes avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.builder import E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compterVoyelles(chaine):\n",
    "    result=0\n",
    "    for element in chaine:\n",
    "        if element in voyelles:\n",
    "            result+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Début de l'enchassement en XML (7/12/15)\n",
    "- récupérer la ponctuation et les sauts de lignes pour rendre le texte lisible\n",
    "- ajouter le reste des informations du lexique dans la balise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enchasseBDLexique(nphrase,nmot,liaison=False):\n",
    "    boolAbrege=False\n",
    "    motTRS=motsPhrases[nphrase][nmot]\n",
    "    if motTRS in motsAbreges:\n",
    "        mot=motsAbreges[motTRS][\"lexical\"]\n",
    "        graphie=motsAbreges[motTRS][\"graphie\"]\n",
    "        boolAbrege=True\n",
    "    else:\n",
    "        mot=motTRS\n",
    "        graphie=motTRS\n",
    "#    print mot\n",
    "    if mot in phon: \n",
    "        phono=sampa2api(phon[mot][1])\n",
    "        if liaison:\n",
    "            phono+=sampa2api(phon[mot][2])\n",
    "        cat=phon[mot][3]\n",
    "        if cat in [u\"J\",u\"K\"]:\n",
    "            cat=u\"Adj\"\n",
    "        ms=phon[mot][4]\n",
    "        vs=phon[mot][5]\n",
    "        lexeme=phon[mot][6].upper()\n",
    "        freq=phon[mot][8]\n",
    "        nbVoyelles=str(compterVoyelles(phon[mot][1]))\n",
    "        if u\" \" in vs:\n",
    "            vs=u\"\"\n",
    "    else:\n",
    "        phono=verifier_mot(mot)[:-1]\n",
    "        cat=u\"???\"\n",
    "        ms=\"\"\n",
    "        vs=\"\"\n",
    "        lexeme=\"???\"\n",
    "        freq=\"\"\n",
    "        nbVoyelles=\"\"\n",
    "    motAttributs={\"cat\":cat,\"ms\":ms,\"vs\":vs,\"phon\":phono,\"nbsyll\":nbVoyelles, \"lexeme\":lexeme, \"freq\":freq, \"id\":\"%05d%03d\"%(nphrase,nmot)}\n",
    "    if boolAbrege:\n",
    "        motAttributs[\"ABnbsyll\"]=\"\"\n",
    "        motAttributs[\"ABphon\"]=\"\"\n",
    "    result=E.motBDL(graphie,motAttributs)\n",
    "#    print etree.tostring(result,encoding=\"utf8\")\n",
    "#    print (cat,ms,vs,phono,mot)\n",
    "#    u'<mot cat=\"%s\" ms=\"%s\" vs=\"%s\" phon=\"%s\">%s</mot>' % (cat,ms,vs,phono,mot)\n",
    "    return result\n",
    "    \n",
    "def enchasseXML(mot, phono):\n",
    "    if isinstance(phono,str):\n",
    "        phono=phono.decode(\"utf8\")\n",
    "    result=E.motBDL(mot,{\"phon\":phono})\n",
    "#    u'<mot phon=\"%s\">%s</mot>' % (phono, mot)\n",
    "    return result\n",
    "\n",
    "def enchasseTour(phrase):\n",
    "    result=E.tour(phrase,{\"id\":\"%06d\"%nPhrase})\n",
    "    return result\n",
    "\n",
    "def enchasseNonMot(nonmot):\n",
    "    result=E.punct(nonmot)\n",
    "#    u'<punct>%s</punct>' % (nonmot)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitementTRS(rootTRS):\n",
    "    a=1\n",
    "    nPhrase=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        phrase=ligne.strip()\n",
    "        api=E.tour()\n",
    "        mot_numero=0\n",
    "        element_numero=0\n",
    "        while elementsPhrases[nPhrase] and element_numero < len(elementsPhrases[nPhrase]):\n",
    "            if not mot_numero < len(motsPhrases[nPhrase]) or motsPhrases[nPhrase][mot_numero]!=elementsPhrases[nPhrase][element_numero].lower():\n",
    "                api.append(enchasseNonMot(elementsPhrases[nPhrase][element_numero]))\n",
    "            elif liaison_possible(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                if liaison_obligatoire(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    api.append(enchasseBDLexique(nPhrase,mot_numero,True))\n",
    "                elif liaison_facultative(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    if facultatives:\n",
    "                        api.append(enchasseBDLexique(nPhrase,mot_numero,True))\n",
    "                    else :\n",
    "                        api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                else:\n",
    "                    api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero+=1\n",
    "            else:\n",
    "                api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero = mot_numero+1\n",
    "            element_numero+=1\n",
    "        a=a+1\n",
    "        if phrase!=\"\":\n",
    "            phraseConnecteurs=set()\n",
    "            for connecteur in connecteurs:\n",
    "                if \" \" in connecteur:\n",
    "                    connecteurParties=connecteur.split(\" \")\n",
    "                else:\n",
    "                    connecteurParties=[connecteur]\n",
    "                for i in range(len(elementsPhrases[nPhrase])-len(connecteurParties)+1):\n",
    "                    if connecteurParties==elementsPhrases[nPhrase][i:i+len(connecteurParties)]:\n",
    "                        phraseConnecteurs.add(connecteur)\n",
    "            if phraseConnecteurs:\n",
    "#                print phraseConnecteurs\n",
    "                api.set(\"connecteurs\",\",\".join(phraseConnecteurs))\n",
    "            api.set(\"nbmots\",str(len(api.xpath(\"//tour/motBDL\"))))\n",
    "            api.set(\"id\",\"%06d\"%nPhrase)\n",
    "            noeudAttachement=ligne.getparent()\n",
    "            if noeudAttachement.text==None:\n",
    "                noeudAttachement.tail=None\n",
    "                noeudAttachement.addnext(api)\n",
    "            else:\n",
    "                noeudAttachement.text=None\n",
    "                try:\n",
    "                    noeudAttachement.append(api)\n",
    "                except TypeError:\n",
    "                    print phrase, noeudAttachement\n",
    "                    noeudAttachement.append(api)\n",
    "        else:\n",
    "            ligne.getparent().tail=None\n",
    "        nPhrase+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- Insertion d'un set sur les nouvellesExceptions pour éviter les entrées multiples\n",
    "- Ajout d'un test pour vérifier que les nouvellesExceptions sont nouvelles\n",
    "\n",
    "#TO DO\n",
    "- Ajouter un message pour dire que le résultat a été concaténé au fichier existant si c'est le cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraireMotsTRS(motsCorpus,phon):\n",
    "    for entry in bdlexique:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(u';')\n",
    "        if p[0].lower() in motsCorpus:\n",
    "            if p[2]==\"@\" and not p[3] in [\"N\",\"V\",\"J\",\"K\"]:\n",
    "                p[1]+=p[2]\n",
    "                p[2]=\"\"\n",
    "                if len(p)<7:\n",
    "                    for i in range(len(p)+1,7):\n",
    "                        p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8],p[9])\n",
    "    return phon\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if fichier_exceptions:\n",
    "    for entry in inconnus:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(\";\")\n",
    "        if len(p[1])!=0:\n",
    "            if len(p)<9:\n",
    "                for i in range(len(p)+1,7):\n",
    "                    p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "        oldExceptions.append(p[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2.b. mettre les phrases phonémisées dans un fichier\n",
    "enteteXML=[\n",
    "            u'<?xml version=\"1.0\" encoding=\"UTF8\" standalone=\"yes\"?>',\n",
    "            u'<?xml-stylesheet type=\"text/xsl\" href=\"phonemise-TRS.xsl\"?>',\n",
    "            u'<!DOCTYPE Trans SYSTEM \"trans-14-corpus.dtd\">'\n",
    "          ]\n",
    "\n",
    "#print [etree.tostring(rootTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\")]\n",
    "motsAbreges={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiretsTRS(contenuTRS):\n",
    "    sortie=[]\n",
    "    for ligne in contenuTRS:\n",
    "        m=re.search(ur'Event desc=\"-(\\w+)\" .* extent=\"(\\w+)\"',ligne)\n",
    "        if m:\n",
    "            ligne=ligne.replace('desc=\"-%s\"'%m.group(1),'desc=\"%s\"'%m.group(1)).replace('extent=\"%s\"'%m.group(2),'extent=\"end\"')\n",
    "        m=re.search(ur'Event desc=\"(\\w+)-\" .* extent=\"(\\w+)\"',ligne)\n",
    "        if m:\n",
    "            ligne=ligne.replace('desc=\"%s-\"'%m.group(1),'desc=\"%s\"'%m.group(1)).replace('extent=\"%s\"'%m.group(2),'extent=\"begin\"')\n",
    "        sortie.append(ligne)\n",
    "    return sortie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baliserTRS(nomTRS):\n",
    "    with open(nomTRS,\"r\") as temp:\n",
    "        header= temp.readlines()[0]\n",
    "        s=re.search(ur'encoding=\"(.+)\"',header)\n",
    "        if s:\n",
    "            TRS=codecs.open(nomTRS,\"r\",encoding=s.group(1)).readlines()\n",
    "        else:\n",
    "            TRS=open(nomTRS,\"r\").readlines()\n",
    "    sortie=\"\"\n",
    "    fins=[]\n",
    "    debs=[]\n",
    "    TRS=tiretsTRS(TRS)\n",
    "    for numLigne,ligne in enumerate(TRS[2:]):\n",
    "        ligne=ligne.strip()\n",
    "        if 0<=numLigne <=10:\n",
    "            print ligne\n",
    "        disfluenceGen=re.match('<Event desc=\"disflu\" type=\"(noise|lexical|pronounce|language|entities)\" extent=\"(begin|end)\"/>',ligne)\n",
    "        disfluenceSpec=re.match('<Event desc=\"([Mm]d|[Rr]ep|[Aa]uto[Cc]|[Nn]on[Ff]inie|[Mm][Cc]oup)\" type=\"pronounce\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        eventAutre=re.match('<Event desc=\"([^\"]+)\" type=\"([^\"]+)\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        tagTurn=re.match('<(/?)Turn.*>',ligne)        \n",
    "        if disfluenceGen:\n",
    "            if debug: print \"disfluGen\",disfluenceGen.group(2)\n",
    "            if disfluenceGen.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceGen.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceGen.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif disfluenceSpec:\n",
    "            if debug: print \"disfluSpec\",disfluenceSpec.group(2)\n",
    "            if disfluenceSpec.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceSpec.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceSpec.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif eventAutre:\n",
    "            if debug: print \"Autre\",eventAutre.group(3)\n",
    "            descEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(1)])\n",
    "            typeEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(2)])\n",
    "            if eventAutre.group(3)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<%s desc=\"%s\">'%(typeEvent,descEvent)+\"\\n\")\n",
    "                fins.append(\"</%s>\"%typeEvent)\n",
    "            elif eventAutre.group(3)==\"end\":\n",
    "#                print numLigne\n",
    "                if fins:\n",
    "                    sortie+=(\"</%s>\"%typeEvent+\"\\n\")\n",
    "                    chaine=fins.pop()\n",
    "                else:\n",
    "                    print \"PB no stack to pop\", typeEvent,numLigne\n",
    "                if chaine!=\"</%s>\"%typeEvent:\n",
    "                    print \"PB\",chaine, typeEvent,numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif tagTurn:\n",
    "            if debug: print tagTurn.group(1)+\"Turn\"\n",
    "            if tagTurn.group(1)==\"/\" and fins:\n",
    "                lenFins=len(fins)\n",
    "                for num in range(lenFins):\n",
    "                    chaine=fins.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    debs.append(chaine.replace(\"/\",\"\"))\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "            if tagTurn.group(1)==\"\" and debs:\n",
    "                lenDebs=len(debs)\n",
    "                for num in range(lenDebs):\n",
    "                    chaine=debs.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    fins.append(chaine.replace(\"<\",\"</\"))\n",
    "        else:\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "        if debug and (debs or fins):\n",
    "            print debs, fins\n",
    "    return sortie"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dossiersTRS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "paires={num:el for num,el in enumerate(listeDossiersTRS)}\n",
    "for paire in paires:\n",
    "    print paire,paires[paire]\n",
    "#debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/\n",
      "['/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-2.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-1.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-1.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie2.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-2-BDL2.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-1-BDL2.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-1-BDL2.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie2-BDL2.trs']\n",
      "fichier Exception /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/inconnus.txt\n",
      "\n",
      "0 0 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-2.trs\n",
      "<Trans scribe=\"Marie-Clara\" audio_filename=\"record2017-Maïlys\" version=\"6\" version_date=\"171216\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#1\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"301.537\">\n",
      "<Turn startTime=\"0\" endTime=\"4.753\" speaker=\"spk1\">\n",
      "<Sync time=\"0\"/>\n",
      "oui donc pour rev(e)nir au portable\n",
      "<Event desc=\"tic\" type=\"lexical\" extent=\"begin\"/>\n",
      "PB no stack to pop pronounce 261\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-2-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-2-BDL2.trs\n",
      "0 1 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-1.trs\n",
      "<Trans scribe=\"mvettori001\" audio_filename=\"record2017_corpus_Floriane wav\" version=\"12\" version_date=\"171217\">\n",
      "<Topics>\n",
      "<Topic id=\"to1\" desc=\"non trans\"/>\n",
      "<Topic id=\"to2\" desc=\"lu\"/>\n",
      "</Topics>\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#1\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"1413.777\">\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-1-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-Clara-1-BDL2.trs\n",
      "0 2 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-1.trs\n",
      "<Trans scribe=\"marie\" audio_filename=\"20171119_001-_AudioTrimmer_com_-_AudioTrimmer_com_ - Copie\" version=\"11\" version_date=\"171217\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#3\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"speaker#1\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"897.048\">\n",
      "<Turn startTime=\"0\" endTime=\"1.743\">\n",
      "<Sync time=\"0\"/>\n",
      "///\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-1-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie-1-BDL2.trs\n",
      "0 3 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie2.trs\n",
      "<Trans scribe=\"marie\" audio_filename=\"Enregistrement 2 de Marie\" version=\"7\" version_date=\"171217\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#1\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"917.205\">\n",
      "<Turn startTime=\"0\" endTime=\"6.788\" speaker=\"spk1\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "<Event desc=\"tic\" type=\"lexical\" extent=\"begin\"/>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie2-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/Marie2-BDL2.trs\n",
      "fichierExceptions /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Vettori/inconnus.txt\n",
      "and pre ciao partiarcat déja aulieu avertisssements y' quelquechose xx pratiquemment derrrière tai ptetre connait paralait roti parcequ' xxxx rucs gépgraphe reveillé précisémment engeuler paranoïoaque tou)te jen is paler mhn semstre persone gentimment xxx oscultent vélib jetrouve ç' etlà emmenerait personellement dêtre convo parceque parcque philosphe choppée of d(e arivant squatte mélée ommercial êtrequ' je) cequ' ily\n",
      "1 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/\n",
      "['/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur 21-30.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur 12-20.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur 21-30-BDL2.trs', '/Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur 12-20-BDL2.trs']\n",
      "fichier Exception /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/inconnus.txt\n",
      "\n",
      "1 0 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur 21-30.trs\n",
      "<Trans scribe=\"Victoria\" audio_filename=\"Locuteur 21-31\" version=\"5\" version_date=\"180416\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Interviewer\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Sportif L21\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"Sportif L22\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk4\" name=\"Sportif L23\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk5\" name=\"Sportif L24\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk6\" name=\"Sportif L25\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk7\" name=\"Sportif L26\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk8\" name=\"Sportif L27\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk9\" name=\"Sportif L28\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur\\ 21-30-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur\\ 21-30-BDL2.trs\n",
      "1 1 /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur 12-20.trs\n",
      "<Trans scribe=\"Victoria\" audio_filename=\"Locuteur 12-20\" version=\"7\" version_date=\"180416\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Interviewer\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Sportif L12\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"Sportif L13\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk4\" name=\"Sportif L14\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk5\" name=\"Sportif L15\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk6\" name=\"Sportif L16\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk7\" name=\"Sportif L17\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk8\" name=\"Sportif L18\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk9\" name=\"Sportif L19\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "xsltproc /Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/TRS-phon.xsl /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur\\ 12-20-BDL2.xml > /Users/gilles/pCloud\\ Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/Locuteur\\ 12-20-BDL2.trs\n",
      "fichierExceptions /Users/gilles/pCloud Drive/FOD/Corpus-2017/0AjustementsTIC/Richard/inconnus.txt\n",
      "satifait parcequ' débrief enfaite porfer beacoup advaisaires\n"
     ]
    }
   ],
   "source": [
    "oldExceptions=[]\n",
    "for numDossier,dossier in enumerate(listeDossiersTRS):\n",
    "    if numDossier in numDossiers:\n",
    "        print numDossier, dossier\n",
    "        fichiersTRS=glob.glob(dossier+\"/*.trs\")\n",
    "        print fichiersTRS\n",
    "        fichiersTRS=[f for f in fichiersTRS if not f.endswith(\"-BDL2.trs\")]\n",
    "        fichierExceptions=dossiersTRS[dossier]\n",
    "        print \"fichier Exception\",fichierExceptions\n",
    "        print\n",
    "        nouvellesExceptions=[]\n",
    "        boolExceptions=True\n",
    "        try:\n",
    "    #        print fichierExceptions\n",
    "            exceptions=codecs.open(fichierExceptions,\"r\",encoding='utf8')\n",
    "            inconnus=exceptions.readlines()\n",
    "            exceptions.close()\n",
    "    #        print inconnus\n",
    "        except IOError:\n",
    "            boolExceptions=False\n",
    "        if fichier_exceptions and boolExceptions:\n",
    "            oldExceptions=[]\n",
    "            for entry in inconnus:\n",
    "                entry=entry.strip()\n",
    "                if 0: print entry\n",
    "                p=entry.split(\";\")\n",
    "                if len(p)<9:\n",
    "                    for i in range(len(p)+1,10):\n",
    "                        p.append(u\"\")\n",
    "                if 0: print p\n",
    "                if len(p[1])!=0:\n",
    "                    phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "                oldExceptions.append(p[0].lower())\n",
    "        for numTRS,nomTRS in enumerate(fichiersTRS):\n",
    "            print numDossier,numTRS,nomTRS\n",
    "            fichierBDL=nomTRS[:-4]+\"-BDL2.xml\"\n",
    "            if nomTRS.split(\"/\")[-1] in sansRebalisageFichiers:\n",
    "                print \"SANS reBALISER\"\n",
    "                xmlTRS=etree.parse(nomTRS,parser)\n",
    "                print \"FIN parse\"\n",
    "            else:\n",
    "                fichierTRS=baliserTRS(nomTRS)\n",
    "                print \"FIN reBALISER\"\n",
    "                xmlTRS=etree.fromstring(fichierTRS,parser)\n",
    "                print \"FIN fromstring\"\n",
    "            (motsCorpus,motsPhrases,elementsPhrases)=listerMotsCorpus(xmlTRS)\n",
    "            print \"FIN lister mots\"\n",
    "            phon=extraireMotsTRS(motsCorpus,phon)\n",
    "            print \"FIN extraire mots\"\n",
    "            traitementTRS(xmlTRS)\n",
    "            print \"FIN traitement\"\n",
    "            with codecs.open(fichierBDL, \"w\", encoding='utf8') as f:\n",
    "                for ligne in enteteXML:\n",
    "                    f.write(ligne+u\"\\n\")\n",
    "                f.write(etree.tostring(xmlTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\"))\n",
    "            cliBDL=fichierBDL.replace(\" \",\"\\ \")\n",
    "            cliXSLT=fichierXSLT.replace(\" \",\"\\ \")\n",
    "            cliPhonTRS=fichierBDL.replace(\".xml\",\".trs\").replace(\" \",\"\\ \")\n",
    "            cliText=\"xsltproc %s %s > %s\"%(cliXSLT,cliBDL,cliPhonTRS)\n",
    "            print cliText\n",
    "            os.system(cliText)  \n",
    "        with codecs.open(fichierExceptions, \"a\", encoding='utf8') as f:\n",
    "            print \"fichierExceptions\",fichierExceptions\n",
    "            for n in set(nouvellesExceptions):\n",
    "                print n,\n",
    "                if not (n in oldExceptions): \n",
    "                    f.write(n+u\";;;;;;;;;;;;\")\n",
    "                    f.write(\"\\n\")\n",
    "            print\n",
    "        oldExceptions=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPremierDossier=10\n",
    "numDernierDossier=0\n",
    "if numDernierDossier<numPremierDossier or numDernierDossier==0:\n",
    "    numDernierDossier=100\n",
    "elif numDernierDossier==numPremierDossier:\n",
    "    numDernierDossier+=1\n",
    "numDossiers=range(numPremierDossier,numDernierDossier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problèmes de noms de fichiers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fichierPbs={}\n",
    "for numDossier,dossier in enumerate(glob.glob(dossierCorpus+\"*/\")):\n",
    "    fichierPbs[numDossier]=glob.glob(dossier+\"*'*.trs\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for fichier in fichierPbs[30]:\n",
    "    mPar=re.findall(ur\"\\([^)]+\\)\",fichier.split(\"/\")[-1])\n",
    "    oldString=mPar[0]\n",
    "    newString=mPar[0][1:-1]\n",
    "    newName=fichier.replace(oldString,newString).replace(\".trs\",\"-PBdeNOM.trs\")\n",
    "    if os.path.isfile(newName):\n",
    "        print \"PB fichier existant\",fichier,newName\n",
    "    else:\n",
    "        os.rename(fichier,newName)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for fichier in fichierPbs[26]:\n",
    "    newName=fichier.replace(\"'\",\" \").replace(\".trs\",\"-PBdeNOM.trs\")\n",
    "    if os.path.isfile(newName):\n",
    "        print \"PB fichier existant\",fichier,newName\n",
    "    else:\n",
    "        os.rename(fichier,newName)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fichierPbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
