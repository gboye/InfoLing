{
 "metadata": {
  "name": "",
  "signature": "sha256:bf012734987bfd800ee84109bac35e5a724bab2ab98d90d325358bd7b7ce865e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import sys\n",
      "import codecs\n",
      "import re\n",
      "import pdb # ajouter pdb.set_trace() \u00e0 l'endroit o\u00f9 on veut le d\u00e9bugueur"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Modif GB 12/04/14\n",
      "- mise en texte des deux blocs de traitement de la ligne de commande"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "if len(sys.argv) < 3:\n",
      "    print (\"Veuillez renseigner tous les champs  : \\n 1. un fichier segment\u00e9 \\n 2. le fichier du lexique \\n 3. \u00e9ventuellement un fichier d'exceptions\")\n",
      "    sys.exit()\n",
      "\n",
      "# ouvre le fichier segment\u00e9 et affiche un message d'erreur s'il ne peut pas \u00eatre ouvert\n",
      "try:\n",
      "    fichier=codecs.open(sys.argv[1],\"r\")\n",
      "except IOError:\n",
      "    print ('le fichier \"'+ sys.argv[1]+ '\" ne peut pas \u00eatre ouvert',)\n",
      "    sys.exit()\n",
      "# ouvre BDLex et affiche un message d'erreur s'il ne peut pas \u00eatre ouvert\n",
      "try:\n",
      "    lexicon=codecs.open(sys.argv[2],\"r\")\n",
      "except IOError:\n",
      "    print ('le fichier \"'+ sys.argv[2]+ '\" ne peut pas \u00eatre ouvert',)\n",
      "    sys.exit()\n",
      "# ouvre le fichier d'exceptions(s'il est l\u00e0) et affiche un message d'erreur s'il ne peut pas \u00eatre ouvert\n",
      "fichier_exceptions=False # pour ne pas ex\u00e9cuter la pr\u00e9paration des exceptions s'il n'y a pas de fichier\n",
      "if len(sys.argv) == 4:\n",
      "    try:\n",
      "        exceptions=codecs.open(sys.argv[3],\"r\")\n",
      "        fichier_exceptions=True\n",
      "    except IOError:\n",
      "        print ('le fichier \"'+ sys.argv[3]+ '\" ne peut pas \u00eatre ouvert', )\n",
      "        sys.exit()"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# ajouter les liaisons facultatives ou pas ?\n",
      "facultatives=input(\"Voulez-vous ajouter les liaisons facultatives ou pas ?\\n1 = Oui, 0 = Non (suivi d'Entr\u00e9e) : \")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Modif GB 12/04/14\n",
      "- extension du bloc pour permettre d'ajouter les trois fichiers \u00e0 la main"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fichierLexique=\"../../phonemisation/bdlexique.txt\"\n",
      "lexicon=codecs.open(fichierLexique,\"r\")\n",
      "fichierCorpus=\"corpusphon-utf8.txt\"\n",
      "fichier=codecs.open(fichierCorpus,\"r\")\n",
      "fichierExceptions=\"inconnus.txt\"\n",
      "exceptions=codecs.open(fichierExceptions,\"r\")\n",
      "fichier_exceptions=True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "facultatives = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrases=[]\n",
      "phon={}\n",
      "result=[]\n",
      "nouvellesExceptions = []\n",
      "output=[]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Pr\u00e9paration des fichiers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "algorithme\n",
      "\n",
      "ajouter chaque ligne du fichier \u00e0 phrases[]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lowerAccents(chaine):\n",
      "    if isinstance(chaine,str):\n",
      "        try:\n",
      "            result=chaine.decode(\"utf8\").lower().encode(\"utf8\")\n",
      "        except:\n",
      "            print chaine\n",
      "        return result\n",
      "    elif isinstance(chaine,unicode):\n",
      "        return chaine.lower().encode('utf8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in fichier:\n",
      "    line=line.strip()\n",
      "    if line != '':\n",
      "        phrases.append(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fichier.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "algorithme\n",
      "\n",
      "extraire de BDLex 0.forme fl\u00e9chie, 1.phon\u00e9tique, 2.liaison, 3.cat-gram, 4.genre+nombre"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for entry in lexicon:\n",
      "    entry=entry.strip()\n",
      "    p=entry.split(';')\n",
      "    phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lexicon.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "algorithme\n",
      "\n",
      "extraire du fichier d'exceptions les m\u00eames donn\u00e9es que pour BDLex"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Modif GB 12/04/14\n",
      "- fait une liste des exceptions lues pour ne pas les rajouter \u00e0 la fin\n",
      "- \u00e9viter de tenir compte des exceptions non renseign\u00e9es\n",
      " - les mots du fichier exceptions sans transcriptions \u00e9taient transcrits par une chaine vide..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if fichier_exceptions:\n",
      "    oldExceptions=[]\n",
      "    for entry in exceptions:\n",
      "        entry=entry.strip()\n",
      "        p=entry.split(';')\n",
      "        if len(p[1])!=0:\n",
      "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4])\n",
      "        oldExceptions.append(p[0].lower())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exceptions.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for exception in oldExceptions:\n",
      "    print (exception)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "end\n",
        "y'\n",
        "jacqueline\n",
        "week\n",
        "plupart\n",
        "elys\u00e9e\n",
        "tap\n",
        "impr\u00e9ssionnant\n",
        "lucas\n",
        "quest\n",
        "javie\n",
        "pshit\n",
        "chan\n",
        "montaren\n",
        "ida\n",
        "oc\u00e9ane\n",
        "wow\n",
        "main'\n",
        "chaine\n",
        "texto\n",
        "kill\n",
        "kiffe\n",
        "guadeloupe\n",
        "angleterre\n",
        "cuil\u00e0\n",
        "quil\n",
        "cetera\n",
        "dja\n",
        "yoda\n",
        "obiwan\n",
        "roh\n",
        "ct'\n",
        "inqui\u00e8terait\n",
        "r'\n",
        "vador\n",
        "calins\n",
        "re\n",
        "pac'\n",
        "anne\n",
        "ss\n",
        "paul\n",
        "dlc\n",
        "anxiet\u00e9\n",
        "comares\n",
        "alhambra\n",
        "david\n",
        "of\n",
        "mappelle\n",
        "cque\n",
        "meuh\n",
        "pschit\n",
        "heumvoil\u00e0\n",
        "courgettes\n",
        "prisoniers\n",
        "emb\u00eatre\n",
        "rez\n",
        "oula\n",
        "'\n",
        "calin\n",
        "jsuis\n",
        "wii\n",
        "toulon\n",
        "auschwitz\n",
        "bil\n",
        "dossin\n",
        "gateaux\n",
        "italie\n",
        "rebaign\u00e9e\n",
        "ch'\n",
        "gommettes\n",
        "sappellent\n",
        "cor\u00e9tha\n",
        "gad\n",
        "noob\n",
        "tropez\n",
        "l\u00e9a\n",
        "mhmh\n",
        "c4\n",
        "heum\n",
        "kholles\n",
        "coninuent\n",
        "sylvia\n",
        "dfr\u00e8re\n",
        "gameplay\n",
        "france\n",
        "sylvie\n",
        "commentary\n",
        "kiki\n",
        "nounouche\n",
        "tchernobil\n",
        "alain\n",
        "ouark\n",
        "speed\n",
        "black\n",
        "tchoupi\n",
        "jo\n",
        "pc\n",
        "nathan\n",
        "is\n",
        "serena\n",
        "xbox\n",
        "apres\n",
        "tite\n",
        "post\n",
        "tites\n",
        "soizante\n",
        "alya\n",
        "gomettes\n",
        "you\n",
        "mulhac\u00e9n\n",
        "ref'\n",
        "homisoya\n",
        "parc'\n",
        "ya\n",
        "ptit\n",
        "ouah\n",
        "janass\n",
        "sque\n",
        "justy\n",
        "buggu\u00e9\n",
        "\u00e9changait\n",
        "espagne\n",
        "f'\n",
        "gard\n",
        "birkenau\n",
        "couilles\n",
        "quelq'\n",
        "maintenat\n",
        "b\u00e9h\n",
        "p'\n",
        "qg\n",
        "r\u00e9mi\n",
        "pr\u00e9pa\n",
        "lilo\n",
        "bitch\n",
        "mathilde\n",
        "min\n",
        "nan\n",
        "rapha\u00ebl\n",
        "dark\n",
        "tsouviens\n",
        "pff\n",
        "mmhh\n",
        "tit\n",
        "wul\n",
        "parce\n",
        "oulika\n",
        "tirlemont\n",
        "urssi\n",
        "gaulle\n",
        "et'\n",
        "kirikou\n",
        "st\u00e9rimar\n",
        "lympe\n",
        "cookie\n",
        "jai\n",
        "titou\n",
        "wup\n",
        "grifouill\u00e9\n",
        "faustine\n",
        "restau\n",
        "esther\n",
        "rattr\n",
        "kikinette\n",
        "atchoume\n",
        "pyvalone\n",
        "over\n",
        "dmande\n",
        "obs\n",
        "langoiran\n",
        "commercants\n",
        "stromae\n",
        "mat'\n",
        "haribo\n",
        "p\u00e8riode\n",
        "chuis\n",
        "quarantre\n",
        "javais\n",
        "qu\n",
        "drancy\n",
        "numa\n",
        "sil\u00e9sie\n",
        "chantal\n",
        "plait\n",
        "que'\n",
        "dinette\n",
        "anakin\n",
        "maines\n",
        "ront\n",
        "d\u00e9gout\u00e9\n",
        "\u00e9\n",
        "asseoit\n",
        "matignon\n",
        "toup\n",
        "minnie\n",
        "cest\n",
        "grimli\n",
        "wc\n",
        "simon\n",
        "inde\n",
        "life\n",
        "paou\n",
        "c\u00e9tait\n",
        "hyper\n",
        "web\n",
        "2\n",
        "paraitre\n",
        "daccord\n",
        "pr\u00e9v'\n",
        "valentine\n",
        "beh\n",
        "baschrum\n",
        "h&m\n",
        "pa'\n",
        "int\u00e9r\u00e9ss\u00e9e\n",
        "cl\u00e9lia\n",
        "microstat\n",
        "coca\u00efnoman\n",
        "andalousie\n",
        "prc'\n",
        "chocos\n",
        "slalooms\n",
        "zacky\n",
        "calinours\n",
        "couine\n",
        "inint\u00e9r\u00e9ssant\n",
        "compl\u00e8t'\n",
        "ui\n",
        "sui\n",
        "spaak\n",
        "mh\n",
        "tc'\n",
        "zacharie\n",
        "y\u00e9\u00e9\n",
        "ines\n",
        "mickey\n",
        "cui\n",
        "antipuc\u00e9e\n",
        "jam\n",
        "dragibus\n",
        "londres\n",
        "\u00e9gal'\n",
        "bruxelles\n",
        "amenerai\n",
        "montmartre\n",
        "let\n",
        "tabanac\n",
        "henri\n",
        "loire\n",
        "yavait\n",
        "marseille\n",
        "samantha\n",
        "atchoum\n",
        "vrait\n",
        "eumh\n",
        "ach\n",
        "dounia\n",
        "chateaux\n",
        "nant\n",
        "europe\n",
        "legend\n",
        "clovis\n",
        "homi\n",
        "ja\n",
        "commme\n",
        "boing\n",
        "pasque\n",
        "orsay\n",
        "gilles\n",
        "etre\n",
        "tavais\n",
        "ptetre\n",
        "j\u00e0\n",
        "mmh\n",
        "facielement\n",
        "eric\n",
        "euuh\n",
        "ouh\n",
        "ezekel\n",
        "colombie\n",
        "belgique\n",
        "piou\n",
        "elmaleh\n",
        "vincent\n",
        "edith\n",
        "yo\n",
        "louvre\n",
        "snickers\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fonctions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. V\u00e9rifier si le mot existe"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "algorithme\n",
      "\n",
      "+ si le mot est dans BDLex, ok\n",
      "+ s'il y a un espace dans le mot,\n",
      "    * le mot est divis\u00e9 en deux et\n",
      "    * si les mots existent dans bdlex, ok\n",
      "    * sinon les mots sont ajout\u00e9s aux nouvelles exceptions et mis entre \u00e9toiles\n",
      "+ s'il y a un apostrophe dans le mot,\n",
      "    * le mot est divis\u00e9 en deux\n",
      "    * si les mots existent dans bdlex, ok\n",
      "    * sinon les mots sont ajout\u00e9s aux nouvelles exceptions et mis entre \u00e9toiles\n",
      "+ dans les autres cas, le mot est ajout\u00e9 aux nouvelles exceptions et mis entre \u00e9toiles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def verifier_mot(mot):\n",
      "        sampa=\"\"\n",
      "        if mot in phon.keys():\n",
      "            sampa += phon[mot][0]\n",
      "        elif \" \" in mot:\n",
      "            mots = mot.split()\n",
      "            for mot in mots:\n",
      "                if mot in phon.keys():\n",
      "                    sampa += phon[mot][0]+\" \"\n",
      "                elif mot != \"\":\n",
      "                    sampa += \"***\"+mot+\"*** \"\n",
      "        elif \"'\" in mot:\n",
      "            mots = mot.split(\"'\")\n",
      "            mots[0]=mots[0]+\"'\"\n",
      "            for mot in mots:\n",
      "                if mot in phon.keys():\n",
      "                    sampa += phon[mot][0]+\" \"\n",
      "                elif mot != \"\":\n",
      "                    nouvellesExceptions.append(mot)\n",
      "                    sampa += \"***\"+mot+\"*** \"\n",
      "        elif mot != \"\": \n",
      "            nouvellesExceptions.append(mot)\n",
      "            sampa=\"***\"+mot+\"*** \"\n",
      "        return sampa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verifier_mot(\"manger\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "'manger'"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verifier_mot(\"aujourd'hui\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "\"aujourd'hui\""
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verifier_mot(\"mangr\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "'***mangr*** '"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verifier_mot(\"jacqueline\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "'jacqueline'"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verifier_mot(\"manger mot\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "'manger mot '"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verifier_mot(\"manger mt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "'manger ***mt*** '"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verifier_mot(\"j'ai\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "\"j' ai \""
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verifier_mot(\"c\u00f4t\u00e9\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "'c\\xc3\\xb4t\\xc3\\xa9'"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. traduire le SAMPA de BDLexique en API"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Modif GB 12/04/14\n",
      "- ajout du r et du \u00e2\n",
      "- ajout des exemples associ\u00e9s en dessous"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# traduire SAMPA-BDLex en API\n",
      "def sampa2api(sampa):\n",
      "    api=re.sub('S','\u0283',sampa) \n",
      "    api=re.sub('Z','\u0292', api)\n",
      "    api=re.sub('N','\u014b',api)\n",
      "    api=re.sub('J','\u0272',api)\n",
      "    api=re.sub('r','\u0281',api) \n",
      "    api=re.sub('H','\u0265',api)\n",
      "    api=re.sub('E','\u025b',api)\n",
      "    api=re.sub('2','\u00f8',api)\n",
      "    api=re.sub('9','\u0153',api)\n",
      "    api=re.sub('6','\u0259',api)\n",
      "    api=re.sub('O','\u0254',api)\n",
      "    api=re.sub('\u00e8','e',api)   \n",
      "    api=re.sub('\u00f2','o',api)    \n",
      "    api=re.sub('\u00e2','\u0251\u0303',api)   \n",
      "    api=re.sub('\u00ea','\u025b\u0303',api)   \n",
      "    api=re.sub('\u00fb','\u0153\u0303',api)  \n",
      "    api=re.sub('\u00f4','\u0254\u0303',api)       \n",
      "    api=re.sub('@','\u0259',api)\n",
      "    api=re.sub('n\"','n',api) \n",
      "    api=re.sub('t\"','t',api) \n",
      "    api=re.sub('z\"','z',api) \n",
      "    api=re.sub('R\"','\u0281',api) \n",
      "    api=re.sub('p\"','p',api) \n",
      "    return api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampa2api(phon[\"ai\"][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "'e'"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampa2api(phon[\"chat\"][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "'\\xca\\x83a'"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampa2api(phon[\"aucun\"][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "'ok\\xc5\\x93\\xcc\\x83'"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampa2api(phon[\"chant\"][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "'\\xca\\x83\\xc9\\x91\\xcc\\x83'"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampa2api(phon[\"march\u00e9\"][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "'ma\\xca\\x81\\xca\\x83e'"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampa2api(phon[\"jacqueline\"][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "'\\xca\\x92ak\\xc9\\x99lin'"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3. trimer le mot en cours"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "algorithme\n",
      "\n",
      "+ la ponctuation est remplac\u00e9e par un espace\n",
      "+ les espaces aux extr\u00e9mit\u00e9s sont effac\u00e9s\n",
      "+ le mot est mis en minuscules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def trimer(mot):\n",
      "    mot=lowerAccents(mot)\n",
      "#    for p in ',;.:-?!()\"':\n",
      "    for p in ',;.:-?!()\u201c\u201d\u2018\u2019\u201b\u201f\u2032\u2033\u00b4\u02dd\"\u00ab\u00bb':\n",
      "        mot=mot.replace(p, ' ')\n",
      "    mot=mot.strip()\n",
      "    return mot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trimer(\",;. :trois-?!( )\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "'trois'"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trimer(\"(essai)chaud\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "'essai chaud'"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trimer(\"gar\u00e7on.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "'gar\\xc3\\xa7on'"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trimer(\"vont-ils\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "'vont ils'"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chaine=u\"c\u00f4t\u00e9\"\n",
      "print chaine,len(chaine)\n",
      "trimer(chaine)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "c\u00f4t\u00e9 4\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "'c\\xc3 t\\xc3\\xa9'"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trimer(\"y'a\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "\"y'a\""
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "4. V\u00e9rifier si la liaison est possible"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "algorithme\n",
      "\n",
      "+ si le mot courant et le suivant ne sont pas dans lexicon, pas de liaison\n",
      "+ si le mot a une consonne dans le champ de la voyelle de liaison, check1 est vrai\n",
      "+ si le mot suivant commence par une voyelle, check2 est vrai\n",
      "\n",
      "  si check1 et check2 sont vrais, il y a liaison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def liaison_possible(phrase ,mot , mot_numero):\n",
      "    check1=0\n",
      "    check2=0\n",
      "    if mot in phon and phrase[mot_numero+1] in phon:\n",
      "        consonnes=['k\"', '(kt)\"', 'n\"', 'p\"', 'R\"', '@t\"', 't\"', '-V', '+V', '@z\"', 'z\"']\n",
      "        phoneme=phon[mot][2]\n",
      "        for phoneme in consonnes:\n",
      "            check1=1\n",
      "        \n",
      "        voyelles=[\"H\", \"j\", \"w\", \"E\", \"a\", \"2\", \"9\", \"6\", \"@\", \"y\", \"u\", \"O\", \"\u00f2\", \"o\", \"e\", \"\u00e8\", \"\u00ea\", \"\u00fb\", \"\u00f4\", \"i\"]\n",
      "        mot_suivant=phon[phrase[mot_numero+1]][1]\n",
      "        for v in voyelles:\n",
      "            if mot_suivant.startswith(v):\n",
      "                check2=1\n",
      "\n",
      "    if check1 and check2 :\n",
      "        return True\n",
      "    else:\n",
      "        return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5. v\u00e9rifier si la liaison est obligatoire"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "algorithme\n",
      "\n",
      "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
      "+ sinon pas de liaison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def liaison_obligatoire(phrase, mot, mot_numero):\n",
      "    determinant=[\"d\", \"P\"]\n",
      "    nom=[\"N\", \"G\", \"M\"]\n",
      "    adjectif=[\"J\", \"G\", \"M\"]\n",
      "    pronompers=[\"P\"]\n",
      "    verbe=[\"V\"]\n",
      "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
      "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
      "\n",
      "    if catgram_mot1 in determinant and catgram_mot2 in nom :\n",
      "        return True\n",
      "\n",
      "    elif catgram_mot1 in determinant and catgram_mot2 in adjectif :\n",
      "        return True\n",
      " \n",
      "    elif catgram_mot1 in pronompers and catgram_mot2 in verbe :\n",
      "        return True\n",
      "\n",
      "    elif catgram_mot1 in verbe and catgram_mot2 in pronompers :\n",
      "        return True\n",
      "\n",
      "    else:\n",
      "        return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phon[\"sommes\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "('sommes', 'sOm', '@', 'V', '2S')"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phon[\"armes\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "('armes', 'arm', '@', 'V', '2S')"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phon[\"cet\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "('cet', 'sEt', '+V', 'd', 'MS')"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cas de figure possibles:\n",
      "\n",
      "- DET + N\n",
      "    * ri + N:   d'animal, \n",
      "    * di + N:   certains \u00e9l\u00e9phants\n",
      "    * rd + N:   les animaux\n",
      "    * dd + N:   ces \u00e9t\u00e9s, cet \u00e9t\u00e9\n",
      "    * dp + N:   ton anorak\n",
      "    * rc + N:   aux armes\n",
      "- DET + ADJ:\n",
      "    * ri + ADJ:   d'\u00e9normes\n",
      "    * di + ADJ:   plusieurs immenses\n",
      "    * rd + ADJ:   les immenses\n",
      "    * dd + ADJ:   cet immense\n",
      "    * dp + ADJ:   son immense\n",
      "    * rc + ADJ:   aux immenses\n",
      "- PERS + V:\n",
      "    * SS + V:   m'\u00e9pate\n",
      "- V + PRO PERS: \n",
      "    * V + SS:   vont-ils\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "algorithme\n",
      "\n",
      "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
      "+ sinon pas de liaison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# v\u00e9rifier si la liaison est facultative\n",
      "def liaison_facultative(phrase, mot, mot_numero):\n",
      "    #pdb.set_trace()\n",
      "    nom=[\"N\", \"G\", \"M\"]\n",
      "    pluriel=[\"MP\", \"FP\"]\n",
      "    adjectif=[\"J\", \"G\", \"M\"]\n",
      "    verbe=[\"V\"]\n",
      "    pronompers=[\"P\"]\n",
      "    adverbe=[\"A\"]\n",
      "    preposition=[\"p\"]\n",
      "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
      "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
      "    genre_mot1=phon[phrase[mot_numero]][4]\n",
      "    \n",
      "    if (catgram_mot1 in nom) and (phon[phrase[mot_numero]][4] in pluriel) and (catgram_mot2 in adjectif) : \n",
      "        return True\n",
      "\n",
      "    elif (catgram_mot1 in verbe) and (catgram_mot2 not in pronompers):\n",
      "        return True\n",
      "\n",
      "    elif catgram_mot1 in adverbe :\n",
      "        return True\n",
      "    \n",
      "    elif catgram_mot1 in preposition : \n",
      "        return True\n",
      "\n",
      "    else :\n",
      "        return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cas de figure possibles :\n",
      "\n",
      "- N pl + ADJ: \n",
      "    * N + ADJ: monstres \u00e9normes \n",
      "    * G + ADJ: rivaux \u00e9normes\n",
      "- VERBE + TOUT-SAUF-PRO-PERS:\n",
      "    * V + N sont \u00e9l\u00e9phants\n",
      "    * V + G sommes abdicaires\n",
      "    * V + V sommes assis\n",
      "    * V + A sommes admirablement\n",
      "    * V + p sommes autour de\n",
      "    * V + di ont aucune\n",
      "    * V + rc sommes au\n",
      "- ADV + QQCH:\n",
      "    * ADV + N vraiment abruti\n",
      "    * ADV + G vraiment abandonn\u00e9\n",
      "    * ADV + V vraiment aim\u00e9\n",
      "    * ADV + J vraiment \u00e9tonnant\n",
      "    * ADV + ss vraiment ils\n",
      "    * ADV + A vraiment \u00e9tonnamment\n",
      "    * ADV + p vraiment attendu\n",
      "    * ADV + di vraiment autre \n",
      "    * ADV + rc vraiment au\n",
      "- PREP + QQCH:\n",
      "    * PREP + N tr\u00e8s amoureux\n",
      "    * PREP + G tr\u00e8s abandonn\u00e9\n",
      "    * PREP + V tr\u00e8s aim\u00e9\n",
      "    * PREP + J tr\u00e8s \u00e9tonnant\n",
      "    * PREP + SS tr\u00e8s ils\n",
      "    * PREP + A tr\u00e8s \u00e9tonnamment\n",
      "    * PREP + p tr\u00e8s attendu\n",
      "    * PREP + di tr\u00e8s autre\n",
      "    * PREP + rc tr\u00e8s au\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Traitement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ Partie 1\n",
      "*chaque phrase est prise individuellement,\n",
      "    * d\u00e9coup\u00e9e en blocs,\n",
      "        * qui sont chacuns trim\u00e9s si ce sont des mots\n",
      "        * s'il y a plusieurs mots dans le bloc, ils sont s\u00e9par\u00e9s\n",
      "    + Partie 2\n",
      "    * pour chaque couple de mots\n",
      "        * si la liaison est possible,\n",
      "            * et qu'elle est obligatoire, l'api avec la liaison est g\u00e9n\u00e9r\u00e9\n",
      "            * et qu'elle est facultative,\n",
      "                * si l'utilisateur l'a choisi, l'api avec la liaison est g\u00e9n\u00e9r\u00e9\n",
      "                * sinon l'api sans la liaison est g\u00e9n\u00e9r\u00e9\n",
      "\n",
      "        + Partie 3\n",
      "        * si la liaison n'est pas possible,\n",
      "            * si le mot est dans bdlex, l'api est g\u00e9n\u00e9r\u00e9\n",
      "            * sinon le mot est laiss\u00e9 tel quel (il a d\u00e9j\u00e0 les \u00e9toiles)        \n",
      "\n",
      "    * pour le dernier mot de la phrase, \n",
      "        * si le mot est dans bdlex, l'api est g\u00e9n\u00e9r\u00e9\n",
      "        * sinon le mot est laiss\u00e9 tel quel (il a d\u00e9j\u00e0 les \u00e9toiles) \n",
      "\n",
      "+ Partie 4\n",
      "* le message \u00e0 l'utilisateur et la phrase en api est imprim\u00e9e"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Modif GB 12/04/14\n",
      "- suppression du d\u00e9lai dans la boucle\n",
      " - pour 1500 lignes => 3 secondes sans ralentisseur, 1503 secondes avec "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# partie 1\n",
      "a=1\n",
      "for phrase in phrases:\n",
      "    api = \"\"\n",
      "    mots=re.split(\"[->< /@\\_]\", phrase)\n",
      "    phrasePropre = \"\"\n",
      "    for mot in mots:\n",
      "        mot = trimer(mot)\n",
      "        mot = verifier_mot(mot)\n",
      "        phrasePropre += mot+\" \"\n",
      "    phraseMots = phrasePropre.strip()\n",
      "    phraseMots = phrasePropre.split()\n",
      "\n",
      "    # partie 2    \n",
      "    mot_numero=0\n",
      "    while mot_numero <= len(phraseMots)-2:\n",
      "        \n",
      "        if liaison_possible(phraseMots, phraseMots[mot_numero], mot_numero):\n",
      " \n",
      "            if liaison_obligatoire(phraseMots, phraseMots[mot_numero], mot_numero):\n",
      "                api += sampa2api(phon[phraseMots[mot_numero]][1])+sampa2api(phon[phraseMots[mot_numero]][2]+\" \")\n",
      "\n",
      "            elif liaison_facultative(phraseMots, phraseMots[mot_numero], mot_numero):\n",
      "                if facultatives:\n",
      "                    api += sampa2api(phon[phraseMots[mot_numero]][1])+sampa2api(phon[phraseMots[mot_numero]][2]+\" \")\n",
      "                else :\n",
      "                    api += sampa2api(phon[phraseMots[mot_numero]][1])+\" \"\n",
      "            else:\n",
      "                if phraseMots[mot_numero] in phon:\n",
      "                    api += sampa2api(phon[phraseMots[mot_numero]][1]+\" \")\n",
      "                else:\n",
      "                    api += phraseMots[mot_numero]+\" \"\n",
      "        # partie 3\n",
      "        else:\n",
      "            if phraseMots[mot_numero] in phon:\n",
      "                api += sampa2api(phon[phraseMots[mot_numero]][1]+\" \")\n",
      "            else:\n",
      "                api += phraseMots[mot_numero]+\" \"\n",
      "        mot_numero = mot_numero+1\n",
      "    \n",
      "    if phraseMots[len(phraseMots)-1] in phon:\n",
      "        api += sampa2api(phon[phraseMots[len(phraseMots)-1]][1])\n",
      "    else:\n",
      "        api += phraseMots[mot_numero]\n",
      "    \n",
      "    # partie 4\n",
      "    sys.stdout.write(\"Traitement de \"+str(a)+\" sur \"+ str(len(phrases))+ \" phrases. \"+\"\\n\"+phrase+\"\\n\"+api+\"\\n\\n\"+chr(20))\n",
      "    sys.stdout.flush()\n",
      "    #time.sleep(1)\n",
      "    a=a+1\n",
      "    output.append(api)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 1 sur 1390 phrases. \n",
        "pour le week-end du patrimoine du quatorze et seize du quatorze et quinze septembre euh j'ai une voisine Jacqueline\n",
        "pu\u0281 l\u0259 wik \u025bnd dy pat\u0281imwan dy kat\u0254\u0281z e s\u025bz dy kat\u0254\u0281z e k\u025b\u0303z s\u025bpt\u0251\u0303b\u0281 \u0259 \u0292 e yn vwazin \u0292ak\u0259lin\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 2 sur 1390 phrases. \n",
        "qui m'avait promis\n",
        "ki m ave p\u0281omi\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 3 sur 1390 phrases. \n",
        "de m'amener avec elle \u00e0 Bordeaux pour visiter des monuments\n",
        "d m am\u0259ne av\u025bk \u025bl a b\u0254\u0281do pu\u0281 vizite de monym\u0251\u0303\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 4 sur 1390 phrases. \n",
        "et\n",
        "e\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 5 sur 1390 phrases. \n",
        "comme l\u00e0 ce n'est pas la premi\u00e8re fois qu'elle\n",
        "k\u0254m la s n e pa la p\u0281\u0259mj\u025b\u0281 fwa k \u025bl\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 6 sur 1390 phrases. \n",
        "me fait\n",
        "m fe\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 7 sur 1390 phrases. \n",
        "le coup\n",
        "l ku\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 8 sur 1390 phrases. \n",
        "elle au dernier moment\n",
        "\u025bl o d\u025b\u0281nje mom\u0251\u0303\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 9 sur 1390 phrases. \n",
        "l'a annul\u00e9 donc j'\u00e9tais d\u00e9\u00e7ue mais bon maintenant je lui demanderai plus rien\n",
        "l a anyle d\u0254\u0303k \u0292 ete desy me b\u0254\u0303 m\u025b\u0303t\u0259n\u0251\u0303 \u0292 l\u0265i d\u0259m\u0251\u0303d\u0259\u0281e ply \u0281j\u025b\u0303\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 10 sur 1390 phrases. \n",
        "mais moi j'pensais que j'allais rejoindre ma m\u00e8re\n",
        "me mwa \u0292 p\u0251\u0303se k \u0292 ale \u0281\u0259\u0292w\u025b\u0303d\u0281 ma m\u025b\u0281\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 11 sur 1390 phrases. \n",
        "parce que l'arrestation de ma m\u00e8re avait \u00e9t\u00e9 quelque chose de tellement brutal\n",
        "***parce*** k l a\u0281\u025bstasj\u0254\u0303 d ma m\u025b\u0281 ave ete k\u025blk \u0283oz d tel\u0259m\u0251\u0303 b\u0281ytal\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 12 sur 1390 phrases. \n",
        "j'avais re\u00e7u euh la lettre \u00e9tait revenue en disant parti pour une destination inconnue\n",
        "\u0292 ave \u0281\u0259sy \u0259 la l\u025bt\u0281 ete \u0281\u0259v\u0259ny \u0251\u0303 diz\u0251\u0303 pa\u0281ti pu\u0281 yn d\u025bstinasj\u0254\u0303 \u025b\u0303kony\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 13 sur 1390 phrases. \n",
        "c'\u00e9tait certainement la concierge qui avait \u00e9crit \u00e7a\n",
        "s ete s\u025b\u0281ten\u0259m\u0251\u0303 la k\u0254\u0303sj\u025b\u0281\u0292 ki ave ek\u0281i sa\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 14 sur 1390 phrases. \n",
        "on avait pas eu de nouvelles mon fr\u00e8re m'avait donn\u00e9 tr\u00e8s peu de nouvelles\n",
        "\u0254\u0303n ave pa y d nuv\u025bl m\u0254\u0303 f\u0281\u025b\u0281 m ave done t\u0281e p\u00f8 d nuv\u025bl\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 15 sur 1390 phrases. \n",
        "on m'avait dit qu'elle avait \u00e9t\u00e9 d\u00e9port\u00e9e puis on ne savait rien du tout jamais aucune lettre\n",
        "\u0254\u0303 m ave di k \u025bl\u0259 ave ete dep\u0254\u0281te p\u0265i \u0254\u0303 n save \u0281j\u025b\u0303 dy tu \u0292ame okyn l\u025bt\u0281\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 16 sur 1390 phrases. \n",
        "elle avait \u00e9crit comme beaucoup de personnes elle avait grifouill\u00e9\n",
        "\u025bl\u0259 ave ek\u0281i k\u0254m boku d p\u025b\u0281son \u025bl\u0259 ave ***grifouill\u00e9***\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 17 sur 1390 phrases. \n",
        "une petite lettre \u00e0 Drancy que j'avais re\u00e7ue l\u00e0-bas c'\u00e9tait pareil aussi\n",
        "yn p\u0259tit l\u025bt\u0281 a ***drancy*** k \u0292 ave \u0281\u0259sy la ba s ete pa\u0281\u025bj osi\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 18 sur 1390 phrases. \n",
        "euh ma m\u00e8re m'\u00e9crivait je me suis fait prendre\n",
        "\u0259 ma m\u025b\u0281 m ek\u0281ive \u0292 m s\u0265i fe p\u0281\u0251\u0303d\u0281\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 19 sur 1390 phrases. \n",
        "comme un petit oiseau en cage m'avait-elle \u00e9crit et je pars pour une destination inconnue\n",
        "k\u0254m \u0153\u0303 p\u0259ti wazo \u0251\u0303 ka\u0292 m avet \u025bl\u0259 ek\u0281i e \u0292 pa\u0281 pu\u0281 yn d\u025bstinasj\u0254\u0303 \u025b\u0303kony\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 20 sur 1390 phrases. \n",
        "et alors \u00e0 Drancy\n",
        "e al\u0254\u0281 a ***drancy***\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 21 sur 1390 phrases. \n",
        "je suis rest\u00e9e une semaine\n",
        "\u0292 s\u0265i \u0281\u025bste yn s\u0259m\u025bn\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 22 sur 1390 phrases. \n",
        "et puis un beau jour j'\u00e9tais d\u00e9port\u00e9e le dix f\u00e9vrier le neuf f\u00e9vrier on a su que\n",
        "e p\u0265i \u0153\u0303 bo \u0292u\u0281 \u0292 ete dep\u0254\u0281te l dis fev\u0281ie l n\u0153f fev\u0281ie \u0254\u0303n a sy k\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 23 sur 1390 phrases. \n",
        "qu'on \u00e9tait sur la liste qu'on allait \u00eatre d\u00e9port\u00e9s mais\n",
        "k \u0254\u0303n ete sy\u0281 la list k \u0254\u0303n ale \u025bt\u0281 dep\u0254\u0281te me\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 24 sur 1390 phrases. \n",
        "on nous a tout d'suite dit\n",
        "\u0254\u0303 nuz a tu d s\u0265it di\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 25 sur 1390 phrases. \n",
        "que on allait rejoindre nos familles\n",
        "k \u0254\u0303n ale \u0281\u0259\u0292w\u025b\u0303d\u0281 no famij\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 26 sur 1390 phrases. \n",
        "donc moi j'n'\u00e9tais pas alarm\u00e9e\n",
        "d\u0254\u0303k mwa \u0292 \u025bn ete pa ala\u0281me\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 27 sur 1390 phrases. \n",
        "j'me disais bon bah je vais rejoindre ma m\u00e8re euh\n",
        "\u0292 m dize b\u0254\u0303 ba \u0292 ve \u0281\u0259\u0292w\u025b\u0303d\u0281 ma m\u025b\u0281 \u0259\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 28 sur 1390 phrases. \n",
        "des bruits couraient on allait dans des camps on allait travailler\n",
        "de b\u0281\u0265i ku\u0281et \u0254\u0303n ale d\u0251\u0303 de k\u0251\u0303 \u0254\u0303n ale t\u0281avaje\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 29 sur 1390 phrases. \n",
        "on s'doutait bien qu'on allait pas \u00eatre choy\u00e9s m'enfin\n",
        "\u0254\u0303 s dute bj\u025b\u0303 k \u0254\u0303n ale pa \u025bt\u0281 \u0283waje m \u0251\u0303f\u025b\u0303\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 30 sur 1390 phrases. \n",
        "moi j'n'avais pas peur j'attendais\n",
        "mwa \u0292 \u025bn ave pa p\u0153\u0281 \u0292 at\u0251\u0303de\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 31 sur 1390 phrases. \n",
        "moi je croyais sinc\u00e8rement mais tr\u00e8s sinc\u00e8rement\n",
        "mwa \u0292 k\u0281waje s\u025b\u0303se\u0281\u0259m\u0251\u0303 me t\u0281e s\u025b\u0303se\u0281\u0259m\u0251\u0303\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 32 sur 1390 phrases. \n",
        "que j'allais rejoindre ma m\u00e8re\n",
        "k \u0292 ale \u0281\u0259\u0292w\u025b\u0303d\u0281 ma m\u025b\u0281\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 33 sur 1390 phrases. \n",
        "\u00e0 telle enseigne\n",
        "a t\u025bl \u0251\u0303s\u025b\u0272\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 34 sur 1390 phrases. \n",
        "bon j'vous raconterai tout d'suite le voyage dans le wagon qui nous conduisait \u00e0 Auschwitz ce voyage qui a dur\u00e9 trois jours et trois nuits\n",
        "b\u0254\u0303 \u0292 vu \u0281ak\u0254\u0303t\u0259\u0281e tu d s\u0265it l vwaja\u0292 d\u0251\u0303 l vag\u0254\u0303 ki nu k\u0254\u0303d\u0265ize a ***auschwitz*** s vwaja\u0292 ki a dy\u0281e t\u0281wa \u0292u\u0281 e t\u0281wa n\u0265i\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 35 sur 1390 phrases. \n",
        "je n'ai pas voulu entamer\n",
        "\u0292 n e pa vuly \u0251\u0303tame\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 36 sur 1390 phrases. \n",
        "les vivres que m'avait donn\u00e9s ma nourrice\n",
        "le viv\u0281 k m ave done ma nu\u0281is\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 37 sur 1390 phrases. \n",
        "y avait du miel y avait des rillettes\n",
        "i ave dy mj\u025bl i ave de \u0281ij\u025bt\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 38 sur 1390 phrases. \n",
        "j'me souviens plus tr\u00e8s bien des produits qui se conservaient mais quand nous sommes partis on nous a rien distribu\u00e9\n",
        "\u0292 m suvj\u025b\u0303 ply t\u0281e bj\u025b\u0303 de p\u0281od\u0265i ki s k\u0254\u0303s\u025b\u0281ve me k\u0251\u0303 nu s\u0254m pa\u0281ti \u0254\u0303 nuz a \u0281j\u025b\u0303 dist\u0281ibye\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 39 sur 1390 phrases. \n",
        "mais moi j'n'ai rien voulu ouvrir j'\u00e9tais certaine\n",
        "me mwa \u0292 \u025bn e \u0281j\u025b\u0303 vuly uv\u0281i\u0281 \u0292 ete s\u025b\u0281t\u025bn\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 40 sur 1390 phrases. \n",
        "mais absolument certaine\n",
        "me absolym\u0251\u0303 s\u025b\u0281t\u025bn\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 41 sur 1390 phrases. \n",
        "de rejoindre ma m\u00e8re\n",
        "d \u0281\u0259\u0292w\u025b\u0303d\u0281 ma m\u025b\u0281\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 42 sur 1390 phrases. \n",
        "et j'comprenais quand m\u00eame que ma m\u00e8re s'rait contente\n",
        "e \u0292 k\u0254\u0303p\u0281\u0259ne k\u0251\u0303 m\u025bm k ma m\u025b\u0281 s \u0281e k\u0254\u0303t\u0251\u0303t\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 43 sur 1390 phrases. \n",
        "d'avoir quelque chose euh \u00e0 manger\n",
        "d avwa\u0281 k\u025blk \u0283oz \u0259 a m\u0251\u0303\u0292e\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 44 sur 1390 phrases. \n",
        "qu'elle devait manquer de nourriture\n",
        "k \u025bl d\u0259ve m\u0251\u0303ke d nu\u0281ity\u0281\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 45 sur 1390 phrases. \n",
        "alors donc\n",
        "al\u0254\u0281 d\u0254\u0303k\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 46 sur 1390 phrases. \n",
        "le dix au matin\n",
        "l dis o mat\u025b\u0303\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 47 sur 1390 phrases. \n",
        "nous sommes parti c'\u00e9tait un convoi de mille cinq cent\n",
        "nu s\u0254m pa\u0281ti s ete \u0153\u0303 k\u0254\u0303vwa d mil s\u025b\u0303k s\u0251\u0303\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 48 sur 1390 phrases. \n",
        "un grand convoi\n",
        "\u0153\u0303 g\u0281\u0251\u0303 k\u0254\u0303vwa\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traitement de 49 sur 1390 phrases. \n",
        "de mille cinq cent hommes et femmes\n",
        "d mil s\u025b\u0303k s\u0251\u0303t \u0254m e fam\n",
        "\n",
        "\u0014"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-40-6513df1a2ea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverifier_mot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mphrasePropre\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mphraseMots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphrasePropre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-11-2ef35275bb4e>\u001b[0m in \u001b[0;36mverifier_mot\u001b[0;34m(mot)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mverifier_mot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0msampa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0msampa\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mphon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Modif GB 12/04/14\n",
      "- Insertion d'un set sur les nouvellesExceptions pour \u00e9viter les entr\u00e9es multiples\n",
      "- Ajout d'un test pour v\u00e9rifier que les nouvellesExceptions sont nouvelles\n",
      "\n",
      "#TO DO\n",
      "- Ajouter un message pour dire que le r\u00e9sultat a \u00e9t\u00e9 concat\u00e9n\u00e9 au fichier existant si c'est le cas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#1.2.a. mettre la liste des inconnus dans le fichier inconnus.txt\n",
      "with open(\"inconnus.txt\", \"a\") as f:\n",
      "    for n in set(nouvellesExceptions):\n",
      "        if not (n in oldExceptions): \n",
      "            f.write(n+\";;;;;\")\n",
      "            f.write(\"\\n\")\n",
      "        \n",
      "#1.2.b. mettre les phrases phon\u00e9mis\u00e9es dans un fichier\n",
      "with open(\"phonemise.txt\", \"a\") as f:\n",
      "    for o in output:\n",
      "        f.write(o)\n",
      "        f.write(\"\\n\")\n",
      "\n",
      "with open(\"verification.txt\", \"a\") as f:\n",
      "    for a in range(len(output)-2):\n",
      "        f.write(phrases[a]+\"\\n\"+output[a])\n",
      "        f.write(\"\\n\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}