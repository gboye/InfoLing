{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des TRS pour ajouter les informations de BDLexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import codecs\n",
    "import re\n",
    "import pdb # ajouter pdb.set_trace() à l'endroit où on veut le débugueur\n",
    "from lxml import etree\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os, fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS À FAIRE :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFICATIONS FAITES :\n",
    "1. changer l'organisation pour pouvoir traiter une liste de dossiers plutôt que un dossier\n",
    "  - garder le lexique général en entrée\n",
    "  - changer les sorties pour avoir un jeu d'exceptions par dossier\n",
    "1. ajouter un #id aux tours et aux mots => **22/12/15**\n",
    "1. gérer les parenthèses => **22/12/15**\n",
    "  - les troncations\n",
    "    - version longue pour BDLexique\n",
    "    - version courte pour la transcription\n",
    "  - les champs supplémentaires\n",
    "    - mot => nbsyllabes à saisir\n",
    "    - tour => raccourci\n",
    "1. gérer les balises Event auto-fermantes => **23/12/15**\n",
    "1. gérer les connecteurs\n",
    "  - trouver les connecteurs multi-mots\n",
    "  - tour => liste de connecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'environnement pour le script\n",
    "- *dossier* doit être le répertoire où se trouvent vos fichiers (devrait finir par un /)\n",
    "- *fichierTRS* contient la liste des noms de vos fichiers TRS à traiter (rempli automatiquement)\n",
    "- *fichierLexique* doit être le nom du fichier BDLEXIQUE\n",
    "- *fichierExceptions* doit être le nom de votre fichier INCONNUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connecteurs=[\n",
    "    u\"et\", u\"alors\", u\"du coup\", u\"sinon\", u\"par contre\", u\"ça veut dire\", u\"enfin\",\n",
    "u\"après\", u\"donc\", u\"puisque\", u\"puisqu'\", u\"en fait\", u\"mais\", u\"parce que\", u\"parce qu'\", u\"même si\" , u\"d'abord\", u\"et puis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dossier évité : \n",
      "dossier évité : BARBEDET-LABORDE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : BARDET LAFOURCADE LABARRÈRE\n",
      "dossier évité : Belio Miskic Schein\n",
      "dossier évité : Belio Miskic Schein\n",
      "dossier évité : Belio Miskic Schein\n",
      "dossier évité : Belio Miskic Schein\n",
      "dossier évité : Belio Miskic Schein\n",
      "dossier évité : Bertrand\n",
      "dossier évité : Bertrand\n",
      "dossier évité : Bertrand\n",
      "dossier évité : Bertrand\n",
      "dossier évité : Bertrand\n",
      "dossier évité : Bertrand\n",
      "dossier évité : BraïdaValade\n",
      "dossier évité : BraïdaValade\n",
      "dossier évité : BraïdaValade\n",
      "dossier évité : CHANAUD Elise ; GIRAUD Cécile ; REYNAUD Marie ECCGMR\n",
      "dossier évité : CHANAUD Elise ; GIRAUD Cécile ; REYNAUD Marie ECCGMR\n",
      "dossier évité : CHANAUD Elise ; GIRAUD Cécile ; REYNAUD Marie ECCGMR\n",
      "dossier évité : CHANAUD Elise ; GIRAUD Cécile ; REYNAUD Marie ECCGMR\n",
      "dossier évité : CHANAUD Elise ; GIRAUD Cécile ; REYNAUD Marie ECCGMR\n",
      "dossier évité : CHANAUD Elise ; GIRAUD Cécile ; REYNAUD Marie ECCGMR\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus AhTiock-Bussard-Verdiell\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : Corpus ALINS FALSON CALAND\n",
      "dossier évité : corpus bailleul mallier vandevoir\n",
      "dossier évité : corpus bailleul mallier vandevoir\n",
      "dossier évité : corpus bailleul mallier vandevoir\n",
      "dossier évité : corpus bailleul mallier vandevoir\n",
      "dossier évité : Corpus BEAUMARD Mathilde DINAL Cassandra PAUL Justine\n",
      "dossier évité : Corpus BEAUMARD Mathilde DINAL Cassandra PAUL Justine\n",
      "dossier évité : Corpus BEAUMARD Mathilde DINAL Cassandra PAUL Justine\n",
      "dossier évité : Corpus BEAUMARD Mathilde DINAL Cassandra PAUL Justine\n",
      "dossier évité : Corpus BEAUMARD Mathilde DINAL Cassandra PAUL Justine\n",
      "dossier évité : Corpus BEAUMARD Mathilde DINAL Cassandra PAUL Justine\n",
      "dossier évité : Corpus Duthil Aurore - Chalois Madisson - Daviaud Chloé\n",
      "dossier évité : Corpus Gauthier-Manterola-Bayet\n",
      "dossier évité : Corpus Gauthier-Manterola-Bayet\n",
      "dossier évité : Corpus Gauthier-Manterola-Bayet\n",
      "dossier évité : Corpus Gauthier-Manterola-Bayet\n",
      "dossier évité : Corpus Gouget_Gozzini_Massip\n",
      "dossier évité : Corpus Gouget_Gozzini_Massip\n",
      "dossier évité : Corpus Gouget_Gozzini_Massip\n",
      "dossier évité : Corpus Gouget_Gozzini_Massip\n",
      "dossier évité : corpus Guillard_Mazurier\n",
      "dossier évité : corpus Guillard_Mazurier\n",
      "dossier évité : corpus Guillard_Mazurier\n",
      "dossier évité : corpus Guillard_Mazurier\n",
      "dossier évité : Corpus LABAT-ROUSSEAU-BETUN\n",
      "dossier évité : Corpus LABAT-ROUSSEAU-BETUN\n",
      "dossier évité : Corpus LABAT-ROUSSEAU-BETUN\n",
      "dossier évité : Corpus LABAT-ROUSSEAU-BETUN\n",
      "dossier évité : Corpus LABAT-ROUSSEAU-BETUN\n",
      "dossier évité : Corpus LO MUNOZ JOLLY\n",
      "dossier évité : Corpus LO MUNOZ JOLLY\n",
      "dossier évité : Corpus LO MUNOZ JOLLY\n",
      "dossier évité : Corpus LO MUNOZ JOLLY\n",
      "dossier évité : Corpus LO MUNOZ JOLLY\n",
      "dossier évité : Corpus Manon ARNAL & Sarah GUILLOT\n",
      "dossier évité : Corpus Manon ARNAL & Sarah GUILLOT\n",
      "dossier évité : Corpus Manon ARNAL & Sarah GUILLOT\n",
      "dossier évité : Corpus Ratenon-Mounier\n",
      "dossier évité : Corpus Ratenon-Mounier\n",
      "dossier évité : Corpus Valentine Extier et Estelle Commun-Lessent\n",
      "dossier évité : Corpus Valentine Extier et Estelle Commun-Lessent\n",
      "dossier évité : Corpus Valentine Extier et Estelle Commun-Lessent\n",
      "dossier évité : Corpus Valentine Extier et Estelle Commun-Lessent\n",
      "dossier évité : Corpus Valentine Extier et Estelle Commun-Lessent\n",
      "dossier évité : DanielisRamonBarbier\n",
      "dossier évité : DanielisRamonBarbier\n",
      "dossier évité : DanielisRamonBarbier\n",
      "dossier évité : DanielisRamonBarbier\n",
      "dossier évité : DanielisRamonBarbier\n",
      "dossier évité : DanielisRamonBarbier\n",
      "dossier évité : DUDON-DUBUIS-BARDINET_Corpus\n",
      "dossier évité : DUDON-DUBUIS-BARDINET_Corpus\n",
      "dossier évité : DUDON-DUBUIS-BARDINET_Corpus\n",
      "dossier évité : DUDON-DUBUIS-BARDINET_Corpus\n",
      "dossier évité : DUDON-DUBUIS-BARDINET_Corpus\n",
      "dossier évité : Exemple transcription pour cours d'informatique\n",
      "dossier évité : Exercice Transcription\n",
      "dossier évité : GUARINO DINET-ARNAUD POURTALET\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : Labadie Ragon Mazery\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LAGUNE MIRGUET NAHARBERROUET\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : LATASTE_LARIC_BERNEDE\n",
      "dossier évité : Lavielle Clémence - Caignieu Julie\n",
      "dossier évité : LESAGE-SCHAEFFER-LEMITRE\n",
      "dossier évité : Lesbre Lefort Perrier- CLCPPL-tics\n",
      "dossier évité : Lesbre Lefort Perrier- CLCPPL-tics\n",
      "dossier évité : Lesbre Lefort Perrier- CLCPPL-tics\n",
      "dossier évité : Lesbre Lefort Perrier- CLCPPL-tics\n",
      "dossier évité : Lesbre Lefort Perrier- CLCPPL-tics\n",
      "dossier évité : Maillé_Pascal_Gonzalez\n",
      "dossier évité : Maillé_Pascal_Gonzalez\n",
      "dossier évité : Maillé_Pascal_Gonzalez\n",
      "dossier évité : Maillé_Pascal_Gonzalez\n",
      "dossier évité : PINTO JEAN DEOLIVEIRA\n",
      "dossier évité : Ponctuation\n",
      "dossier évité : Richy_Duverger-Corpus\n",
      "dossier évité : Richy_Duverger-Corpus\n",
      "dossier évité : Richy_Duverger-Corpus\n",
      "dossier évité : Richy_Duverger-Corpus\n",
      "dossier évité : Richy_Duverger-Corpus\n",
      "dossier évité : Transcription Phonétique\n",
      "dossier évité : Transcription Phonétique\n",
      "dossier évité : Transcription Phonétique\n",
      "dossier évité : Transcription Phonétique\n",
      "0 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Augustin 12\n",
      "1 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Donatien 9\n",
      "2 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Gabriel 8\n",
      "3 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Guilhem 7\n",
      "4 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Hortense 13\n",
      "5 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Ignace 6\n",
      "6 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Jeanne 5\n",
      "7 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Joseph 4\n",
      "8 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Louise 14\n",
      "9 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Margaux 11\n",
      "10 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Ombeline 2\n",
      "11 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Victoire 3\n",
      "12 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Violette 1\n",
      "13 /Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Zoé 10\n"
     ]
    }
   ],
   "source": [
    "dossierCorpus=\"/Users/gilles/Copy/Corpus 2015-2016/\"\n",
    "dossiersHorsCorpus=[\"Ponctuation\", \"Transcription Phonétique\",\"Exemple transcription pour cours d'informatique\"]\n",
    "dossiersSpeciaux=[]\n",
    "dossiersRestants=[\"BAYROUBISENSANGDELAPASSE\"]\n",
    "sansRebalisageFichiers=[\n",
    "    \"6 - L'amour à la plage.trs\",\n",
    "    \"7 - Les Mostaganems de saluent.trs\"\n",
    "]\n",
    "dossiersTRS={}\n",
    "inconnusTRS={}\n",
    "for root, dirs, files in os.walk(dossierCorpus):\n",
    "    dossierGroupe=root.split(\"Corpus 2015-2016/\")[1].split(\"/\")[0]\n",
    "    if not dossierGroupe in dossiersHorsCorpus+dossiersSpeciaux and dossierGroupe in dossiersRestants:\n",
    "        trs=fnmatch.filter(files, \"*.trs\")\n",
    "        if trs:\n",
    "            dossiersTRS[root]=dossierGroupe\n",
    "        inconnus=fnmatch.filter(files, \"*-inconnus.txt\")\n",
    "        if inconnus:\n",
    "            inconnusTRS[dossierGroupe]=root+\"/\"+inconnus[0]\n",
    "    else:\n",
    "        print \"dossier évité :\",dossierGroupe\n",
    "        \n",
    "for element in dossiersTRS:\n",
    "    if dossiersTRS[element] in inconnusTRS:\n",
    "        dossiersTRS[element]=inconnusTRS[dossiersTRS[element]]\n",
    "    else:\n",
    "        dossiersTRS[element]=element+\"/inconnus.txt\"\n",
    "if 0:\n",
    "    print \"INC\"\n",
    "    for element in sorted(dossiersTRS):\n",
    "        print element\n",
    "        print dossiersTRS[element]\n",
    "        print\n",
    "listeDossiersTRS=sorted(dossiersTRS.keys())\n",
    "for num,element in enumerate(listeDossiersTRS):\n",
    "    print num, element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPremierDossier=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dossiers=[\"/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/\"]\n",
    "#dossier=\"/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/\"\n",
    "#fichiersTRS=glob.glob(dossier+\"TRS/*.trs\")\n",
    "fichierLexique=\"/Users/gilles/Copy/Cours/Bordeaux/L2-XML/XML-Ressources/bdlexique.txt\"\n",
    "#fichierExceptions=dossier+\"inconnus.txt\"\n",
    "fichier_exceptions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voyelles=u\"ieɛayøœəuoɔɑɛ̃ɔ̃ɑ̃\"\n",
    "voyelles=u\"ieEay296@uoOòèâêûô\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous n'avez pas de fichier *inconnus.txt* \n",
    ">mettez *fichier_exceptions=False* au dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- mise en texte des deux blocs de traitement de la ligne de commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicon=codecs.open(fichierLexique,\"r\",encoding='utf8')\n",
    "bdlexique=lexicon.readlines()\n",
    "lexicon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facultatives = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phon={}\n",
    "result=[]\n",
    "nouvellesExceptions = []\n",
    "output=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "ajouter chaque ligne du fichier à phrases[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lowerAccents(chaine):\n",
    "    return chaine.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser le mot en cours\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ la ponctuation est remplacée par un espace\n",
    "+ les espaces aux extrémités sont effacés\n",
    "+ le mot est mis en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trimer(mot):\n",
    "    mot=lowerAccents(mot)\n",
    "#    for p in u',;.:-?!()“”‘’‛‟′″´˝\"«»':\n",
    "    for p in u',;.:-?!“”‘’‛‟′″´˝\"«»':   # Modifié le 22/12/15 pour gérer les parenthèses comme marqueur dans les mots\n",
    "        mot=mot.replace(p, ' ')\n",
    "    mot=mot.strip()\n",
    "    return mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def listerMotsCorpus(rootTRS):\n",
    "    phrases=[]\n",
    "    motsPhrases=[]\n",
    "    elementsPhrases=[]\n",
    "    motsCorpus=set()\n",
    "    nPhrases=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        line=ligne.strip()\n",
    "        if 0: print [line]\n",
    "    #    print nPhrases, line\n",
    "        phrases.append(line)\n",
    "#        elements=re.findall(ur\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", line)\n",
    "        elements=re.findall(ur\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ()]+['’]?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", line)\n",
    "        mots=[x for x in elements if not x in u\"-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~:\" and not x in [u\" ;\",u\" !\",u\" ?\",u\" :\"]]\n",
    "        elements=[x for x in elements if x!=u\" \"]\n",
    "        elementsPhrases.append(elements)\n",
    "        phrasePropre = u\"\"\n",
    "        for mot in mots:\n",
    "            mot = trimer(mot)\n",
    "            phrasePropre += mot+u\" \"\n",
    "            m=re.search(ur\"\\(.*\\)\",mot)\n",
    "            forme=mot\n",
    "            graphie=mot\n",
    "            if m :\n",
    "                forme=re.sub(ur\"\\((.*)\\)\",\"\\g<1>\", mot)\n",
    "                graphie=re.sub(ur\"\\(([\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?)\\)\",\"'\", mot)\n",
    "                motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}    \n",
    "            motsCorpus.add(forme)\n",
    "#        phraseMots = phrasePropre.strip()\n",
    "        phraseMots = phrasePropre.split()        \n",
    "        motsPhrases.append(phraseMots)\n",
    "        nPhrases+=1\n",
    "    return (motsCorpus,motsPhrases,elementsPhrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire de BDLex 0.forme fléchie, 1.phonétique, 2.liaison, 3.cat-gram, 4.genre+nombre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "extraire du fichier d'exceptions les mêmes données que pour BDLex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- fait une liste des exceptions lues pour ne pas les rajouter à la fin\n",
    "- éviter de tenir compte des exceptions non renseignées\n",
    " - les mots du fichier exceptions sans transcriptions étaient transcrits par une chaine vide..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier si le mot existe\n",
    "\n",
    "algorithme\n",
    "\n",
    "+ si le mot est dans BDLex, ok\n",
    "+ s'il y a un espace dans le mot,\n",
    "    * le mot est divisé en deux et\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ s'il y a un apostrophe dans le mot,\n",
    "    * le mot est divisé en deux\n",
    "    * si les mots existent dans bdlex, ok\n",
    "    * sinon les mots sont ajoutés aux nouvelles exceptions et mis entre étoiles\n",
    "+ dans les autres cas, le mot est ajouté aux nouvelles exceptions et mis entre étoiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def verifier_mot(mot):\n",
    "        sampa=\"\"\n",
    "        if mot in phon.keys():\n",
    "            sampa += phon[mot][0]\n",
    "        elif \" \" in mot:\n",
    "            mots = mot.split()\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif \"'\" in mot:\n",
    "            mots = mot.split(\"'\")\n",
    "            mots[0]=mots[0]+\"'\"\n",
    "            for mot in mots:\n",
    "                if mot in phon.keys():\n",
    "                    sampa += phon[mot][0]+\" \"\n",
    "                elif mot != \"\":\n",
    "                    nouvellesExceptions.append(mot)\n",
    "                    sampa += \"***\"+mot+\"*** \"\n",
    "        elif mot != \"\": \n",
    "            nouvellesExceptions.append(mot)\n",
    "            sampa=\"***\"+mot+\"*** \"\n",
    "        return sampa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. traduire le SAMPA de BDLexique en API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- ajout du r et du â\n",
    "- ajout des exemples associés en dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# traduire SAMPA-BDLex en API\n",
    "\n",
    "def sampa2api(sampa):\n",
    "    if isinstance(sampa,str):\n",
    "        api=sampa.decode(\"utf8\")\n",
    "    else:\n",
    "        api=sampa\n",
    "    api=api.replace(u'S',u'ʃ') \n",
    "    api=api.replace(u'Z',u'ʒ')\n",
    "    api=api.replace(u'N',u'ŋ')\n",
    "    api=api.replace(u'J',u'ɲ')\n",
    "    api=api.replace(u'r',u'ʁ') \n",
    "    api=api.replace(u'H',u'ɥ')\n",
    "    api=api.replace(u'E',u'ɛ')\n",
    "    api=api.replace(u'2',u'ø')\n",
    "    api=api.replace(u'9',u'œ')\n",
    "    api=api.replace(u'6',u'ə')\n",
    "    api=api.replace(u'O',u'ɔ')\n",
    "    api=api.replace(u'è',u'e')   \n",
    "    api=api.replace(u'ò',u'o')    \n",
    "    api=api.replace(u'â',u'ɑ̃')   \n",
    "    api=api.replace(u'ê',u'ɛ̃')   \n",
    "    api=api.replace(u'û',u'œ̃')  \n",
    "    api=api.replace(u'ô',u'ɔ̃')       \n",
    "    api=api.replace(u'@',u'ə')\n",
    "    api=api.replace(u'n\"',u'n') \n",
    "    api=api.replace(u't\"',u't') \n",
    "    api=api.replace(u'z\"',u'z') \n",
    "    api=api.replace(u'R\"',u'ʁ') \n",
    "    api=api.replace(u'p\"',u'p') \n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Vérifier si la liaison est possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant ne sont pas dans lexicon, pas de liaison\n",
    "+ si le mot a une consonne dans le champ de la voyelle de liaison, check1 est vrai\n",
    "+ si le mot suivant commence par une voyelle, check2 est vrai\n",
    "\n",
    "  si check1 et check2 sont vrais, il y a liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def liaison_possible(phrase ,mot , mot_numero):\n",
    "    check1=0\n",
    "    check2=0\n",
    "    if mot in phon and len(phrase)>mot_numero+1 and phrase[mot_numero+1] in phon:\n",
    "        consonnes=['k\"', '(kt)\"', 'n\"', 'p\"', 'R\"', '@t\"', 't\"', '-V', '+V', '@z\"', 'z\"']\n",
    "        phoneme=phon[mot][2]\n",
    "        for phoneme in consonnes:\n",
    "            check1=1\n",
    "        \n",
    "        voyelles=[\"H\", \"j\", \"w\", \"E\", \"a\", \"2\", \"9\", \"6\", \"@\", \"y\", \"u\", \"O\", u\"ò\", \"o\", \"e\", u\"è\", u\"ê\", u\"û\", u\"ô\", \"i\"]\n",
    "        mot_suivant=phon[phrase[mot_numero+1]][1]\n",
    "        for v in voyelles:\n",
    "            if mot_suivant.startswith(v):\n",
    "                check2=1\n",
    "\n",
    "    if check1 and check2 :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. vérifier si la liaison est obligatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def liaison_obligatoire(phrase, mot, mot_numero):\n",
    "    determinant=[\"d\", \"P\"]\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    pronompers=[\"P\"]\n",
    "    verbe=[\"V\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "\n",
    "    if catgram_mot1 in determinant and catgram_mot2 in nom :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in determinant and catgram_mot2 in adjectif :\n",
    "        return True\n",
    " \n",
    "    elif catgram_mot1 in pronompers and catgram_mot2 in verbe :\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in verbe and catgram_mot2 in pronompers :\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles:\n",
    "\n",
    "- DET + N\n",
    "    * ri + N:   d'animal, \n",
    "    * di + N:   certains éléphants\n",
    "    * rd + N:   les animaux\n",
    "    * dd + N:   ces étés, cet été\n",
    "    * dp + N:   ton anorak\n",
    "    * rc + N:   aux armes\n",
    "- DET + ADJ:\n",
    "    * ri + ADJ:   d'énormes\n",
    "    * di + ADJ:   plusieurs immenses\n",
    "    * rd + ADJ:   les immenses\n",
    "    * dd + ADJ:   cet immense\n",
    "    * dp + ADJ:   son immense\n",
    "    * rc + ADJ:   aux immenses\n",
    "- PERS + V:\n",
    "    * SS + V:   m'épate\n",
    "- V + PRO PERS: \n",
    "    * V + SS:   vont-ils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vérifier si la liaison est facultative\n",
    "def liaison_facultative(phrase, mot, mot_numero):\n",
    "    #pdb.set_trace()\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    pluriel=[\"MP\", \"FP\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    verbe=[\"V\"]\n",
    "    pronompers=[\"P\"]\n",
    "    adverbe=[\"A\"]\n",
    "    preposition=[\"p\"]\n",
    "    catgram_mot1=phon[phrase[mot_numero]][3]\n",
    "    catgram_mot2=phon[phrase[mot_numero+1]][3]\n",
    "    genre_mot1=phon[phrase[mot_numero]][4]\n",
    "    \n",
    "    if (catgram_mot1 in nom) and (phon[phrase[mot_numero]][4] in pluriel) and (catgram_mot2 in adjectif) : \n",
    "        return True\n",
    "\n",
    "    elif (catgram_mot1 in verbe) and (catgram_mot2 not in pronompers):\n",
    "        return True\n",
    "\n",
    "    elif catgram_mot1 in adverbe :\n",
    "        return True\n",
    "    \n",
    "    elif catgram_mot1 in preposition : \n",
    "        return True\n",
    "\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles :\n",
    "\n",
    "- N pl + ADJ: \n",
    "    * N + ADJ: monstres énormes \n",
    "    * G + ADJ: rivaux énormes\n",
    "- VERBE + TOUT-SAUF-PRO-PERS:\n",
    "    * V + N sont éléphants\n",
    "    * V + G sommes abdicaires\n",
    "    * V + V sommes assis\n",
    "    * V + A sommes admirablement\n",
    "    * V + p sommes autour de\n",
    "    * V + di ont aucune\n",
    "    * V + rc sommes au\n",
    "- ADV + QQCH:\n",
    "    * ADV + N vraiment abruti\n",
    "    * ADV + G vraiment abandonné\n",
    "    * ADV + V vraiment aimé\n",
    "    * ADV + J vraiment étonnant\n",
    "    * ADV + ss vraiment ils\n",
    "    * ADV + A vraiment étonnamment\n",
    "    * ADV + p vraiment attendu\n",
    "    * ADV + di vraiment autre \n",
    "    * ADV + rc vraiment au\n",
    "- PREP + QQCH:\n",
    "    * PREP + N très amoureux\n",
    "    * PREP + G très abandonné\n",
    "    * PREP + V très aimé\n",
    "    * PREP + J très étonnant\n",
    "    * PREP + SS très ils\n",
    "    * PREP + A très étonnamment\n",
    "    * PREP + p très attendu\n",
    "    * PREP + di très autre\n",
    "    * PREP + rc très au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Partie 1\n",
    "*chaque phrase est prise individuellement,\n",
    "    * découpée en blocs,\n",
    "        * qui sont chacuns trimés si ce sont des mots\n",
    "        * s'il y a plusieurs mots dans le bloc, ils sont séparés\n",
    "    + Partie 2\n",
    "    * pour chaque couple de mots\n",
    "        * si la liaison est possible,\n",
    "            * et qu'elle est obligatoire, l'api avec la liaison est généré\n",
    "            * et qu'elle est facultative,\n",
    "                * si l'utilisateur l'a choisi, l'api avec la liaison est généré\n",
    "                * sinon l'api sans la liaison est généré\n",
    "\n",
    "        + Partie 3\n",
    "        * si la liaison n'est pas possible,\n",
    "            * si le mot est dans bdlex, l'api est généré\n",
    "            * sinon le mot est laissé tel quel (il a déjà les étoiles)        \n",
    "\n",
    "    * pour le dernier mot de la phrase, \n",
    "        * si le mot est dans bdlex, l'api est généré\n",
    "        * sinon le mot est laissé tel quel (il a déjà les étoiles) \n",
    "\n",
    "+ Partie 4\n",
    "* le message à l'utilisateur et la phrase en api est imprimée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- suppression du délai dans la boucle\n",
    " - pour 1500 lignes => 3 secondes sans ralentisseur, 1503 secondes avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml.builder import E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compterVoyelles(chaine):\n",
    "    result=0\n",
    "    for element in chaine:\n",
    "        if element in voyelles:\n",
    "            result+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Début de l'enchassement en XML (7/12/15)\n",
    "- récupérer la ponctuation et les sauts de lignes pour rendre le texte lisible\n",
    "- ajouter le reste des informations du lexique dans la balise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def enchasseBDLexique(nphrase,nmot,liaison=False):\n",
    "    boolAbrege=False\n",
    "    motTRS=motsPhrases[nphrase][nmot]\n",
    "    if motTRS in motsAbreges:\n",
    "        mot=motsAbreges[motTRS][\"lexical\"]\n",
    "        graphie=motsAbreges[motTRS][\"graphie\"]\n",
    "        boolAbrege=True\n",
    "    else:\n",
    "        mot=motTRS\n",
    "        graphie=motTRS\n",
    "#    print mot\n",
    "    if mot in phon: \n",
    "        phono=sampa2api(phon[mot][1])\n",
    "        if liaison:\n",
    "            phono+=sampa2api(phon[mot][2])\n",
    "        cat=phon[mot][3]\n",
    "        if cat in [u\"J\",u\"K\"]:\n",
    "            cat=u\"Adj\"\n",
    "        ms=phon[mot][4]\n",
    "        vs=phon[mot][5]\n",
    "        lexeme=phon[mot][6].upper()\n",
    "        freq=phon[mot][8]\n",
    "        nbVoyelles=str(compterVoyelles(phon[mot][1]))\n",
    "        if u\" \" in vs:\n",
    "            vs=u\"\"\n",
    "    else:\n",
    "        phono=verifier_mot(mot)[:-1]\n",
    "        cat=u\"???\"\n",
    "        ms=\"\"\n",
    "        vs=\"\"\n",
    "        lexeme=\"???\"\n",
    "        freq=\"\"\n",
    "        nbVoyelles=\"\"\n",
    "    motAttributs={\"cat\":cat,\"ms\":ms,\"vs\":vs,\"phon\":phono,\"nbsyll\":nbVoyelles, \"lexeme\":lexeme, \"freq\":freq, \"id\":\"%05d%03d\"%(nphrase,nmot)}\n",
    "    if boolAbrege:\n",
    "        motAttributs[\"ABnbsyll\"]=\"\"\n",
    "        motAttributs[\"ABphon\"]=\"\"\n",
    "    result=E.motBDL(graphie,motAttributs)\n",
    "#    print etree.tostring(result,encoding=\"utf8\")\n",
    "#    print (cat,ms,vs,phono,mot)\n",
    "#    u'<mot cat=\"%s\" ms=\"%s\" vs=\"%s\" phon=\"%s\">%s</mot>' % (cat,ms,vs,phono,mot)\n",
    "    return result\n",
    "    \n",
    "def enchasseXML(mot, phono):\n",
    "    if isinstance(phono,str):\n",
    "        phono=phono.decode(\"utf8\")\n",
    "    result=E.motBDL(mot,{\"phon\":phono})\n",
    "#    u'<mot phon=\"%s\">%s</mot>' % (phono, mot)\n",
    "    return result\n",
    "\n",
    "def enchasseTour(phrase):\n",
    "    result=E.tour(phrase,{\"id\":\"%06d\"%nPhrase})\n",
    "    return result\n",
    "\n",
    "def enchasseNonMot(nonmot):\n",
    "    result=E.punct(nonmot)\n",
    "#    u'<punct>%s</punct>' % (nonmot)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def traitementTRS(rootTRS):\n",
    "    a=1\n",
    "    nPhrase=0\n",
    "    for ligne in rootTRS.xpath(\"//Turn//text()\"):\n",
    "        phrase=ligne.strip()\n",
    "        api=E.tour()\n",
    "        mot_numero=0\n",
    "        element_numero=0\n",
    "        while elementsPhrases[nPhrase] and element_numero < len(elementsPhrases[nPhrase]):\n",
    "            if not mot_numero < len(motsPhrases[nPhrase]) or motsPhrases[nPhrase][mot_numero]!=elementsPhrases[nPhrase][element_numero].lower():\n",
    "                api.append(enchasseNonMot(elementsPhrases[nPhrase][element_numero]))\n",
    "            elif liaison_possible(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                if liaison_obligatoire(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    api.append(enchasseBDLexique(nPhrase,mot_numero,True))\n",
    "                elif liaison_facultative(motsPhrases[nPhrase], motsPhrases[nPhrase][mot_numero], mot_numero):\n",
    "                    if facultatives:\n",
    "                        api.append(enchasseBDLexique(nPhrase,mot_numero,True))\n",
    "                    else :\n",
    "                        api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                else:\n",
    "                    api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero+=1\n",
    "            else:\n",
    "                api.append(enchasseBDLexique(nPhrase,mot_numero))\n",
    "                mot_numero = mot_numero+1\n",
    "            element_numero+=1\n",
    "        a=a+1\n",
    "        if phrase!=\"\":\n",
    "            phraseConnecteurs=set()\n",
    "            for connecteur in connecteurs:\n",
    "                if \" \" in connecteur:\n",
    "                    connecteurParties=connecteur.split(\" \")\n",
    "                else:\n",
    "                    connecteurParties=[connecteur]\n",
    "                for i in range(len(elementsPhrases[nPhrase])-len(connecteurParties)+1):\n",
    "                    if connecteurParties==elementsPhrases[nPhrase][i:i+len(connecteurParties)]:\n",
    "                        phraseConnecteurs.add(connecteur)\n",
    "            if phraseConnecteurs:\n",
    "#                print phraseConnecteurs\n",
    "                api.set(\"connecteurs\",\",\".join(phraseConnecteurs))\n",
    "            api.set(\"nbmots\",str(len(api.xpath(\"//tour/motBDL\"))))\n",
    "            api.set(\"id\",\"%06d\"%nPhrase)\n",
    "            noeudAttachement=ligne.getparent()\n",
    "            if noeudAttachement.text==None:\n",
    "                noeudAttachement.tail=None\n",
    "                noeudAttachement.addnext(api)\n",
    "            else:\n",
    "                noeudAttachement.text=None\n",
    "                try:\n",
    "                    noeudAttachement.append(api)\n",
    "                except TypeError:\n",
    "                    print phrase, noeudAttachement\n",
    "                    noeudAttachement.append(api)\n",
    "        else:\n",
    "            ligne.getparent().tail=None\n",
    "        nPhrase+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modif GB 12/04/14\n",
    "- Insertion d'un set sur les nouvellesExceptions pour éviter les entrées multiples\n",
    "- Ajout d'un test pour vérifier que les nouvellesExceptions sont nouvelles\n",
    "\n",
    "#TO DO\n",
    "- Ajouter un message pour dire que le résultat a été concaténé au fichier existant si c'est le cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extraireMotsTRS(motsCorpus,phon):\n",
    "    for entry in bdlexique:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(u';')\n",
    "        if p[0].lower() in motsCorpus:\n",
    "            if p[2]==\"@\" and not p[3] in [\"N\",\"V\",\"J\",\"K\"]:\n",
    "                p[1]+=p[2]\n",
    "                p[2]=\"\"\n",
    "                if len(p)<7:\n",
    "                    for i in range(len(p)+1,7):\n",
    "                        p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8],p[9])\n",
    "    return phon\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if fichier_exceptions:\n",
    "    oldExceptions=[]\n",
    "    for entry in inconnus:\n",
    "        entry=entry.strip()\n",
    "        p=entry.split(\";\")\n",
    "        if len(p[1])!=0:\n",
    "            if len(p)<9:\n",
    "                for i in range(len(p)+1,7):\n",
    "                    p.append(\"\")\n",
    "            phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "        oldExceptions.append(p[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.2.b. mettre les phrases phonémisées dans un fichier\n",
    "enteteXML=[\n",
    "            u'<?xml version=\"1.0\" encoding=\"UTF8\" standalone=\"yes\"?>',\n",
    "            u'<?xml-stylesheet type=\"text/xsl\" href=\"phonemise-TRS.xsl\"?>',\n",
    "            u'<!DOCTYPE Trans SYSTEM \"trans-14-corpus.dtd\">'\n",
    "          ]\n",
    "\n",
    "#print [etree.tostring(rootTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\")]\n",
    "motsAbreges={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baliserTRS(nomTRS):\n",
    "    with open(nomTRS,\"r\") as temp:\n",
    "        header= temp.readlines()[0]\n",
    "        s=re.search(ur'encoding=\"(.+)\"',header)\n",
    "        if s:\n",
    "            TRS=codecs.open(nomTRS,\"r\",encoding=s.group(1)).readlines()\n",
    "        else:\n",
    "            TRS=open(nomTRS,\"r\").readlines()\n",
    "    sortie=\"\"\n",
    "    fins=[]\n",
    "    debs=[]\n",
    "    for numLigne,ligne in enumerate(TRS[2:]):\n",
    "        ligne=ligne.strip()\n",
    "        if 0<=numLigne <=10:\n",
    "            print ligne\n",
    "        disfluenceGen=re.match('<Event desc=\"disflu\" type=\"(noise|lexical|pronounce|language|entities)\" extent=\"(begin|end)\"/>',ligne)\n",
    "        disfluenceSpec=re.match('<Event desc=\"(Md|Rep|AutoC|NonFinie|MCoup)\" type=\"pronounce\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        eventAutre=re.match('<Event desc=\"([^\"]+)\" type=\"([^\"]+)\" extent=\"(begin|end)\"/>',ligne)        \n",
    "        tagTurn=re.match('<(/?)Turn.*>',ligne)        \n",
    "        if disfluenceGen:\n",
    "            if debug: print \"disfluGen\",disfluenceGen.group(2)\n",
    "            if disfluenceGen.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceGen.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceGen.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif disfluenceSpec:\n",
    "            if debug: print \"disfluSpec\",disfluenceSpec.group(2)\n",
    "            if disfluenceSpec.group(2)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<disfluence type=\"%s\">'%disfluenceSpec.group(1)+\"\\n\")\n",
    "                fins.append(\"</disfluence>\")\n",
    "            elif disfluenceSpec.group(2)==\"end\":\n",
    "                sortie+=(\"</disfluence>\"+\"\\n\")\n",
    "                chaine=fins.pop()\n",
    "                if chaine!=\"</disfluence>\":\n",
    "                    print \"PB\",chaine, \"</disfluence>\", numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif eventAutre:\n",
    "            if debug: print \"Autre\",eventAutre.group(3)\n",
    "            descEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(1)])\n",
    "            typeEvent=\"\".join([l if not l in \" *\" else \"_\" for l in eventAutre.group(2)])\n",
    "            if eventAutre.group(3)==\"begin\":\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "                sortie+=('<%s desc=\"%s\">'%(typeEvent,descEvent)+\"\\n\")\n",
    "                fins.append(\"</%s>\"%typeEvent)\n",
    "            elif eventAutre.group(3)==\"end\":\n",
    "#                print numLigne\n",
    "                if fins:\n",
    "                    sortie+=(\"</%s>\"%typeEvent+\"\\n\")\n",
    "                    chaine=fins.pop()\n",
    "                else:\n",
    "                    print \"PB no stack to pop\", typeEvent,numLigne\n",
    "                if chaine!=\"</%s>\"%typeEvent:\n",
    "                    print \"PB\",chaine, typeEvent,numLigne\n",
    "                sortie+=(ligne+\"\\n\")\n",
    "        elif tagTurn:\n",
    "            if debug: print tagTurn.group(1)+\"Turn\"\n",
    "            if tagTurn.group(1)==\"/\" and fins:\n",
    "                lenFins=len(fins)\n",
    "                for num in range(lenFins):\n",
    "                    chaine=fins.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    debs.append(chaine.replace(\"/\",\"\"))\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "            if tagTurn.group(1)==\"\" and debs:\n",
    "                lenDebs=len(debs)\n",
    "                for num in range(lenDebs):\n",
    "                    chaine=debs.pop()\n",
    "                    sortie+=(chaine+\"\\n\")\n",
    "                    fins.append(chaine.replace(\"<\",\"</\"))\n",
    "        else:\n",
    "            sortie+=(ligne+\"\\n\")\n",
    "        if debug and (debs or fins):\n",
    "            print debs, fins\n",
    "    return sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Augustin 12\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Augustin 12/id2015_aug12.trs\n",
      "<Trans scribe=\"Claudine\" audio_filename=\"id2015_aug12\" version=\"4\" version_date=\"151208\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"interviewer\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Augustin\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"339.696\">\n",
      "<Turn startTime=\"0\" endTime=\"1.38\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Donatien 9\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Donatien 9/id2015-don9.trs\n",
      "<Trans scribe=\"ANAIS\" audio_filename=\"donatien\" version=\"2\" version_date=\"151110\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#1\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"134.139\">\n",
      "<Turn startTime=\"0\" endTime=\"0.335\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Gabriel 8\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Gabriel 8/id2014_gab8.trs\n",
      "<Trans scribe=\"Lapasse\" audio_filename=\"gabriel\" version=\"25\" version_date=\"151210\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#1\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk3\" name=\"other\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk4\" name=\"r\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"824.738\">\n",
      "<Turn startTime=\"0\" endTime=\"1.28\">\n",
      "<Sync time=\"0\"/>\n",
      "PB no stack to pop pronounce 3839\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Guilhem 7\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Guilhem 7/id2015_gui7.trs\n",
      "<Trans scribe=\"Claudine\" audio_filename=\"id2015_gil7\" version=\"3\" version_date=\"151203\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"interviewer\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Guilhem\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"200.725\">\n",
      "<Turn startTime=\"0\" endTime=\"1.213\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Hortense 13\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Hortense 13/id2015_hor13.trs\n",
      "<Trans scribe=\"ANAIS\" audio_filename=\"hortense\" version=\"6\" version_date=\"151204\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Hortense\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Interviewer\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"556.643\">\n",
      "<Turn startTime=\"0\" endTime=\"1.696\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Ignace 6\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Ignace 6/id2015_ign6.trs\n",
      "<Trans scribe=\"Lapasse\" audio_filename=\"ignace\" version=\"7\" version_date=\"151210\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#1\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"male\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"568.764\">\n",
      "<Turn startTime=\"0\" endTime=\"1.22\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "PB no stack to pop pronounce 678\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Jeanne 5\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Jeanne 5/id2015_jea5.trs\n",
      "<Trans scribe=\"Claudine\" audio_filename=\"id2015_jea5\" version=\"4\" version_date=\"151204\">\n",
      "<Topics>\n",
      "<Topic id=\"to1\" desc=\"trransend\"/>\n",
      "</Topics>\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"interviewer\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Jeanne\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"379.320\">\n",
      "<Turn startTime=\"0\" endTime=\"1.524\">\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Joseph 4\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Joseph 4/id2015_jos4.trs\n",
      "<Trans scribe=\"Lapasse\" audio_filename=\"joseph\" version=\"5\" version_date=\"151211\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#1\" check=\"no\" type=\"male\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"398.420\">\n",
      "<Turn startTime=\"0\" endTime=\"0.684\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "PB no stack to pop pronounce 1554\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Louise 14\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Louise 14/id2015_lou14.trs\n",
      "<Trans scribe=\"Claudine\" audio_filename=\"LOUISE CORPUS\" version=\"2\" version_date=\"151212\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Louise\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"interviewer\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"172.608\">\n",
      "<Turn startTime=\"0\" endTime=\"3.556\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Margaux 11\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Margaux 11/id2015_mar11.trs\n",
      "<Trans scribe=\"ANAIS\" audio_filename=\"id2015_mar11\" version=\"9\" version_date=\"151215\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"speaker#1\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"speaker#2\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"Margaux\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk4\" name=\"interviewer\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"513.072\">\n",
      "<Turn startTime=\"0\" endTime=\"1.429\">\n",
      "<Sync time=\"0\"/>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Ombeline 2\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Ombeline 2/id2015_omb2.trs\n",
      "<Trans scribe=\"Claudine\" audio_filename=\"id2015_omb2\" version=\"3\" version_date=\"151129\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"interviewer\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Ombeline\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"221.074\">\n",
      "<Turn startTime=\"0\" endTime=\"0.813\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Victoire 3\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Victoire 3/id2015_vic3.trs\n",
      "<Trans scribe=\"ANAIS\" audio_filename=\"Marie Victoire\" version=\"6\" version_date=\"151118\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Marie Victoire\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "<Speaker id=\"spk2\" name=\"Interviewer\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\" type=\"female\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"474.540\">\n",
      "<Turn startTime=\"0\" endTime=\"0.759\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Violette 1\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Violette 1/id2015_vio1.trs\n",
      "<Trans scribe=\"Claudine\" audio_filename=\"id2015_vio1\" version=\"6\" version_date=\"151204\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Violette\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"interviewer\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk3\" name=\"speaker indéf\" check=\"no\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"232.584\">\n",
      "<Turn startTime=\"0\" endTime=\"3.651\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Zoé 10\n",
      "/Users/gilles/Copy/Corpus 2015-2016/BAYROUBISENSANGDELAPASSE/Zoé 10/id2015_zoe10.trs\n",
      "<Trans scribe=\"ANAIS\" audio_filename=\"CORPUS ZOE\" version=\"6\" version_date=\"151120\">\n",
      "<Speakers>\n",
      "<Speaker id=\"spk1\" name=\"Interviewer\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "<Speaker id=\"spk2\" name=\"Zoé\" check=\"no\" type=\"female\" dialect=\"native\" accent=\"\" scope=\"local\"/>\n",
      "</Speakers>\n",
      "<Episode>\n",
      "<Section type=\"report\" startTime=\"0\" endTime=\"560.280\">\n",
      "<Turn startTime=\"0\" endTime=\"1.362\">\n",
      "<Sync time=\"0\"/>\n",
      "\n",
      "</Turn>\n",
      "FIN reBALISER\n",
      "FIN fromstring\n",
      "FIN lister mots\n",
      "FIN extraire mots\n",
      "FIN traitement\n"
     ]
    }
   ],
   "source": [
    "for dossier in listeDossiersTRS[numPremierDossier:]:\n",
    "    print dossier\n",
    "    fichiersTRS=glob.glob(dossier+\"/*.trs\")\n",
    "    fichierExceptions=dossiersTRS[dossier]\n",
    "    boolExceptions=True\n",
    "    try:\n",
    "        exceptions=codecs.open(fichierExceptions,\"r\",encoding='utf8')\n",
    "        inconnus=exceptions.readlines()\n",
    "        exceptions.close()\n",
    "    except IOError:\n",
    "        boolExceptions=False\n",
    "    if fichier_exceptions:\n",
    "        oldExceptions=[]\n",
    "        for entry in inconnus:\n",
    "            entry=entry.strip()\n",
    "            if 0: print entry\n",
    "            p=entry.split(\";\")\n",
    "            if len(p)<9:\n",
    "                for i in range(len(p)+1,10):\n",
    "                    p.append(u\"\")\n",
    "            if 0: print p\n",
    "            if len(p[1])!=0:\n",
    "                phon[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "            oldExceptions.append(p[0].lower())\n",
    "    for numTRS,nomTRS in enumerate(fichiersTRS):\n",
    "        print nomTRS\n",
    "        fichierBDL=nomTRS[:-4]+\"-BDL2.xml\"\n",
    "        if nomTRS.split(\"/\")[-1] in sansRebalisageFichiers:\n",
    "            print \"SANS reBALISER\"\n",
    "            xmlTRS=etree.parse(nomTRS,parser)\n",
    "            print \"FIN parse\"\n",
    "        else:\n",
    "            fichierTRS=baliserTRS(nomTRS)\n",
    "            print \"FIN reBALISER\"\n",
    "            xmlTRS=etree.fromstring(fichierTRS,parser)\n",
    "            print \"FIN fromstring\"\n",
    "        (motsCorpus,motsPhrases,elementsPhrases)=listerMotsCorpus(xmlTRS)\n",
    "        print \"FIN lister mots\"\n",
    "        phon=extraireMotsTRS(motsCorpus,phon)\n",
    "        print \"FIN extraire mots\"\n",
    "        traitementTRS(xmlTRS)\n",
    "        print \"FIN traitement\"\n",
    "        with codecs.open(fichierBDL, \"w\", encoding='utf8') as f:\n",
    "            for ligne in enteteXML:\n",
    "                f.write(ligne+u\"\\n\")\n",
    "            f.write(etree.tostring(xmlTRS,pretty_print=True,encoding=\"utf8\").decode(\"utf8\"))\n",
    "    with codecs.open(fichierExceptions, \"a\", encoding='utf8') as f:\n",
    "        for n in set(nouvellesExceptions):\n",
    "            if not (n in oldExceptions): \n",
    "                f.write(n+u\";;;;;;;;;;;;\")\n",
    "                f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print fichierTRS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
