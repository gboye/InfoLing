{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /opt/anaconda3/lib/python3.11/site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des EAF avec BDLexique\n",
    "- la phonétisation dans un fichier-phonetique.eaf\n",
    "- les éléments de BDLexique et les balises complémentaires dans un fichier.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time, sys, codecs, re, glob\n",
    "import pdb # ajouter pdb.set_trace() à l'endroit où on veut le débugueur\n",
    "from lxml import etree as ET\n",
    "import bs4\n",
    "# import xml.etree.cElementTree as ET\n",
    "import os, fnmatch, unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annee=22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un parser XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = ET.XMLParser(remove_blank_text=True)\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lire BDLexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fichierLexique=\"/Users/gilles/ownCloud/Cours/Bordeaux/L2-XML/XML-Ressources/bdlexique.txt\"\n",
    "fichier_exceptions=True\n",
    "\n",
    "lexicon=codecs.open(fichierLexique,\"r\",encoding='utf8')\n",
    "lBdlexique=lexicon.readlines()\n",
    "lexicon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bdlexique={}\n",
    "for line in lBdlexique:\n",
    "    line=line.strip()\n",
    "    p=line.split(u';')\n",
    "    if p[2]==\"@\" and not p[3] in [\"N\",\"V\",\"J\",\"K\"]:\n",
    "        p[1]+=p[2]\n",
    "        p[2]=\"\"\n",
    "        if len(p)<7:\n",
    "            for i in range(len(p)+1,7):\n",
    "                p.append(\"\")\n",
    "    bdlexique[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8],p[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connecteurs=[\n",
    "    u\"et\", u\"alors\", u\"du coup\", u\"sinon\", u\"par contre\", u\"ça veut dire\", u\"enfin\",\n",
    "u\"après\", u\"donc\", u\"puisque\", u\"puisqu'\", u\"en fait\", u\"mais\", u\"parce que\", u\"parce qu'\", u\"même si\" , u\"d'abord\", u\"et puis\"\n",
    "]\n",
    "motTheme=[u\"cible\",u\"frontières\",u\"accueillir\",u\"démonstrations\",\n",
    "          u\"accompagner\",u\"contre-courant\",u\"importantes\",u\"droit de bouger\",\n",
    "          u\"peur\",u\"solution\",u\"durable\",u\"refuge\",u\"assassins\",u\"tueurs\",u\"violeurs\",\n",
    "          u\"fuient\",u\"misère\",u\"chaos\",u\"circulation\",u\"liberté\",u\"installation\",\n",
    "          u\"solidarité\",u\"migrants\",u\"ouverture\",u\"frontières\",u\"conditions\",u\"réflexe\",\n",
    "          u\"normal\",u\"sain\",u\"accueillir\",u\"moyens\",u\"intégrés\",u\"flux\",u\"migratoires\",\n",
    "          u\"énormes\",u\"moyens\",u\"structures\",u\"loger\",u\"répondre\",u\"peuples\",u\"coopération\",\n",
    "          u\"indéniable\",u\"réfugiés\",u\"digne\",u\"prendre la main\",u\"équilibrée\",u\"accueil\",\n",
    "          u\"correctement\",u\"favorable\",u\"hébergés\",u\"mise à l’abri\",u\"centre humanitaire\",\n",
    "          u\"situation\",u\"convenable\",u\"heurtée\",u\"valeurs\",u\"république\",u\"comportement\",\n",
    "          u\"politique\",u\"associations\",u\"hébergement\",u\"respect\",u\"lien\",u\"confiance\",\n",
    "          u\"travailleur\",u\"social\",u\"policiers\",u\"gazent\",u\"détruisent\",u\"nourriture\",\n",
    "          u\"refusent\",u\"points d’eau\",u\"négation\",u\"partent\",u\"parcours\",u\"migration\",\n",
    "          u\"terribles\",u\"touche\",u\"cimetière\",u\"choquant\",u\"scandaleux\",u\"dignité\",\n",
    "          u\"impression\",u\"responsabilités\",u\"multiplication\",u\"conflits\",u\"excessivement\",\n",
    "          u\"violents\",u\"solution\",u\"seule\",u\"quitter\",u\"victimes\",u\"esclavage\",\n",
    "          u\"regression\",u\"humanité\",u\"guerre\",u\"état\",u\"pauvreté\",u\"pays\",u\"conditions\",\n",
    "          u\"respect\",u\"organisme\",u\"ficher\",u\"contrôler\",u\"demande\",u\"papiers\",u\"droits\",\n",
    "          u\"échec\",u\"aide\",u\"développement\",u\"vivre\",u\"famille\",u\"terrain\",u\"voir\",\n",
    "          u\"souffrance\",u\"regression\",u\"France\",u\"richesse\",u\"humanité\",u\"extraordinaire\",\n",
    "          u\"intérger\",u\"asile\",u\"question\",u\"temporaire\",u\"débat\",u\"souhaitons\",\n",
    "          u\"propositions\",u\"européen\",u\"rapprocher\",u\"proches\",u\"position\",u\"absurdité\",\n",
    "          u\"ONG\",u\"aider\",u\"détresse\",u\"lois\",u\"règles\",u\"principes\",u\"humanité\",\n",
    "          u\"vulnérable\",u\"enfants\",u\"sauver\",u\"vies\",u\"générosité\",u\"classes\",\n",
    "          u\"francophones\",u\"découverte\",u\"langue\",u\"logements\",u\"associations\",\n",
    "          u\"continuerai\",u\"nouveaux\",u\"clé\",u\"chômage\",u\"héberger\",u\"employer\",u\"former\",\n",
    "          u\"éduquer\",u\"milliers\",u\"vaincre\",u\"réticences\",u\"acccepter\",u\"aménage\",\n",
    "          u\"refuges\",u\"régions\",u\"viennent\",u\"zones\",u\"protégées\",u\"normales\",u\"chez-eux\",\n",
    "          u\"circuler\",u\"librement\",u\"Allemagne\",u\"obligations\",u\"humanitaire\",u\"préserver\",\n",
    "          u\"populations\",u\"bataille\",u\"hégémonique\",u\"bataille\",u\"s'installer\",u\"mois\",\n",
    "          u\"désaccord\",u\"moins\",u\"accueillant\",u\"bataille\",u\"idéologique\",u\"pression\",\n",
    "          u\"chercher\",u\"immigrés\",u\"de force\",u\"délogés\",u\"expulsés\",u\"xénophobie\",\n",
    "          u\"racistes\",u\"recul\",u\"idées\",u\"argent\",u\"dramatique\",u\"problèmes\",u\"économiques\",\n",
    "          u\"interventions\",u\"militaires\",u\"famine\",u\"massacres\",u\"répression\",u\"bombardé\",\n",
    "          u\"manqué\",u\"devoir\",u\"indigne\",u\"déposer\",u\"demande d'asile\",u\"absurde\",\n",
    "          u\"campements\",u\"regrette\",u\"dispositifs\",u\"pérennes\",u\"divergence\",\n",
    "          u\"appréciation\",u\"reconstitution\",u\"campements\",u\"crise\",u\"emballement\",\n",
    "          u\"otage\",u\"noyer\",u\"guerre\",u\"bombardement\",u\"morts\",u\"difficultés\",u\"blocage\",\n",
    "          u\"maltraiter\",u\"seul\",u\"privation\",u\"absurde\",u\"illusion\",u\"mensonge\",u\"ghettos\",\n",
    "          u\"français\",u\"divisés\",u\"meurent\",u\"fuient\",u\"devoirs\",u\"moraux\",\n",
    "          u\"centres de rétention\",u\"protection\",u\"cause\",u\"guerre\",u\"lieu\",u\"couteux\",\n",
    "          u\"charge\",u\"services\",u\"gratuits\",u\"système\",u\"gestion\",u\"patrimoine\",\n",
    "          u\"nationale\",u\"importante\",u\"fossé\",u\"travail\",u\"difficulté\",u\"maîtrise\",\n",
    "          u\"suspendre\",u\"shengen\",u\"arrêter\",u\"immigration\",u\"communautarisme\",\n",
    "          u\"fondamentalisme\",u\"islamiste\",u\"gel\",u\"constructions\",u\"mosquées\",u\"islam\",\n",
    "          u\"radicaux\",u\"vivier\",u\"radicalisation\",u\"soldats\",u\"djihadisme\",u\"terroristes\",\n",
    "          u\"puissance\",u\"terreau\",u\"frappent\",u\"clandestine\",u\"massive\",u\"insécurité\",\n",
    "          u\"terrifiante\",u\"forces de l'ordre\",u\"mesures législatives\",u\"suppression\",\n",
    "          u\"enrayer\",u\"processus\",u\"récupérer\",u\"clandestins\",u\"absence\",u\"bateaux\",\n",
    "          u\"en mer\",u\"ramener\",u\"facilite\",u\"réseaux\",u\"criminels\",u\"laisser\",u\"mourir\",\n",
    "          u\"sauver\",u\"ramener\",u\"port d’origine\",u\"corrompus\",u\"passeurs\",u\"arme\",\n",
    "          u\"catastrophique\",u\"occupation\",u\"illégale\",u\"inexpulsable\",u\"engrenage\",\n",
    "          u\"procédures\",u\"demandeurs\",u\"déboutés\",u\"économique\",u\"raisons\",u\"traverser\",\n",
    "          u\"sortis\",u\"territoire\",u\"arrivés\",u\"origine\",u\"critères\",u\"extrêmement\",\n",
    "          u\"incitatif\",u\"centres\",u\"AME\",u\"CMU\",u\"ensemble\",u\"folle\",u\"coût\",u\"faramineux\",\n",
    "          u\"malvenu\",u\"opposition\",u\"opposée\",u\"communautarisme\",u\"fondamentalisme\",\n",
    "          u\"imposer\",u\"ennemi\",u\"contre\",u\"rejet\",u\"anti-démocratique\",u\"enfermemement\",\n",
    "          u\"séparation\",u\"pourissement\",u\"étranger\",u\"drame\",u\"faillite\",u\"déloyale\",\n",
    "          u\"ménage\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatage divers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time2TRS(time):\n",
    "    return str(float(time)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "consonnes=['k\"', '(kt)\"', 'n\"', 'p\"', 'R\"', '@t\"', 't\"', '-V', '+V', '@z\"', 'z\"']\n",
    "voyelles=[\"H\", \"j\", \"w\", \"E\", \"a\", \"2\", \"9\", \"6\", \"@\", \"y\", \"u\", \"O\", u\"ò\", \"o\", \"e\", u\"è\", u\"ê\", u\"û\", u\"ô\", \"i\"]\n",
    "\n",
    "# traduire SAMPA-BDLex en API\n",
    "\n",
    "def sampa2api(sampa):\n",
    "    if isinstance(sampa,str):\n",
    "        # api=sampa.decode(\"utf8\")\n",
    "        api=sampa\n",
    "    else:\n",
    "        api=sampa\n",
    "    api=api.replace(u'n\"',u'n') \n",
    "    api=api.replace(u't\"',u't') \n",
    "    api=api.replace(u'z\"',u'z') \n",
    "    api=api.replace(u'R\"',u'ʁ') \n",
    "    api=api.replace(u'p\"',u'p') \n",
    "    api=api.replace(u'S',u'ʃ') \n",
    "    api=api.replace(u'Z',u'ʒ')\n",
    "    api=api.replace(u'N',u'ŋ')\n",
    "    api=api.replace(u'J',u'ɲ')\n",
    "    api=api.replace(u'r',u'ʁ') \n",
    "    api=api.replace(u'H',u'ɥ')\n",
    "    api=api.replace(u'E',u'ɛ')\n",
    "    api=api.replace(u'2',u'ø')\n",
    "    api=api.replace(u'9',u'œ')\n",
    "    api=api.replace(u'6',u'ə')\n",
    "    api=api.replace(u'O',u'ɔ')\n",
    "    api=api.replace(u'è',u'e')   \n",
    "    api=api.replace(u'ò',u'o')    \n",
    "    api=api.replace(u'â',u'ɑ̃')   \n",
    "    api=api.replace(u'ê',u'ɛ̃')   \n",
    "    api=api.replace(u'û',u'œ̃')  \n",
    "    api=api.replace(u'ô',u'ɔ̃')       \n",
    "    api=api.replace(u'@',u'ə')\n",
    "#     api=api.replace(u'R',u'ʁ') \n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion Liaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liaison possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant ne sont pas dans lexicon, pas de liaison\n",
    "+ si le mot a une consonne dans le champ de la voyelle de liaison, check1 est vrai\n",
    "+ si le mot suivant commence par une voyelle, check2 est vrai\n",
    "\n",
    "  si check1 et check2 sont vrais, il y a liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def formerLiaison(mot1,mot2,contexteLiaison=False):\n",
    "    if mot1[1][1]:\n",
    "        result=sampa2api(mot1[1][1])\n",
    "        if contexteLiaison:\n",
    "#             print (mot1,) \n",
    "#             print (mot2)\n",
    "            if mot1[1][2] in consonnes and mot2[1][1][0] in voyelles:\n",
    "                result+=sampa2api(mot1[1][2].strip(\"()\"))\n",
    "    else:\n",
    "        result=\"***%s***\"%mot1[1][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tɛkstɔ̃\n"
     ]
    }
   ],
   "source": [
    "print (formerLiaison([\"textons\",(\"1\",\"tEkstô\",\"3\")],None,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liaison obligatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def liaison_obligatoire(mot1,mot2):\n",
    "    determinant=[\"d\", \"P\"]\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    pronompers=[\"P\"]\n",
    "    verbe=[\"V\"]\n",
    "    cat1=mot1[1][3]\n",
    "    cat2=mot2[1][3]\n",
    "#     print (cat1,cat2)\n",
    "\n",
    "    if cat1 in determinant and cat2 in nom :\n",
    "        return True\n",
    "\n",
    "    elif cat1 in determinant and cat2 in adjectif :\n",
    "        return True\n",
    "\n",
    "    elif cat1 in adjectif and cat2 in nom :\n",
    "        return True\n",
    "    \n",
    "    elif cat1 in pronompers and cat2 in verbe :\n",
    "        return True\n",
    "\n",
    "    elif cat1 in verbe and cat2 in pronompers :\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles:\n",
    "\n",
    "- DET + N\n",
    "    * ri + N:   d'animal, \n",
    "    * di + N:   certains éléphants\n",
    "    * rd + N:   les animaux\n",
    "    * dd + N:   ces étés, cet été\n",
    "    * dp + N:   ton anorak\n",
    "    * rc + N:   aux armes\n",
    "- DET + ADJ:\n",
    "    * ri + ADJ:   d'énormes\n",
    "    * di + ADJ:   plusieurs immenses\n",
    "    * rd + ADJ:   les immenses\n",
    "    * dd + ADJ:   cet immense\n",
    "    * dp + ADJ:   son immense\n",
    "    * rc + ADJ:   aux immenses\n",
    "- PERS + V:\n",
    "    * SS + V:   m'épate\n",
    "- V + PRO PERS: \n",
    "    * V + SS:   vont-ils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithme\n",
    "\n",
    "+ si le mot courant et le suivant sont dans un des cas de figure, il y a liaison\n",
    "+ sinon pas de liaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liaison facultative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vérifier si la liaison est facultative\n",
    "def liaison_facultative(mot1,mot2):\n",
    "    #pdb.set_trace()\n",
    "    nom=[\"N\", \"G\", \"M\"]\n",
    "    pluriel=[\"MP\", \"FP\"]\n",
    "    adjectif=[\"J\", \"G\", \"M\"]\n",
    "    verbe=[\"V\"]\n",
    "    pronompers=[\"P\"]\n",
    "    adverbe=[\"A\"]\n",
    "    preposition=[\"p\"]\n",
    "    cat1=mot1[1][3]\n",
    "    cat2=mot2[1][3]\n",
    "    \n",
    "    if (cat1 in nom) and (mot1[1][4] in pluriel) and (cat2 in adjectif) : \n",
    "        return True\n",
    "\n",
    "    elif (cat1 in verbe) and (cat2 not in pronompers):\n",
    "        return True\n",
    "\n",
    "    elif cat1 in adverbe :\n",
    "        return True\n",
    "    \n",
    "    elif cat1 in preposition : \n",
    "        return True\n",
    "\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas de figure possibles :\n",
    "\n",
    "- N pl + ADJ: \n",
    "    * N + ADJ: monstres énormes \n",
    "    * G + ADJ: rivaux énormes\n",
    "- VERBE + TOUT-SAUF-PRO-PERS:\n",
    "    * V + N sont éléphants\n",
    "    * V + G sommes abdicaires\n",
    "    * V + V sommes assis\n",
    "    * V + A sommes admirablement\n",
    "    * V + p sommes autour de\n",
    "    * V + di ont aucune\n",
    "    * V + rc sommes au\n",
    "- ADV + QQCH:\n",
    "    * ADV + N vraiment abruti\n",
    "    * ADV + G vraiment abandonné\n",
    "    * ADV + V vraiment aimé\n",
    "    * ADV + J vraiment étonnant\n",
    "    * ADV + ss vraiment ils\n",
    "    * ADV + A vraiment étonnamment\n",
    "    * ADV + p vraiment attendu\n",
    "    * ADV + di vraiment autre \n",
    "    * ADV + rc vraiment au\n",
    "- PREP + QQCH:\n",
    "    * PREP + N très amoureux\n",
    "    * PREP + G très abandonné\n",
    "    * PREP + V très aimé\n",
    "    * PREP + J très étonnant\n",
    "    * PREP + SS très ils\n",
    "    * PREP + A très étonnamment\n",
    "    * PREP + p très attendu\n",
    "    * PREP + di très autre\n",
    "    * PREP + rc très au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Partie 1\n",
    "*chaque phrase est prise individuellement,\n",
    "    * découpée en blocs,\n",
    "        * qui sont chacuns trimés si ce sont des mots\n",
    "        * s'il y a plusieurs mots dans le bloc, ils sont séparés\n",
    "    + Partie 2\n",
    "    * pour chaque couple de mots\n",
    "        * si la liaison est possible,\n",
    "            * et qu'elle est obligatoire, l'api avec la liaison est généré\n",
    "            * et qu'elle est facultative,\n",
    "                * si l'utilisateur l'a choisi, l'api avec la liaison est généré\n",
    "                * sinon l'api sans la liaison est généré\n",
    "\n",
    "        + Partie 3\n",
    "        * si la liaison n'est pas possible,\n",
    "            * si le mot est dans bdlex, l'api est généré\n",
    "            * sinon le mot est laissé tel quel (il a déjà les étoiles)        \n",
    "\n",
    "    * pour le dernier mot de la phrase, \n",
    "        * si le mot est dans bdlex, l'api est généré\n",
    "        * sinon le mot est laissé tel quel (il a déjà les étoiles) \n",
    "\n",
    "+ Partie 4\n",
    "* le message à l'utilisateur et la phrase en api est imprimée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparer structures Tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "altEspace=r\"\\s|_\"\n",
    "connecteurs=[\n",
    "    u\"et\", u\"alors\", u\"du coup\", u\"sinon\", u\"par contre\", u\"ça veut dire\", u\"enfin\",\n",
    "u\"après\", u\"donc\", u\"puisque\", u\"puisqu'\", u\"en fait\", u\"mais\", u\"parce que\", u\"parce qu'\", u\"même si\" , u\"d'abord\", u\"et puis\"\n",
    "]\n",
    "immigration=[u\"cible\",u\"frontières\",u\"accueillir\",u\"démonstrations\",u\"accompagner\",u\"contre-courant\",u\"importantes\",u\"droit de bouger\",u\"peur\",u\"solution\",u\"durable\",u\"refuge\",u\"assassins\",u\"tueurs\",u\"violeurs\",u\"fuient\",u\"misère\",u\"chaos\",u\"circulation\",u\"liberté\",u\"installation\",u\"solidarité\",u\"migrants\",u\"ouverture\",u\"frontières\",u\"conditions\",u\"réflexe\",u\"normal\",u\"sain\",u\"accueillir\",u\"moyens\",u\"intégrés\",u\"flux\",u\"migratoires\",u\"énormes\",u\"moyens\",u\"structures\",u\"loger\",u\"répondre\",u\"peuples\",u\"coopération\",u\"indéniable\",u\"réfugiés\",u\"digne\",u\"prendre la main\",u\"équilibrée\",u\"accueil\",u\"correctement\",u\"favorable\",u\"hébergés\",u\"mise à l’abri\",u\"centre humanitaire\",u\"situation\",u\"convenable\",u\"heurtée\",u\"valeurs\",u\"république\",u\"comportement\",u\"politique\",u\"associations\",u\"hébergement\",u\"respect\",u\"lien\",u\"confiance\",u\"travailleur\",u\"social\",u\"policiers\",u\"gazent\",u\"détruisent\",u\"nourriture\",u\"refusent\",u\"points d’eau\",u\"négation\",u\"partent\",u\"parcours\",u\"migration\",u\"terribles\",u\"touche\",u\"cimetière\",u\"choquant\",u\"scandaleux\",u\"dignité\",u\"impression\",u\"responsabilités\",u\"multiplication\",u\"conflits\",u\"excessivement\",u\"violents\",u\"solution\",u\"seule\",u\"quitter\",u\"victimes\",u\"esclavage\",u\"regression\",u\"humanité\",u\"guerre\",u\"état\",u\"pauvreté\",u\"pays\",u\"conditions\",u\"respect\",u\"organisme\",u\"ficher\",u\"contrôler\",u\"demande\",u\"papiers\",u\"droits\",u\"échec\",u\"aide\",u\"développement\",u\"vivre\",u\"famille\",u\"terrain\",u\"voir\",u\"souffrance\",u\"regression\",u\"France\",u\"richesse\",u\"humanité\",u\"extraordinaire\",u\"intérger\",u\"asile\",u\"question\",u\"temporaire\",u\"débat\",u\"souhaitons\",u\"propositions\",u\"européen\",u\"rapprocher\",u\"proches\",u\"position\",u\"absurdité\",u\"ONG\",u\"aider\",u\"détresse\",u\"lois\",u\"règles\",u\"principes\",u\"humanité\",u\"vulnérable\",u\"enfants\",u\"sauver\",u\"vies\",u\"générosité\",u\"classes\",u\"francophones\",u\"découverte\",u\"langue\",u\"logements\",u\"associations\",u\"continuerai\",u\"nouveaux\",u\"clé\",u\"chômage\",u\"héberger\",u\"employer\",u\"former\",u\"éduquer\",u\"milliers\",u\"vaincre\",u\"réticences\",u\"acccepter\",u\"aménage\",u\"refuges\",u\"régions\",u\"viennent\",u\"zones\",u\"protégées\",u\"normales\",u\"chez-eux\",u\"circuler\",u\"librement\",u\"Allemagne\",u\"obligations\",u\"humanitaire\",u\"préserver\",u\"populations\",u\"bataille\",u\"hégémonique\",u\"bataille\",u\"s'installer\",u\"mois\",u\"désaccord\",u\"moins\",u\"accueillant\",u\"bataille\",u\"idéologique\",u\"pression\",u\"chercher\",u\"immigrés\",u\"de force\",u\"délogés\",u\"expulsés\",u\"xénophobie\",u\"racistes\",u\"recul\",u\"idées\",u\"argent\",u\"dramatique\",u\"problèmes\",u\"économiques\",u\"interventions\",u\"militaires\",u\"famine\",u\"massacres\",u\"répression\",u\"bombardé\",u\"manqué\",u\"devoir\",u\"indigne\",u\"déposer\",u\"demande d'asile\",u\"absurde\",u\"campements\",u\"regrette\",u\"dispositifs\",u\"pérennes\",u\"divergence\",u\"appréciation\",u\"reconstitution\",u\"campements\",u\"crise\",u\"emballement\",u\"otage\",u\"noyer\",u\"guerre\",u\"bombardement\",u\"morts\",u\"difficultés\",u\"blocage\",u\"maltraiter\",u\"seul\",u\"privation\",u\"absurde\",u\"illusion\",u\"mensonge\",u\"ghettos\",u\"français\",u\"divisés\",u\"meurent\",u\"fuient\",u\"devoirs\",u\"moraux\",u\"centres de rétention\",u\"protection\",u\"cause\",u\"guerre\",u\"lieu\",u\"couteux\",u\"charge\",u\"services\",u\"gratuits\",u\"système\",u\"gestion\",u\"patrimoine\",u\"nationale\",u\"importante\",u\"fossé\",u\"travail\",u\"difficulté\",u\"maîtrise\",u\"suspendre\",u\"shengen\",u\"arrêter\",u\"immigration\",u\"communautarisme\",u\"fondamentalisme\",u\"islamiste\",u\"gel\",u\"constructions\",u\"mosquées\",u\"islam\",u\"radicaux\",u\"vivier\",u\"radicalisation\",u\"soldats\",u\"djihadisme\",u\"terroristes\",u\"puissance\",u\"terreau\",u\"frappent\",u\"clandestine\",u\"massive\",u\"insécurité\",u\"terrifiante\",u\"forces de l'ordre\",u\"mesures législatives\",u\"suppression\",u\"enrayer\",u\"processus\",u\"récupérer\",u\"clandestins\",u\"absence\",u\"bateaux\",u\"en mer\",u\"ramener\",u\"facilite\",u\"réseaux\",u\"criminels\",u\"laisser\",u\"mourir\",u\"sauver\",u\"ramener\",u\"port d’origine\",u\"corrompus\",u\"passeurs\",u\"arme\",u\"catastrophique\",u\"occupation\",u\"illégale\",u\"inexpulsable\",u\"engrenage\",u\"procédures\",u\"demandeurs\",u\"déboutés\",u\"économique\",u\"raisons\",u\"traverser\",u\"sortis\",u\"territoire\",u\"arrivés\",u\"origine\",u\"critères\",u\"extrêmement\",u\"incitatif\",u\"centres\",u\"AME\",u\"CMU\",u\"ensemble\",u\"folle\",u\"coût\",u\"faramineux\",u\"malvenu\",u\"opposition\",u\"opposée\",u\"communautarisme\",u\"fondamentalisme\",u\"imposer\",u\"ennemi\",u\"contre\",u\"rejet\",u\"anti-démocratique\",u\"enfermemement\",u\"séparation\",u\"pourissement\",u\"étranger\",u\"drame\",u\"faillite\",u\"déloyale\",u\"ménage\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "immigrationMots=sorted(set(immigration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compterVoyelles(chaine):\n",
    "    result=0\n",
    "    for element in chaine:\n",
    "        if element in voyelles:\n",
    "            result+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lister les groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listerGroupes(repRacine):\n",
    "    return glob.glob(repRacine+r\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chercher les inconnus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dicterInconnus(lInconnus):\n",
    "    result={}\n",
    "    for line in lInconnus:\n",
    "        line=line.strip()\n",
    "        p=line.split(\";\")\n",
    "        if len(p[1])!=0:\n",
    "            if len(p)>8:\n",
    "                # print (p)\n",
    "                for i in range(len(p)+1,7):\n",
    "                    p.append(\"\")\n",
    "            result[p[0].lower()]=(p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7],p[8])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lireInconnus(repGroupe):\n",
    "    result={}\n",
    "    fInconnus=repGroupe+\"/inconnus.txt\"\n",
    "    try:\n",
    "        with codecs.open(fInconnus,\"r\",encoding=\"utf8\") as inFile:\n",
    "            lInconnus=inFile.readlines()\n",
    "        result=dicterInconnus(lInconnus)\n",
    "        # print (result)\n",
    "    except:\n",
    "        print (\"pas d'inconnus.txt\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lister les EAFs du groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listerEAFs(repGroupe):\n",
    "    result=[f for f in glob.glob(repGroupe+r\"/*.eaf\") if \"phonetique\" not in unidecode.unidecode(f.lower())]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lister les mots d'un EAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trimer(mot):\n",
    "#     mot=mot.lower()\n",
    "    for p in u',;.-?!“”‘’‛‟′″´˝\"«»':      # Modifié le 12/01/20 pour gérer les deux points comme marqueur dans les mots\n",
    "        mot=mot.replace(p, ' ')\n",
    "    mot=mot.strip()\n",
    "    return mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deparentheser(mot):\n",
    "    forme=mot\n",
    "    graphie=mot\n",
    "    m=re.search(r\"\\([^)]*\\)\",forme)\n",
    "    while (m):\n",
    "        forme=re.sub(r\"\\(([^)]*)\\)\",\"\\g<1>\", forme)\n",
    "        graphie=re.sub(r\"\\(([\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ]+['’]?)\\)\",\"'\", graphie)\n",
    "        m=re.search(r\"\\([^)]*\\)\",forme)\n",
    "    forme=forme.lstrip(\")\").rstrip(\"(\")\n",
    "    forme=forme.replace(\":\",\"\")\n",
    "    if graphie.endswith(\"(\"):\n",
    "        graphie=graphie[:-1]+\"'\"\n",
    "    return(forme,graphie)\n",
    "#    motsAbreges[mot]={\"lexical\":forme, \"graphie\":graphie}    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bec ter', ('Maintenant', \"Main'nant\"))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimer(\"bec‘ter\"), deparentheser(\"Main(te)nant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizerTour(tour,lexique):\n",
    "    listeMots=[]\n",
    "    listeTokens=[]\n",
    "    elements=re.findall(r\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ():]+/?|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", tour)\n",
    "    # print (elements)\n",
    "    elements=[x for x in elements if x!=u\" \"]\n",
    "    mots=[x for x in elements if not x in u\"-_.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~:\" and not x in [u\" ;\",u\" !\",u\" ?\",u\" :\"]]\n",
    "    for element in elements:\n",
    "        if element in mots:\n",
    "            mot = trimer(element)\n",
    "            (forme,graphie)=deparentheser(mot)\n",
    "            listeMots.append(graphie)\n",
    "            if forme.lower() in lexique:\n",
    "                listeTokens.append(lexique[forme.lower()])\n",
    "            else:\n",
    "                listeTokens.append(forme.lower())\n",
    "        else:\n",
    "            listeMots.append(element)\n",
    "            listeTokens.append(element)\n",
    "    return listeMots,listeTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['blablabla',\n",
       "  'e',\n",
       "  '[',\n",
       "  'bruit',\n",
       "  ']',\n",
       "  'dans',\n",
       "  'l/',\n",
       "  'la',\n",
       "  'première',\n",
       "  'im/',\n",
       "  'e',\n",
       "  'pardon'],\n",
       " [('blablabla', 'blablabla', '', 'N', 'MS', '', 'blablabla', '', '88', '34'),\n",
       "  ('e', '6', '', 'N', 'Mj', '', 'e', 'L23', '6091', '2899'),\n",
       "  '[',\n",
       "  'bruit',\n",
       "  ']',\n",
       "  ('dans', 'dâ', 'z\"', 'p', '', '', 'dans', 'L23', '465859', '829608'),\n",
       "  'l/',\n",
       "  ('la', 'la', '', 'd', 'FS', 'rd', 'la', 'L23', '***', '***'),\n",
       "  ('première', 'pr6mjEr', '@', 'N', 'FS', '', 'première', 'L23', '***', '***'),\n",
       "  'im/',\n",
       "  ('e', '6', '', 'N', 'Mj', '', 'e', 'L23', '6091', '2899'),\n",
       "  ('pardon', 'pardô', '', 'N', 'MS', '', 'pardon', 'L23', '5562', '2689')])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizerTour(\"blablabla {e} [bruit] dans {l/} la première {im/} {e} pardon\",subBdlexique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizerTexte(texte):\n",
    "    listeMots=set()\n",
    "    elements=re.findall(r\"[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ():]+|[-.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~]| ?[;!?:]\", texte)\n",
    "    elements=[x for x in elements if x!=u\" \"]\n",
    "    mots=[x for x in elements if not x in u\"-_.…,—–()\\[\\]\\/#\\\"“”‘«»<>'’=~:\" and not x in [u\" ;\",u\" !\",u\" ?\",u\" :\"]]\n",
    "    for mot in mots:\n",
    "        mot = trimer(mot)\n",
    "        (forme,graphie)=deparentheser(mot)\n",
    "        listeMots.add(forme.lower())\n",
    "    return list(listeMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listerMots(nomEAF):\n",
    "    xmlEAF=ET.parse(nomEAF,parser)\n",
    "    texteLignesEAF=[]\n",
    "    for tier in xmlEAF.xpath(\"//TIER\"):\n",
    "        for annotation in tier.xpath(\"ANNOTATION/ALIGNABLE_ANNOTATION\"):\n",
    "            aValue=annotation.xpath(\"ANNOTATION_VALUE/text()\")\n",
    "            texteLignesEAF.append(\"\\n\".join(aValue))\n",
    "    texteEAF=\"\\n\".join(texteLignesEAF)\n",
    "    return tokenizerTexte(texteEAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def faireLexique(nomEAF,groupeInconnus):\n",
    "    extraitBdlexique={}\n",
    "    listeMots=listerMots(nomEAF)\n",
    "    for forme in listeMots:\n",
    "        if forme in groupeInconnus:\n",
    "            extraitBdlexique[forme]=groupeInconnus[forme]\n",
    "        elif forme in bdlexique:\n",
    "            extraitBdlexique[forme]=bdlexique[forme]\n",
    "        else:\n",
    "            groupeInconnus[forme]=(forme,\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\")\n",
    "            extraitBdlexique[forme]=(forme,\"***%s***\"%forme,\"\",\"\",\"\",\"\",\"\",\"\",\"\")\n",
    "    return extraitBdlexique,groupeInconnus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dicterContent(content,lexique):\n",
    "    lMots,lTokens=tokenizerTour(content,lexique)\n",
    "    result=[[mot,lTokens[nMot]] for nMot,mot in enumerate(lMots)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changement de convention d'annotation pour les disfluences\n",
    "- 2021: \n",
    "    - [blablabla] => \\<disfluence\\>blablabla\\</disfluence\\>\n",
    "- 2022: \n",
    "    - [rire] => \\<rire/\\>\n",
    "    - {blablabla} => \\<disfluence\\>blablabla\\</disfluence\\>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def makeAttribs(chaine):\n",
    "    result=chaine\n",
    "    mAttribs=re.match(r\"(\\w+) (((\\w+)=[\\\"\\']?[^\\\"\\']+[\\\"\\']?\\s*)+)\",chaine)\n",
    "    if mAttribs:\n",
    "        result=mAttribs.group(1)+\" \"+mAttribs.group(2)\n",
    "    else:\n",
    "        mType=re.match(r\"(\\w+) (.*)\",chaine)\n",
    "        if mType:\n",
    "            result=mType.group(1)+\" type='%s'\"%mType.group(2)\n",
    "    return result \n",
    "\n",
    "def makeTagAttribs(chaine):\n",
    "    resTag=unidecode.unidecode(chaine)\n",
    "    resAttrib={}\n",
    "    mAttribs=re.match(r\"(\\w+) (((\\w+)=[\\\"\\']?[^\\\"\\']+[\\\"\\']?\\s*)+)\",chaine,re.U)\n",
    "    if mAttribs:\n",
    "#         print (mAttribs.groups())\n",
    "        resTag=unidecode.unidecode(mAttribs.group(1))\n",
    "        if \"'\" not in mAttribs.group(2) and '\"' not in mAttribs.group(2):\n",
    "            resAttrib=re.findall(r\"(\\w+)=(\\S+)\",mAttribs.group(2),re.U)\n",
    "#             print (resAttrib)\n",
    "            resAttrib={unidecode.unidecode(k):v for k,v in resAttrib}            \n",
    "        else:\n",
    "            resAttrib=re.findall(r\"(\\w+)=[\\\"\\']([^\\\"\\']+)[\\\"\\']\",mAttribs.group(2),re.U)\n",
    "#             print (resAttrib)\n",
    "            resAttrib={unidecode.unidecode(k):v for k,v in resAttrib}\n",
    "    else:\n",
    "        mType=re.match(r\"(\\w+) (.*)\",chaine,re.U)\n",
    "        if mType:\n",
    "            resTag=unidecode.unidecode(mType.group(1))\n",
    "            resAttrib={\"type\":mType.group(2)}\n",
    "    return resTag,resAttrib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e t=acc p=fRãsE'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeAttribs(u\"e t=acc p=fRãsE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def baliserTour(tour,lexique):    \n",
    "    lMorceaux=re.split(r\"([[{][^}\\]]*[}\\]])\",tour)\n",
    "    # print (lMorceaux)\n",
    "    newTour=[]\n",
    "    for lMorceau in lMorceaux:\n",
    "        m1=re.match(r\"\\[(.*)\\]\",lMorceau)\n",
    "        m2=re.match(r\"\\{(.*)\\}\",lMorceau)\n",
    "        if m1:\n",
    "            bContent=m1.group(1)\n",
    "            if bContent.startswith(u\"=\"):\n",
    "                newTour.append([\"[%s]\"%bContent,\"<%s>\"%makeAttribs(bContent[1:])])\n",
    "            elif bContent.startswith(u\"/\"):\n",
    "                newTour.append([\"[%s]\"%bContent,\"</%s>\"%bContent[1:]])\n",
    "            else:\n",
    "                newTour.append([\"[%s]\"%bContent,\"<%s/>\"%makeAttribs(bContent)])\n",
    "        elif m2:\n",
    "            aContent=m2.group(1)\n",
    "            newTour.append([\"{\",\"<disfluence>\"])\n",
    "            aContentDict=dicterContent(aContent,lexique)\n",
    "            newTour.extend(aContentDict)\n",
    "            newTour.append([\"}\",\"</disfluence>\"])\n",
    "\n",
    "        else:\n",
    "            if lMorceau.strip()!=\"\":\n",
    "                lMorceauDict=dicterContent(lMorceau.strip(),lexique)\n",
    "                newTour.extend(lMorceauDict)\n",
    "    return newTour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['blablabla',\n",
       "  ('blablabla', 'blablabla', '', 'N', 'MS', '', 'blablabla', '', '88', '34')],\n",
       " ['{', '<disfluence>'],\n",
       " ['e', ('e', '6', '', 'N', 'Mj', '', 'e', 'L23', '6091', '2899')],\n",
       " ['}', '</disfluence>'],\n",
       " ['[bruit]', '<bruit/>'],\n",
       " ['dans',\n",
       "  ('dans', 'dâ', 'z\"', 'p', '', '', 'dans', 'L23', '465859', '829608')],\n",
       " ['{', '<disfluence>'],\n",
       " ['le', ('le', 'l@', '', 'd', 'MS', 'rd', 'le', 'L23', '***', '***')],\n",
       " ['la', ('la', 'la', '', 'd', 'FS', 'rd', 'la', 'L23', '***', '***')],\n",
       " ['l/', 'l/'],\n",
       " ['}', '</disfluence>'],\n",
       " ['la', ('la', 'la', '', 'd', 'FS', 'rd', 'la', 'L23', '***', '***')],\n",
       " ['première',\n",
       "  ('première',\n",
       "   'pr6mjEr',\n",
       "   '@',\n",
       "   'N',\n",
       "   'FS',\n",
       "   '',\n",
       "   'première',\n",
       "   'L23',\n",
       "   '***',\n",
       "   '***')],\n",
       " ['{', '<disfluence>'],\n",
       " ['im/', 'im/'],\n",
       " ['}', '</disfluence>'],\n",
       " ['{', '<disfluence>'],\n",
       " ['e', ('e', '6', '', 'N', 'Mj', '', 'e', 'L23', '6091', '2899')],\n",
       " ['}', '</disfluence>'],\n",
       " ['pardon',\n",
       "  ('pardon', 'pardô', '', 'N', 'MS', '', 'pardon', 'L23', '5562', '2689')]]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baliserTour(\"blablabla {e} [bruit] dans {le la l/} la première {im/} {e} pardon\",subBdlexique)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "testBaliseTour=baliserTour(u\"qu’est ce c’est ça [=CH] cette affaire Dupont là [/CH]\",subBdlexique)\n",
    "print (testBaliseTour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trouverMot2(nMot1,tourBalises):\n",
    "    result=None\n",
    "    if len(tourBalises[nMot1])>1:\n",
    "#         print (tourBalises[nMot1][1])\n",
    "        if isinstance(tourBalises[nMot1][1],tuple):\n",
    "            for nMot2,mot2 in enumerate(tourBalises[nMot1+1:]):\n",
    "                if len(mot2)>1:\n",
    "#                     print (mot2[0],mot2[1])\n",
    "                    if isinstance(mot2[1],tuple):\n",
    "                        result=nMot1+1+nMot2\n",
    "                        break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def faireTourPhon(tourBalises):\n",
    "    result=[]\n",
    "    for nMot1 in range(len(tourBalises)):\n",
    "        nMot2=trouverMot2(nMot1,tourBalises)\n",
    "        mot1=tourBalises[nMot1]\n",
    "#         print (mot1)\n",
    "        if nMot2:\n",
    "            mot2=tourBalises[nMot2]\n",
    "            contexteLiaison=liaison_obligatoire(mot1,mot2)\n",
    "#             print (nMot1,mot1[1],contexteLiaison)\n",
    "            result.append(formerLiaison(mot1,mot2,contexteLiaison))\n",
    "        else:\n",
    "#             print (mot1)\n",
    "            if len(mot1)==2 and isinstance(mot1[1],tuple):\n",
    "                result.append(sampa2api(mot1[1][1]))\n",
    "            elif len(mot1)==2:\n",
    "#                 print (\"len(mot1)==2\", mot1)\n",
    "                result.append(mot1[1])\n",
    "            else:\n",
    "#                 print (\"len(mot1)!=2\", mot1)\n",
    "                result.append(mot1[0])\n",
    "    return \"\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transcrireTourEAF(tour,lexique):\n",
    "    tourBalises=baliserTour(tour,lexique)\n",
    "    tourEAF=faireTourPhon(tourBalises)\n",
    "    return tourEAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transcrireEAF(nomEAF,subBdlexique):\n",
    "    xmlEAF=ET.parse(nomEAF,parser)\n",
    "    texteLignesEAF=[]\n",
    "    for nAnnotation,annotation in enumerate(xmlEAF.xpath(\"//ANNOTATION_VALUE\")):\n",
    "        if annotation.text:\n",
    "            tourEAF=transcrireTourEAF(annotation.text,subBdlexique)\n",
    "            annotation.text=tourEAF\n",
    "    return xmlEAF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def enchasseMot(balise,mot,graphie,phono,nMot,nTour):\n",
    "    ortho=mot[0]\n",
    "    cat=mot[3]\n",
    "    if cat in [u\"J\",u\"K\"]:\n",
    "        cat=u\"Adj\"\n",
    "    ms=mot[4]\n",
    "    vs=mot[5]\n",
    "    lexeme=mot[6].upper()\n",
    "    freq=mot[8]\n",
    "    nbVoyelles=compterVoyelles(mot[1])\n",
    "    if u\" \" in vs:\n",
    "        vs=u\"\"\n",
    "    motAttributs={\"cat\":cat,\"ms\":ms,\"vs\":vs,\"phon\":phono,\"nbsyll\":str(nbVoyelles),\"ortho\":ortho, \"lexeme\":lexeme, \"freq\":freq, \"id\":\"%05d%03d\"%(nTour,nMot)}\n",
    "    baliseMotBDL=ET.SubElement(balise,\"motBDL\",motAttributs)\n",
    "    baliseMotBDL.text=graphie\n",
    "    return nbVoyelles\n",
    "    \n",
    "\n",
    "def enchasseNonMot(balise,nonMot):\n",
    "    # print (\"nonMot\",nonMot)\n",
    "    m=re.match(r\"^[\\wâàéèêëîïôùûüçÂÀÉÈÊËÎÏÔÙÛÜÇæœÆŒ():]+/$\",nonMot)\n",
    "    if m: \n",
    "        lNonMot=ET.SubElement(balise, \"abandon\")\n",
    "    else:\n",
    "        lNonMot=ET.SubElement(balise, \"punct\")\n",
    "    lNonMot.text=nonMot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapBalises={\"???\":\"incomprehensible\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def enchasserTourTRS(tour,tourMots):\n",
    "    nbVoyelles=0\n",
    "    nbMots=0\n",
    "    lConnecteurs=set()\n",
    "    lThemeMots=set()\n",
    "#     print (tourMots)\n",
    "#     print (tour)\n",
    "\n",
    "    nTour=int(tour.attrib[\"id\"])\n",
    "    stackBalises=[tour]\n",
    "    for nMot1,mot1 in enumerate(tourMots):\n",
    "#         print (nMot1,mot1)\n",
    "        graphie=mot1[0]\n",
    "        lexMot=mot1[1]\n",
    "        if lexMot:\n",
    "            orthoMot=lexMot[0]\n",
    "        else:\n",
    "            orthoMot=\"\"\n",
    "        if orthoMot in connecteurs:\n",
    "            lConnecteurs.add(orthoMot)\n",
    "        if orthoMot in lThemeMots:\n",
    "            lThemeMots.add(orthoMot)\n",
    "        if isinstance(lexMot,tuple):\n",
    "            nbMots+=1\n",
    "            nMot2=trouverMot2(nMot1,tourMots)\n",
    "            phono=\"???\"\n",
    "            if nMot2:\n",
    "                mot2=tourMots[nMot2]\n",
    "                contexteLiaison=liaison_obligatoire(mot1,mot2)\n",
    "#                 print (nMot1,mot1[1],contexteLiaison)\n",
    "                phono=formerLiaison(mot1,mot2,contexteLiaison)\n",
    "                \n",
    "            nbVoyelles+=enchasseMot(stackBalises[-1],lexMot,graphie,phono,nMot1,nTour)\n",
    "        else:\n",
    "            m=re.match(r\"</.*>\",lexMot)\n",
    "            if m:\n",
    "                stackBalises.pop(-1)\n",
    "#                 print (\"pop\",groupeEAF)\n",
    "#                 print (tourMots)\n",
    "#                 print (stackBalises[-1].tag)\n",
    "            else:\n",
    "                m=re.match(r\"<(.*[^/])/?>\",lexMot)\n",
    "                if m:\n",
    "                    locBalise=m.group(1)\n",
    "#                     print (\"stackBalises\",ET.tostring(stackBalises[-1]),locBalise)\n",
    "                    if locBalise in mapBalises:\n",
    "                        locBalise=mapBalises[locBalise]\n",
    "                    locTag,locAttribs=makeTagAttribs(locBalise)\n",
    "                    newBalise=ET.SubElement(stackBalises[-1],locTag,locAttribs)\n",
    "                    stackBalises.append(newBalise)\n",
    "#                     print (\"push\",stackBalises[-1].tag)\n",
    "                else:\n",
    "                    enchasseNonMot(stackBalises[-1],lexMot)\n",
    "    tour.attrib[\"nbSyll\"]=str(nbVoyelles)\n",
    "    tour.attrib[\"nbMots\"]=str(nbMots)\n",
    "    if lConnecteurs:\n",
    "        tour.attrib[\"connecteurs\"]=\" \".join(lConnecteurs)\n",
    "    if lThemeMots:\n",
    "        tour.attrib[\"themeMots\"]=\" \".join(lThemeMots)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<Turn>\\n  <tour id=\"00001\">\\n    <mot>mot1</mot>\\n    <nom>\\n      <mot>nom1</mot>\\n    </nom>\\n    <mot>mot2</mot>\\n  </tour>\\n</Turn>\\n'\n"
     ]
    }
   ],
   "source": [
    "turn=ET.Element(\"Turn\")\n",
    "tour=ET.SubElement(turn,\"tour\",id=\"00001\")\n",
    "e1=ET.SubElement(tour,\"mot\")\n",
    "e1.text=\"mot1\"\n",
    "nom1=ET.SubElement(tour,\"nom\")\n",
    "nom1e1=ET.SubElement(nom1,\"mot\")\n",
    "nom1e1.text=\"nom1\"\n",
    "e2=ET.SubElement(tour,\"mot\")\n",
    "e2.text=\"mot2\"\n",
    "print (ET.tostring(turn,pretty_print=True,encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transcrireTRS(nomEAF,lexique):\n",
    "    xmlEAF=ET.parse(nomEAF,parser)\n",
    "\n",
    "    #################\n",
    "    #\n",
    "    # Récupération des timestamps\n",
    "    #\n",
    "    #################\n",
    "    \n",
    "    ts={}\n",
    "    for timeOrder in xmlEAF.xpath(\"//TIME_ORDER/TIME_SLOT\"):\n",
    "        tsID=timeOrder.attrib[\"TIME_SLOT_ID\"]\n",
    "        tsTime=timeOrder.attrib[\"TIME_VALUE\"]\n",
    "        ts[tsID]=tsTime\n",
    "    tiersTypes={}\n",
    "    annotations={}\n",
    "    turnTextes=[]\n",
    "\n",
    "    #################\n",
    "    #\n",
    "    # Récupération des tours\n",
    "    #\n",
    "    #################\n",
    "    \n",
    "    for tier in xmlEAF.xpath(\"//TIER\"):\n",
    "        tierID=tier.attrib[\"TIER_ID\"]\n",
    "        tierType=tier.attrib[\"LINGUISTIC_TYPE_REF\"]\n",
    "        tiersTypes[tierID]=tierType\n",
    "        for annotation in tier.xpath(\"ANNOTATION/ALIGNABLE_ANNOTATION\"):\n",
    "            aID=annotation.attrib[\"ANNOTATION_ID\"]\n",
    "            aTS1=annotation.attrib[\"TIME_SLOT_REF1\"]\n",
    "            aTS2=annotation.attrib[\"TIME_SLOT_REF2\"]\n",
    "            aBegin=time2TRS(ts[aTS1])\n",
    "            aEnd=time2TRS(ts[aTS2])\n",
    "            aValue=annotation.xpath(\"ANNOTATION_VALUE/text()\")\n",
    "            turnTextes.append(\"\\n\".join(aValue))\n",
    "            turn=(tierID, aBegin, aEnd, aValue)\n",
    "            annotations[aID]=turn\n",
    "            \n",
    "\n",
    "    #################\n",
    "    #\n",
    "    # Fabrication entête TRS\n",
    "    #\n",
    "    #################\n",
    "\n",
    "    root=ET.Element(\"Trans\")\n",
    "    speakers=ET.SubElement(root, \"Speakers\")\n",
    "    speakerID={}\n",
    "    for nSpk,spk in enumerate(tiersTypes):\n",
    "        ET.SubElement(speakers,\"Speaker\",id=\"spk%d\"%(nSpk+1),name=spk)\n",
    "        speakerID[spk]=\"spk%d\"%(nSpk+1)\n",
    "\n",
    "    episode=ET.SubElement(root, \"Episode\")\n",
    "    section=ET.SubElement(episode, \"Section\")   \n",
    "    tourId=0\n",
    "    # for k,v in sorted(annotations.items(),key=lambda x: int(x[0].strip(\"a\"))):\n",
    "    for k,v in sorted(annotations.items(),key=lambda x: float(x[1][2])):\n",
    "        # print (k,v)\n",
    "        #\n",
    "        # créer la structure Turn avec speaker, startTime, endTime\n",
    "        # et tour avec id\n",
    "        #\n",
    "        turn=ET.SubElement(section,\"Turn\",speaker=speakerID[v[0]],startTime=v[1],\\\n",
    "                                          endTime=v[2])\n",
    "        tour=ET.SubElement(turn,\"tour\",id=\"%05d\"%tourId)\n",
    "        #\n",
    "        # découper le texte de l'annotation\n",
    "        #\n",
    "        vTextes=baliserTour(\"\\n\".join(v[3]),lexique)\n",
    "        if debug: print (vTextes)\n",
    "        enchasserTourTRS(tour,vTextes)\n",
    "        tourId+=1\n",
    "    tree = ET.ElementTree(root)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ecrireInconnus(dInconnus,repGroupe):\n",
    "    fInconnus=repGroupe+\"/inconnus.txt\"\n",
    "    with codecs.open(fInconnus,\"w\",encoding=\"utf8\") as outFile:\n",
    "        for inconnu in dInconnus.values():\n",
    "            outFile.write(\";\".join(inconnu)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/gilles/pCloud Drive/FOD/GB/Cours/L2-Corpus/Corpus-2022/0-Test/AAA']\n"
     ]
    }
   ],
   "source": [
    "repRacine=\"/Users/gilles/pCloud Drive/FOD/GB/Cours/L2-Corpus/Corpus-20%d/0-Test/\"%annee\n",
    "repGroupes=listerGroupes(repRacine)\n",
    "print (repGroupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/gilles/pCloud Drive/FOD/GB/Cours/L2-Corpus/Corpus-2022/0-Test/AAA\n",
      "groupeEAF Rush Ep2_Fanny.eaf\n",
      "groupeEAF Rush Ep2_Leandre.eaf\n",
      "groupeEAF Temoin.eaf\n"
     ]
    }
   ],
   "source": [
    "debug=0\n",
    "for repGroupe in repGroupes[:]:\n",
    "    print ()\n",
    "    print (repGroupe)\n",
    "    groupeInconnus=lireInconnus(repGroupe)\n",
    "    groupeEAFs=listerEAFs(repGroupe)\n",
    "    for groupeEAF in groupeEAFs:\n",
    "        print (\"groupeEAF\",groupeEAF.split(\"/\")[-1])\n",
    "        subBdlexique,groupeInconnus=faireLexique(groupeEAF,groupeInconnus)\n",
    "        newEAF=transcrireEAF(groupeEAF,subBdlexique)\n",
    "        fNewEAF=groupeEAF.replace(\".eaf\",\"-phonetique.eaf\")\n",
    "        newEAF.write(fNewEAF, pretty_print=True, encoding='utf-8', xml_declaration=True)\n",
    "        newTRS=transcrireTRS(groupeEAF,subBdlexique)\n",
    "        nomXML=groupeEAF.replace(\".eaf\",\".xml\")\n",
    "        if nomXML!=groupeEAF:\n",
    "            newTRS.write(nomXML, pretty_print=True, encoding='utf-8', xml_declaration=True)\n",
    "        else:\n",
    "            print (\"pb de nom EAF\",nomEAF)\n",
    "    ecrireInconnus(groupeInconnus,repGroupe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"p(eu)t-êt(re)\" => \"p't-êt'\" pøtEtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
